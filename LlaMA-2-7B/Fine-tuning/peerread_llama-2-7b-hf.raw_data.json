{
    "original": [
        "This paper addresses the problem of disambiguating/linking textual entity\nmentions into a given background knowledge base (in this case, English\nWikipedia).  (Its title and introduction are a little overblown/misleading,\nsince there is a lot more to bridging text and knowledge than the EDL task, but\nEDL is a core part of the overall task nonetheles",
        "This paper presents several weakly supervised methods for developing NERs. The\nmethods rely on some form of projection from English into another language. The\noverall approach is not new and the individual methods proposed are\nimprovements of existing methods. For an ACL paper I would have expected more\nnovel approaches.\n\nOne of the contributions o",
        "This paper describes a rule based approach to time expression extraction. Its\nkey insights are time expressions typically are short and contain at least 1\ntime token. It first recognizes the time token through a combination of\ndictionary lookup, regular expression match with POS tagging information. It\nthen expands the time segment from either dire",
        "This paper presents a neural network-based framework for dialogue state\ntracking.\nThe main contribution of this work is on learning representations of user\nutterances, system outputs, and also ontology entries, all of which are based\non pre-trained word vectors.\nParticularly for the utterance representation, the authors compared two\ndifferent neura",
        "This paper proposes a neural network architecture that represent structural\nlinguistic knowledge in a memory network for sequence tagging tasks (in\nparticular, slot-filling of the natural language understanding unit in\nconversation systems). Substructures (e.g. a node in the parse tree) is encoded\nas a vector (a memory slot) and a weighted sum of t",
        "This paper presents a new dataset with annotations of products coming from\nonline cybercrime forums. The paper is clear and well-written and the\nexperiments are good. Every hypothesis is tested and compared to each other.\n\nHowever, I do have some concerns about the paper:\n\n1. The authors took the liberty to change the font size and the line spacing",
        "This paper introduces UCCA as a target representation for semantic parsing and\nalso describes a quite successful transition-based parser for inference into\nthat representation. I liked this paper a lot. I believe there is a lot of\nvalue simply in the introduction of UCCA (not new, but I believe relatively new\nto this community), which has the poten",
        "This paper proposed a macro discourse structure scheme. The authors carried out\na pilot study annotating a corpus consisting of 97 news articles from Chinese\ntreebank 8.0. They then built a model to recognize the primary-secondary\nrelations and 5 discourse relations (joint, elaboration, sequence, background,\ncause-result) in this corpus.\n\nThe paper",
        "This paper proposes a framework for evaluation of word embeddings based on data\nefficiency and simple supervised tasks. The main motivation is that word\nembeddings are generally used in a transfer learning setting, where evaluation\nis done based on how faster is to train a target model. The approach uses a set\nof simple tasks evaluated in a supervi",
        "This paper delves into the mathematical properties of the skip-gram model,\nexplaining the reason for its success on the analogy task and for the general\nsuperiority of additive composition models. It also establishes a link between\nskip-gram and Sufficient Dimensionality Reduction.\n\nI liked the focus of this paper on explaining the properties of sk",
        "This paper presents a neural sequence-to-sequence model for encoding dialog\ncontexts followed by decoding system responses in open-domain conversations.\nThe authors introduced conditional variational autoencoder (CVAE) which is a\ndeep neural network-based generative model to learn the latent variables for\ndescribing responses conditioning dialog co",
        "This paper compares different ways of inducing embeddings for the task of\npolarity classification. The authors focus on different types of corpora and\nfind that not necessarily the largest corpus provides the most appropriate\nembeddings for their particular task but it is more effective to consider a\ncorpus (or subcorpus) in which a higher concentr",
        "This paper presents a purpose-built neural network architecture for textual\nentailment/NLI based on a three step process of encoding, attention-based\nmatching, and aggregation. The model has two variants, one based on TreeRNNs\nand the other based on sequential BiLSTMs. The sequential model outperforms all\npublished results, and an ensemble with the",
        "This paper proposes a supervised deep learning model for event factuality\nidentification.  The empirical results show that the model outperforms\nstate-of-the-art systems on the FactBank corpus, particularly in three classes\n(CT-, PR+ and PS+).  The main contribution of the paper is the proposal of an\nattention-based two-step deep neural model for e",
        "This paper presents the gated self-matching network for reading comprehension\nstyle question answering. There are three key components in the solution: \n\n(a) The paper introduces the gated attention-based recurrent network to obtain\nthe question-aware representation for the passage. Here, the paper adds an\nadditional gate to attention-based recurre",
        "This paper investigates the cold-start problem in review spam detection. The\nauthors first qualitatively and quantitatively analyze the cold-start problem.\nThey observe that there is no enough prior data from a new user in this\nrealistic scenario. The traditional features fail to help to identify review\nspam. Instead, they turn to rely on the abund",
        "This paper details a method of achieving translation from morphologically\nimpoverished languages (e.g. Chinese) to morphologically rich ones (e.g.\nSpanish) in a two-step process. First, a system translates into a simplified\nversion of the target language. Second, a system chooses morphological features\nfor each generated target word, and inflects t",
        "This paper addresses the network embedding problem by introducing a neural\nnetwork model which uses both the network structure and associated text on the\nnodes, with an attention model to vary the textual representation based on the\ntext of the neighboring nodes.\n\n- Strengths:\n\nThe model leverages both the network and the text to construct the late",
        "This paper describes interesting and ambitious work: the automated conversion\nof Universal Dependency grammar structures into [what the paper calls] semantic\nlogical form representations.  In essence, each UD construct is assigned a\ntarget construction in logical form, and a procedure is defined to effect the\nconversion, working \u2018inside-out\u2019 using ",
        "This paper outlines a method to learn sense embeddings from unannotated corpora\nusing a modular sense selection and representation process. The learning is\nachieved by a message passing scheme between the two modules that is cast as a\nreinforcement learning problem by the authors.\n\n- Strengths:\n\nThe paper is generally well written, presents most of",
        "This paper describes a state-of-the-art CCG parsing model that decomposes into\ntagging and dependency scores, and has an efficient A* decoding algorithm.\nInterestingly, the paper slightly outperforms Lee et al. (2016)'s more\nexpressive global parsing model, presumably because this factorization makes\nlearning easier. It's great that they also repor",
        "This paper presents evaluation metrics for lyrics generation exploring the need\nfor the lyrics to be original,but in a similar style to an artist whilst being\nfluent and co-herent. The paper is well written and the motivation for the\nmetrics are well explained.  \n\nThe authors describe both hand annotated metrics (fluency, co-herence and\nmatch) and ",
        "This paper proposed to explore discourse structure, as defined by Rhetorical\nStructure Theory (RST) to improve text categorization. A RNN with attention\nmechanism is employed to compute a representation of text. The experiments on\nvarious of dataset shows the effectiveness of the proposed method. Below are my\ncomments:\n\n(1) From Table 2, it shows t",
        "This paper proposes joint CTC-attention end-to-end ASR, which utilizes both\nadvantages in training and decoding. \n\n- Strengths:\nIt provides a solid work of hybrid CTC-attention framework in training and\ndecoding, and the experimental results showed that the proposed method could\nprovide an improvement in Japanese CSJ and Mandarin Chinese telephone ",
        "This paper proposes a method for generating datasets of pictures from simple\nbuilding blocks, as well as corresponding logical forms and language\ndescriptions.\nThe goal seems to be to have a method where the complexity of pictures and\ncorresponding desciptions can be controlled and parametrized. \n\n - The biggest downside seems to be that the maxima",
        "This paper propose a general framework for analyzing similarities and\ndifferences in term meaning and representation in different contexts.\n\n- Strengths:\n* The framework proposed in this paper is generalizable and can be applied to\ndifferent applications, and accommodate difference notation of context,\ndifferent similarity functions, different type",
        "This paper modifies existing word embedding algorithms (GloVe, Skip Gram, PPMI,\nSVD) to include ngram-ngram cooccurance statistics. To deal with the large\ncomputational costs of storing such expensive matrices, the authors propose an\nalgorithm that uses two different strategies to collect counts.  \n\n- Strengths:\n\n* The proposed work seems like a na",
        "This paper investigates the application of distributional vectors of meaning in\ntasks that involve the identification of semantic relations, similar to the\nanalogical reasoning task of Mikolov et al. (2013): Given an expression of the\nform \u201cX is for France what London is for the UK\u201d, X can be approximated by\nthe simple vector arithmetic operation L",
        "This paper describes a straightforward extension to left-to-right beam search\nin order to allow it to incorporate lexical constraints in the form of word\nsequences that must appear in MT output. This algorithm is shown to be\neffective for interactive translation and domain adaptation.\n\nAlthough the proposed extension is very simple, I think the pap",
        "This paper introduces a new approach to semantic parsing in which the model is\nequipped with a neural sequence to sequence (seq2seq) model (referred to as the\n\u201cprogrammer\u201d) which encodes a natural language question and produces a\nprogram. The programmer is also equipped with a \u2018key variable\u2019 memory\ncomponent which stores (a) entities in the questio",
        "This paper proposes integrating word sense inventories into existing approaches\nfor the lexical substitution task by using these inventories to filter\ncandidates. To do so, the authors first propose a metric to measure the mutual\nsubstitutability of sense inventories with human judgments for the lexsub task,\nand empirically measure the substitutabi",
        "This paper presents a corpus of annotated essay revisions. \n\nIt includes two examples of application for the corpus:\n\n1) Student Revision Behavior Analysis and 2) Automatic Revision Identification\n\nThe latter is essentially a text classification task using an SVM classifier\nand a variety of features. The authors state that the corpus will be freely",
        "This paper presents a dialogue agent where the belief tracker and the dialogue\nmanager are jointly optimised using the reinforce algorithm. It learns from\ninteraction with a user simulator. There are two training phases. The first is\nan imitation learning phase where the system is initialised using supervising\nlearning from a rule-based model. Then",
        "This paper presents a new state-of-the-art deep learning model for semantic\nrole labeling (SRL) that is a natural extension of the previous\nstate-of-the-art system (Zhou and Xu, 2015) with recent best practices for\ninitialization and regularization in the deep learning literature.\nThe model gives a 10% relative error reduction which is a big gain o",
        "This paper describes several ways to encode arbitrarily long sequences of\ndigits using something called the major system. In the major system, each digit\nis mapped to one or more characters representing consonantal phonemes; the\npossible mappings between digit and phoneme are predefined. The output of an\nencoding is typically a sequence of words co",
        "This paper presents a gated attention mechanism for machine reading. \nA key idea is to extend Attention Sum Reader (Kadlec et al. 2016) to multi-hop\nreasoning by fine-grained gated filter. \nIt's interesting and intuitive for machine reading. \nI like the idea along with significant improvement on benchmark datasets, but\nalso have major concerns to g",
        "This paper proposes to use an encoder-decoder framework for keyphrase\ngeneration. Experimental results show that the proposed model outperforms other\nbaselines if supervised data is available.\n\n- Strengths:\nThe paper is well-organized and easy to follow (the intuition of the proposed\nmethod is clear). It includes enough details to replicate experim",
        "This paper continues the line of work for applying word embeddings for the\nproblem of unsupervised morphological segmentation (e.g. Soricut & Och, 2015;\n\u00dcst\u00fcn & Can, 2016). The proposed method, MORSE, applies a local optimization\nfor segmentation of each word, based on a set of orthographic and semantic\nrules and a few heuristic threshold values as",
        "This paper proposes a simple attention-based RNN model for generating SQL\nqueries from natural language without any intermediate representation. Towards\nthis end they employ a data augmentation approach where more data is\niteratively collected from crowd annotation, based on user feedback on how well\nthe SQL queries produced by the model do. Result",
        "This paper presents a graph-based approach for producing sense-disambiguated\nsynonym sets from a collection of undisambiguated synonym sets.  The authors\nevaluate their approach by inducing these synonym sets from Wiktionary and from\na collection of Russian dictionaries, and then comparing pairwise synonymy\nrelations (using precision, recall, and F",
        "This paper proposes a joint model of salient phrase selection and discourse\nrelation prediction in spoken meeting. Experiments using meeting corpora show\nthat the proposed model has higher performance than the SVM-based classifier.\n\n- Strengths:\nThe paper is written to be easy to read. Technical details are described fully,\nand high performance is ",
        "This paper proposes a method for building dialogue agents involved in a\nsymmetric collaborative task, in which the agents need to strategically\ncommunicate to achieve a common goal.  \n\nI do like this paper.  I am very interested in how much data-driven techniques\ncan be used for dialogue management.  However, I am concerned that the approach\nthat t",
        "This paper proposes an approach for classifying literal and metaphoric\nadjective-noun pairs. The authors create a word-context matrix for adjectives\nand nouns where each element of the matrix is the PMI score. They then use\ndifferent methods for selecting dimensions of this matrix to represent each\nnoun/adjective as a vector. The geometric properti",
        "This paper proposes a novel strategy for zero-resource translation where\n(source, pivot) and (pivot, target) parallel corpora are available. A teacher\nmodel for p(target|pivot) is first trained on the (pivot, target) corpus, then\na student model for p(target|source) is trained to minimize relative entropy\nwith respect to the teacher on the (source,",
        "This paper considers the problem of KB completion and proposes ITransF for this\npurpose. Unlike STransE that assigns each relation an independent matrix, this\npaper proposes to share the parameters between different relations. A model is\nproposed where a tensor D is constructed that contains various relational\nmatrices as its slices and a selection",
        "This paper presents a method for translating natural language descriptions into\nsource code via a model constrained by the grammar of the programming language\nof the source code.  I liked this paper - it's well written, addresses a hard\nand interesting problem by taking advantage of inherent constraints, and shows\nsignificant performance improvemen",
        "This paper focuses on interpreting sarcasm written in Twitter identifying\nsentiment words and then using a machine translation engine to find an\nequivalent not sarcastic tweet. \n\nEDIT: Thank you for your answers, I appreaciate it. I added one line commenting\nabout it.\n\n- Strengths:\n\nAmong the positive aspects of your work, I would like to mention t",
        "This paper describes a system to assist written test scoring.\n\n- Strengths:\nThe paper represents an application of an interesting NLP problem --\nrecognizing textual entailment -- to an important task -- written test scoring.\n\n- Weaknesses:\nThere isn't anything novel in the paper. It consist of an application of an\nexisting technology to a known pro",
        "This paper introduces new configurations and training objectives for neural\nsequence models in a multi-task setting. As the authors describe well, the\nmulti-task setting is important because some tasks have shared information\nand in some scenarios learning many tasks can improve overall performance.\n\nThe methods section is relatively clear and logi",
        "This paper proposed a new phrasal RNN architecture for sequence to sequence\ngeneration. They have evaluated their architecture based on (i) the language\nmodelling test evaluated on PTB and FBIS and (ii) Chinese-English machine\ntranslation task on NIST MT02-08 evaluation sets. The phrasal RNN (pRNN)\narchitecture is achieved by generating subnetworks",
        "This paper proposes new prediction models for Japanese SRL task by adopting the\nEnglish state-of-the-art model of (Zhou and Xu, 2015).\nThe authors also extend the model by applying the framework of Grid-RNNs in\norder to handle the interactions between the arguments of multiple predicates.\n\nThe evaluation is performed on the well-known benchmark dat",
        "This paper develops an LSTM-based model for classifying connective uses for\nwhether they indicate that a causal relation was intended. The guiding idea is\nthat the expression of causal relations is extremely diverse and thus not\namenable to syntactic treatment, and that the more abstract representations\ndelivered by neural models are therefore more",
        "This paper proposes a method for recognizing lexical entailment (specifically,\nhypernymy) in context. The proposed method represents each context by\naveraging, min-pooling, and max-pooling its word embeddings. These\nrepresentations are combined with the target word's embedding via element-wise\nmultiplication. The in-context representation of the le",
        "This paper proposes a method for evaluating topic quality based on using word\nembeddings to calculate similarity (either directly or indirectly via matrix\nfactorisation), achieving impressive results over standard datasets.\n\nThe proposed method represents a natural but important next step in the\nevolutionary path of research on topic evaluation. Th",
        "This paper proposed a very interesting idea of using cognitive features for\nsentiment analysis and sarcasm detection. More specifically, the eye-movement\npatterns of human annotators are recorded to derive a new set of features. The\nauthors claim that this is the first work to include cognitive features into\nthe NLP community. \n\nStrength: \n1. The p",
        "This paper proposes a neural-styled topic model, extending the objective of\nword2vec to also learn document embeddings, which it then constrains through\nsparsification, hence mimicking the output of a topic model.\n\nI really liked the model that the authors proposed, and found the examples\npresented by the authors to be highly promising. What was re",
        "This paper describes four methods of obtaining multilingual word embeddings and\na modified QVEC metric for evaluating the efficacy of these embeddings. The\nembedding methods are: \n\n(1) multiCluster : Uses a dictionary to map words to multilingual clusters.\nCluster embeddings are then obtained which serve as embeddings for the words\nthat reside in e",
        "This paper proposes a method for discovering correspondences between languages\nbased on MDL. The author model correspondences between words sharing the same\nmeaning in a number of Slavic languages. They develop codes for rules that\nmatch substrings in two or more languages and formulate an MDL objective that\nbalances the description of the model an",
        "This paper proposes an approach for multi-lingual named entity recognition\nusing features from Wikipedia. By relying on a cross-lingual Wikifier, it\nidentifies English Wikipedia articles for phrases in a target language and uses\nfeatures based on the wikipedia entry. Experiments show that this new feature\nhelps not only in the monolingual case, but",
        "This paper proposes the new (to my knowledge) step of proposing to treat a\nnumber of sentence pair scoring tasks (e.g. Answer Set Scoring, RTE,\nParaphrasing,\namong others) as instances of a more general task of understanding semantic\nrelations\nbetween two sentences. Furthermore, they investigate the potential of learning\ngenerally-\napplicable neura",
        "This paper presents a transition-based graph parser able to cope with the rich\nrepresentations of a semantico-cognitive annotation scheme, instantiated in the\nUCCA corpora. The authors start first by exposing what, according to them,\nshould cover a semantic-based annotation scheme: (i) being graph-based\n(possibility for a token/node of having multi",
        "This paper presents a Stack LSTM parser based on the work of Henderson et al.\n(2008, 2013) on joint syntactic/semantic transition-based parsing and Dyer et\nal. (2015) on stack LSTM syntactic parsing. The use of the transition system\nfrom the former and the stack LSTM from the latter shows interesting results\ncompared to the joint systems on the CoN",
        "This paper investigates three simple weight-pruning techniques for NMT, and\nshows that pruning weights based on magnitude works best, and that retraining\nafter pruning can recover original performance, even with fairly severe\npruning.\n\nThe main strength of paper is that the technique is very straightforward and\nthe results are good. It\u00e2\u0080\u0099s also cle",
        "This paper presents results on the UD treebanks to test delexicalized transfer\nparsers and an unsupervised parser which is enriched with external\nprobabilities.\n\nThe paper is interesting, but I think it could be improved further.\n\n(5.2) \"McDonald et al. (2011) presented 61.7% of averaged accuracy over 8\nlanguages. On the same languages, our transfe",
        "This paper presents an approach to tag word senses with temporal information\n(past, present, future or atemporal). They model the problem using a\ngraph-based semi-supervised classification algorithm that allows to combine\nitem specific information - such as the presence of some temporal indicators in\nthe glosses - and the structure of Wordnet - tha",
        "This paper models event linking using CNNs. Given event mentions, the authors\ngenerate vector representations based on word embeddings passed through a CNN\nand followed by max-pooling. They also concatenate the resulting\nrepresentations with several word embeddings around the mention. Together with\ncertain pairwise features, they produce a vector o",
        "This paper describes a new deterministic dependency parsing algorithm and\nanalyses its behaviour across a range of languages.\nThe core of the algorithm is a set of rules defining permitted dependencies\nbased on POS tags.\nThe algorithm starts by ranking words using a slightly biased PageRank over a\ngraph with edges defined by the permitted dependenc",
        "This paper improves significantly upon the original NPI work, showing that the model generalizes far better when trained on traces in recursive form. The authors show better sample complexity and generalization results for addition and bubblesort programs, and add two new and more interesting tasks - topological sort and quicksort (added based on r",
        "This paper extends an approach to rate-distortion optimization to deep encoders and decoders, and from a simple entropy encoding scheme to adaptive entropy coding. In addition, the paper discusses the approach\u2019s relationship to variational autoencoders.\n\nGiven that the approach to rate-distortion optimization has already been published, the novelty",
        "This paper describes a new approach to meta learning by interpreting the SGD update rule as gated recurrent model with trainable parameters. The idea is original and important for research related to transfer learning. The paper has a clear structure, but clarity could be improved at some points.\n\nPros:\n\n- An interesting and feasible approach to me",
        "This paper was submitted to arXiv last week:\n\n",
        "This paper makes a valuable contribution to provide a more clear understanding of generative adversarial network (GAN) training procedure. \n\nWith the new insight of the training dynamics of GAN, as well as its variant, the authors reveal the reason that why the gradient is either vanishing in original GAN or unstable in its variant. More importantl",
        "This paper proposes a way of adding unsupervised auxiliary tasks to a deep RL agent like A3C. Authors propose a bunch of auxiliary control tasks and auxiliary reward tasks and evaluate the agent in Labyrinth and Atari. Proposed UNREAL agent performs significantly better than A3C and also learns faster. This is definitely a good contribution to the ",
        "This paper proposed to use RL and RNN to design the architecture of networks for specific tasks. The idea of the paper is quite promising and the experimental results on two datasets show that method is solid.\nThe pros of the paper are:\n1. The idea of using RNN to produce the description of the network and using RL to train the RNN is interesting a",
        "This paper details the approach that won the VizDoom competition - an on-policy reinforcement learning approach that predicts auxiliary variables, uses intrinsic motivation, and is a special case of a universal value function. The approach is a collection of different methods, but it yields impressive empirical results, and it is a clear, well-writ",
        "This paper proposes learning on the fly to represent a dialog as a graph (which acts as the memory), and is first demonstrated on the bAbI tasks. Graph learning is part of the inference process, though there is long term representation learning to learn graph transformation parameters and the encoding of sentences as input to the graph. This seems ",
        "This paper proposes to investigate attention transfers between a teacher and a student network. \n\nAttention transfer is performed by minimising the l2 distance between the teacher/student attention maps at different layers, in addition to minimising the classification loss and optionally a knowledge distillation term.\nAuthors define several activat",
        "This paper investigates the benefits of visual servoing using a learned\nvisual representation. The authors  propose to first learn an action-conditional\nbilinear model of the visual features (obtained from a pre-trained VGG net) from\nwhich a policy can be derived using a linearization of the dynamics. A multi-scale,\nmulti-channel and locally-connec",
        "This paper proposes a nonparametric neural network model, which automatically learns the size of the model during the training process. The key idea is to randomly add zero units and use sparse regularizer to automatically null out the weights that are irrelevant. The idea sounds to be a random search approach over discrete space with the help of s",
        "This paper prunes entire groups of filters in CNN so that they reduce computational cost and at the same time do not result in sparse connectivity. This result is important to speed up and compress neural networks while being able to use standard fully-connected linear algebra routines. \nThe results are a 10% improvements in ResNet-like and ImageNe",
        "This paper is well written, and well presented. This method is using denoise autoencoder to learn an implicit probability distribution helps reduce training difficulty, which is neat. In my view, joint training with an auto-encoder is providing extra auxiliary gradient information to improve generator. Providing auxiliary information may be a metho",
        "This paper presents an approach for skills transfer from one task to another in a control setting (trained by RL) by forcing the embeddings learned on two different tasks to be close (L2 penalty). The experiments are conducted in MuJoCo, with a set of experiments being from the state of the joints/links (5.2/5.3) and a set of experiments on the pix",
        "This paper proposes a model to learn across different views of objects.  The key insight is to use a triplet loss that encourages two different views of the same object to be closer than an image of a different object.  The approach is evaluated on object instance and category retrieval and compared against baseline CNNs (untrained AlexNet and Alex",
        "This paper proposed a neural attention model which has a learnable and differentiable sampling lattice. The work is well motivated as few previous work focus on learning the sampling lattice but with a fixed lattice. This work is quite similar to Spatial Transformer Networks (Jaderberg 2015), but the sampling lattice is learned by the model. The ex",
        "This paper presents an information theoretic framework for unsupervised learning. The framework relies on infomax principle, whose goal is to maximize the mutual information between input and output. The authors propose a two-step algorithm for learning in this setting. First, by leveraging an asymptotic approximation to the mutual information, the",
        "This paper provides a new perspective to understanding the ResNet and Highway net. The new perspective assumes that the blocks inside the networks with residual or skip-connection are groups of successive layers with the same hidden size, which performs to iteratively refine their estimates of the same feature instead of generate new representation",
        "This paper not only shows that a cache model on top of a pre-trained RNN can improve language modeling, but also illustrates a shortcoming of standard RNN models in that they are unable to capture this information themselves. Regardless of whether this is due to the small BPTT window (35 is standard) or an issue with the capability of the RNN itsel",
        "This paper proposed a novel adversarial framework to train a model from demonstrations in a third-person perspective, to perform the task in the first-person view. Here the adversarial training is used to extract a novice-expert (or third-person/first-person) independent feature so that the agent can use to perform the same policy in a different vi",
        "This paper combines variational RNN (VRNN) and domain adversarial networks (DANN) for domain adaptation in the sequence modelling domain.  The VRNN is used to learn representations for sequential data, which is the hidden states of the last time step.  The DANN is used to make the representations domain invariant, therefore achieving cross domain a",
        "This paper introduces a novel method for language modeling which is suitable for both modeling programming language as well as natural language. The approach uses a program synthesis algorithm to search over program space and uses count-based estimation of the weights of the program. This is a departure from neural network-based approaches which re",
        "This paper provides a principled and practical formulation for weight-sharing and quantization, using a simple mixture of Guassians on the weights, and stochastic variational inference. The main idea and results are presented clearly, along with illustrative side-experiments showing the properties of this method in practice. Also, the method is ill",
        "This paper essentially presents a new inductive bias in the architecture of (convolutional) neural networks (CNN). The mathematical motivations/derivations of the proposed architecture are detailed and rigorous. The proposed architecture promises to produce equivariant representations with steerable features using fewer parameters than traditional ",
        "This paper proposed an integration of memory network with reinforcement learning. The experimental data is simple, but the model is very interesting and relatively novel. There are some questions about the model:\n\n1. how does the model extend to the case with multiple variables in a single sentence?\n\n2. If the answer is out of vocabulary, how would",
        "This paper presents an interesting take on getting an ensemble for free whilst training a single network. However, your main accuracy comparison seems to exclude traditional ensemble methods, save for the very end of section 4.3, where the actual ensemble method you used is not mentioned. I would advise expanding this paragraph to explain what ense",
        "This paper introduces an approach for future frame prediction in videos by decoupling motion and content to be encoded separately, and additionally using multi-scale residual connections. Qualitative and quantitative results are shown on KTH, Weizmann, and UCF-101 datasets.\n\nThe idea of decoupling motion and content is interesting, and seems to wor",
        "This paper provides an interesting framework for handling semi-supervised RL problems, settings were one can interact with many MDPs drawn from some class, but where only a few have observable rewards; the agent then uses a policy derived from the labeled MDPs to estimate a reward function for the unlabeled MDPs. The approach is straightforward, an",
        "This paper proposes a new Bayesian neural network architecture for predicting the values of learning curves during the training of machine learning models. This is an exploratory paper, in that the ultimate goal is to use this method in a Bayesian optimization system, but for now the experiments are limited to assessing the quality of the predictio",
        "\nThis papers adds to the literature on learning optimizers/algorithms that has gained popularity recently. The authors choose to use the framework of guided policy search at the meta-level to train the optimizers. They also opt to train on random objectives and assess transfer to a few simple tasks.\n\nAs pointed below, this is a useful addition.\n\nHo",
        "This paper describes a method to estimate likelihood scores for a range of models defined by a decoder.\n \n This work has some issues. The paper mainly applies existing ideas. As discussed on openreview, the isotropic Gaussian noise model used to create a model with a likelihood is questionable, and it's unclear how useful likelihoods are when model",
        "This paper presents new way for compressing CNN weights. In particular this paper uses a new neural network quantization method that compresses network weights to ternary values.\nThe group has recently published multiple paper on this topic, and this one offers possibly the lowest returns I have seen. Only a fraction of percentage in ImageNet. Resu",
        "This paper presents a training strategy for deep networks.  First, the network is trained in a standard fashion.  Second, small magnitude weights are clamped to 0; the rest of the weights continue to be trained.  Finally, all the weights are again jointly trained.  Experiments on a variety of image, text, and speech datasets demonstrate the approac",
        "This paper proposes a new memory module for large scale life-long and one-shot learning. The module is general enough that the authors apply the module to several neural network architectures and show improvements in performance.\n\nUsing k-nearest neighbors for memory access is not completely new. This has been recently explored in Rae et al., 2016 ",
        "This paper presents a clear hierarchical taxonomy of transfer learning methods as applicable to sequence tagging problems. This contextualizes and unifies previous work on specific instances of this taxonomy. Moreover, the paper shows that previously unexplored places in this taxonomy are competitive with or superior to the state of the art in key ",
        "This paper proposes a new gating mechanism to combine word and character representations. The proposed model sets a new state-of-the-art on the CBT dataset; the new gating mechanism also improves over scalar gates without linguistic features on SQuAD and a twitter classification task. \n\nIntuitively, the vector-based gate working better than the sca",
        "This paper performs a very important service: exploring in a clear and systematic way the performance and trainability characteristics of a set of neural network architectures -- in particular, the basic RNN motifs that have recently been popular.   \n\nPros:\n\n* This paper addresses an important question I and many others would have liked to know the",
        "This paper addresses one of the major shortcomings of generative adversarial networks - their lack of mechanism for evaluating held-out data. While other work such as BiGANs/ALI address this by learning a separate inference network, here the authors propose to change the GAN objective function such that the optimal discriminator is also an energy f",
        "This paper presents a novel way of pruning filters from convolutional neural networks with a strong theoretical justification. The proposed methods is derived from the first order Taylor expansion of the loss change while pruning a particular unit. This leads to simple weighting of the unit activation with its gradient w.r.t. loss function and perf",
        "This paper provides two approaches to question answering: pointing to spans, and use of match-LSTM. The models are evaluated on SQuAD and MSMARCO. The reviewers we satisfied that, with the provision of",
        "This paper proposes a modification of the parametric texture synthesis model of Gatys et al. to take into account long-range correlations of textures. To this end the authors add the Gram matrices between spatially shifted feature vectors to the synthesis loss. Some of the synthesised textures are visually superior to the original Gatys et al. meth",
        "This paper proposed a dynamic coattention network for the question answering task with long contextual documents. \nThe model is able to encode co-dependent representations of the question and the document, and a dynamic decoder iteratively pointing the potential answer spans to locate the final answer. \n\nOverall, this is a well-written paper. \nAlth",
        "This paper fairly clearly presents a totally sensible idea. The details of the method presented in this paper are clearly preliminary, but is enough to illustrate a novel approach.",
        "This paper optimizes autoencoders for lossy image compression. Minimal adaptation of the loss makes autoencoders competitive with JPEG2000 and computationally efficient, while the generalizability of trainable autoencoders offers the added promise of adaptation to new domains without domain knowledge.\n The paper is very clear and the authors have t",
        "This paper tests zoneout against a variety of datasets - character level, word level, and pMNIST classification - showing applicability in a wide range of scenarios. While zoneout acts as a regularizer to prevent overfitting, it also has similarities to residual connections. The continued analysis of this aspect, including analyzing how the gradien",
        "This paper motivates the combination of autoregressive models with Variational Auto-Encoders and how to control the amount the amount of information stored in the latent code. The authors provide state-of-the-art results on MNIST, OMNIGLOT and Caltech-101.\nI find that the insights provided in the paper, e.g. with respect to the effect of having a m",
        "This paper proposes a method for significantly increasing the number of parameters in a single layer while keeping computation in par with (or even less than) current SOTA models. The idea is based on using a large mixture of experts (MoE) (i.e. small networks), where only a few of them are adaptively activated via a gating network. While the idea ",
        "This paper discusses Hyperband, an extension of successive halving by Jamieson & Talwalkar (AISTATS 2016). Successive halving is a very nice algorithm that starts evaluating many configurations and repeatedly cuts off the current worst half to explore many configuration for a limited budget.\n\nHaving read the paper for the question period and just r",
        "This paper introduces the Quasi-Recurrent Neural Network (QRNN) that dramatically limits the computational burden of the temporal transitions in\nsequence data. Briefly (and slightly inaccurately) model starts with the LSTM structure but removes all but the diagonal elements to the transition\nmatrices. It also generalizes the connections from lower ",
        "This paper explores ensemble optimisation in the context of policy-gradient training. Ensemble training has been a low-hanging fruit for many years in the this space and this paper finally touches on this interesting subject. The paper is well written and accessible. In particular the questions posed in section 4 are well posed and interesting.\n\nTh",
        "This paper studies the problem of transferring solutions of existing tasks to tackle a novel task under the framework of reinforcement learning and identifies two important issues of avoiding negative transfer and being selective transfer. The proposed approach is based on a convex combination of existing solutions and the being-learned solution to",
        "This paper proposes an approach to learning word vector representations for character sequences and acoustic spans jointly. The paper is clearly written and both the approach and experiments seem reasonable in terms of execution. The motivation and tasks feel a bit synthetic as it requires acoustics spans for words that have already been segmented ",
        "This paper introduces MusicNet, a new dataset. Application of ML techniques to music have been limited due to scarcity of exactly the kind of data that is provided here: meticulously annotated, carefully verified and organized, containing enough \"hours\" of music, and where genre has been well constrained in order to allow for sufficient homogeneity",
        "This paper applies REINFORCE to learn MCMC proposals within the existing STOKE scheme for super-optimization. It's a neat paper, with interesting results.\n \n It's not clear whether interesting representations are learned, and the algorithms are not really new. However, it's a neat piece or work, that some ICLR reviewers found interesting, and could",
        "This paper presented a method of improving the efficiency of deep networks acting on a sequence of correlated inputs, by only performing the computations required to capture changes between adjacent inputs. The paper was clearly written, the approach is clever, and it's neat to see a practical algorithm driven by what is essentially a spiking netwo",
        "This paper applies the idea of normalizing flows (NFs), which allows us to build complex densities with tractable likelihoods, to maximum entropy constrained optimization.\n\nThe paper is clearly written and is easy to follow.\n\nNovelty is a weak factor in this paper. The main contributions come from (1) applying previous work on NFs to the problem of",
        "This paper focusses on attention for neural language modeling and has two major contributions:\n\n1. Authors propose to use separate key, value, and predict vectors for attention mechanism instead of a single vector doing all the 3 functions. This is an interesting extension to standard attention mechanism which can be used in other applications as w",
        "This paper is a by-the-numbers extension of the hidden semi-Markov model to include nonlinear observations, and neural network-based inference. The paper is fairly clear, although the English isn't great. The experiments are thorough.\n \n Where this paper really falls down is on originality. In particular, in the last two years there have been relat",
        "This paper presents a variational inference based method for learning nonlinear dynamical systems. Unlike the deep Kalman filter, the proposed method learns a state space model, which forces the latent state to maintain all of the information relevant to predictions, rather than leaving it implicit in the observations. Experiments show the proposed",
        "This paper first discusses a general framework for improving optimization of a complicated function using a series of approximations. If the series of approximations are well-behaved compared to the original function, the optimization can in principle be sped up. This is then connected to a particular formulation in which a neural network can behav",
        "This paper extends preceding works to create a mapping between the word embedding space of two languages. The word embeddings had been independently trained on monolingual data only, and various forms of bilingual information is used to learn the mapping. This mapping is then used to measure the precision of translations.\n\nIn this paper, the author",
        "This paper proposes to learn decomposition of sequences (such as words) for speech recognition. It addresses an important issue and I forsee it being useful for other applications such as machine translation. While the approach is novel and well-motivated, I would very much like to see a comparison against byte pair encoding (BPE). BPE is a very na",
        "This paper is technically sound. It highlights well the strengths and weaknesses of the proposed simplified model.\n\nIn terms of impact, its novelty is limited, in the sense that the authors did seemingly the right thing and obtained the expected outcomes. The idea of modeling deep learning computation is not in itself particularly novel. As a compa",
        "This paper shows how policy gradient and Q-Learning may be combined together, improving learning as demonstrated in particular in the Atari Learning Environment. The core idea is to note that entropy-regularized policy gradient leads to a Boltzmann policy based on Q values, thus linking pi & Q together and allowing both policy gradient and Q-Learni",
        "This paper clearly lays out the recipe for a family of invertible density models, explores a few extensions, and demonstrates the overall power of the approach. The work is building closely on previous approaches, so it suffers a bit in terms of originality. However, I expect this overall approach to become a standard tool for model-building.\n \n Th",
        "This paper extends batch normalization successfully to RNNs where batch normalization has previously failed or done poorly. The experiments and datasets tackled show definitively the improvement that batch norm LSTMs provide over standard LSTMs. They also cover a variety of examples, including character level (PTB and Text8), word level (CNN questi",
        "This paper describes a way to speed up convergence through sudden increases of otherwise monotonically decreasing learning rates. Several techniques are presented in a clear way and parameterized method is proposed and evaluated on the CIFAR task. The concept is easy to understand and the authors chose state-of-the-art models to show the performanc",
        "This paper proposes a weakly supervised, end-to-end neural network model for solving a challenging natural language understanding task. \nAs an extension of the Neural Programmer, this work aims at overcoming the ambiguities imposed by natural language. \nBy predefining a set of operations, the model is able to learn the interface between the languag",
        "This paper introduces a 'GPU-friendly' variant of A3C which relaxes some synchronicity constraints in the original A3C algorithm to make it more friendly to a high-throughput GPU device. The analysis of the effects of this added latency is thorough. The systems analysis of the algorithm is extensive. \n\nOne caveat is that the performance figures in ",
        "This paper presents an approach to learn to generate programs. Instead of directly trying to generate the program, the authors propose to train a neural net to estimate a fix set of attributes, which then condition a search procedure. This is an interesting approach, which make sense, as building a generative model of programs is a very complex tas",
        "This paper considers the problem of model-based policy search. The authors \nconsider the use of Bayesian Neural Networks to learn a model of the environment\nand advocate for the $\\alpha$-divergence minimization rather than the more usual \nvariational Bayes. \n\nThe ability of alpha-divergence to capture bi-modality however \ncomes at a price and most ",
        "This paper describes a new way of variable computation, which uses a different number of units depending on the input. This is different from other methods for variable computation that compute over multiple time steps. The idea is clearly presented and the results are shown on LSTMs and GRUs for language modeling and music prediction.\n \n Pros:\n - ",
        "This paper discussses applying an information bottleneck to deep networks using a variational lower bound and reparameterization trick. The paper is well written and the examples are compelling. The paper can be improved with more convincing results on MNIST.",
        "This paper proposes the neural noisy channel model, P(x|y), where (x, y) is a input-to-out sequence pair,  based on the authors' previous work on segment to segment neural transduction (SSNT) model. For the noisy channel model, the key difference from sequence-to-sequence is that the complete sequence y is not observed beforehand. SSNT handles this",
        "This paper builds on the work of Weston (2016), using End-to-end memory network models for a limited form of dialogue with teacher feedback. As the authors state in the comments, it is closely related to the question answering problem with the exception that a teacher provides a response after the model\u2019s answer, which does not always come with a p",
        "This paper extends the GAN framework to allow for latent variables. The observed data set is expanded by drawing latent variables z from a conditional distribution q(z|x). The joint distribution on x,z is then modeled using a joint generator model p(x,z)=p(z)p(x|z).  Both q and p are then trained by trying to fool a discriminator. This constitutes ",
        "This paper introduces a simulator and a set of synthetic tasks for evaluating a dialogue agent's ability to learn from user feedback. For solving these tasks, the paper uses memory networks (Sukhbaatar et al., 2015) learned through previously proposed supervised learning and reinforcement learning methods. In this setup, it is demonstrated that the",
        "This paper proposes a design principle for computation blocks in convolutional networks based on repeated application of expand and join operations resulting in a fractal-like structure. \n\nThis paper is primarily about experimental evaluation, since the objective is to show that a residual formulation is not necessary to obtain good performance, at",
        "This paper studies the energy landscape of the loss function in neural networks.  It is generally clearly written and nicely provides intuitions for the results.  One main contribution is to show that the level sets of the loss becomes connected as the network is increasingly overparameterized.  It also quantifies, in a way, the degree of disconnec",
        "This paper provides a simple method to handle action repetitions. They make the action a tuple (a,x), where a is the action chosen, and x the number of repetitions. Overall they report some improvements over A3C/DDPG, dramatic in some games, moderate in other. The idea seems natural and there is a wealth of experiment to support it.\n\nComments:\n\n- T",
        "This paper proposed a proximal (quasi-) Newton\u2019s method to learn binary DNN. The main contribution is to combine pre-conditioning with binarization in a proximal framework. It is interesting to have a proximal Newton\u2019s method to interpret the different DNN binarization schemes. This gives a new interpretation of existing approaches. However, the th",
        "This paper is a parallel work to Improving Generative Adversarial Networks with Denoising Feature Matching. The main solution of both papers is introducing autoencoder into discriminator to improve the stability and quality of GAN. Different to Denoising Feature Matching, EBGAN uses encoder-decoder instead of denoising only, and use hingle loss to "
    ],
    "sampled": [
        "This paper addresses the problem of disambiguating/linking textual entity\nmentions into a given background knowledge base (in this case, English Wikipedia).\nWe present a framework in which multiple annotators annotate sentences using\na shared vocabulary (a Wikipedia category hierarchy), and demonstrate that\nit not only learns to disambiguate but also resolves the issue of noise when\nthe",
        "This paper presents several weakly supervised methods for developing NERs. The\nmethods focus on using data annotations that are not perfect and can be noisy, but in\naddition, they are able to leverage data annotations that do not directly relate to the\ntraining task. This is opposed to methods that require clean or",
        "This paper describes a rule based approach to time expression extraction. Its main contribution is two-fold: the definition of rules that support the analysis of the expression used to describe a time expression and the generation of a formal expression which represents the time expressed by these expressions. Experimental results show",
        "This paper presents a neural network-based framework for dialogue state\ntracking.\nThe main idea of the proposed approach is that each turn is modeled by two hidden\nstates: one that describes the entire dialogue history, and one describing the current\nturn. Using a neural network architecture based on",
        "This paper proposes a neural network architecture that represent structural\nlinguistic knowledge in a memory network for sequence tagging tasks. In such\narchitecture a memory network with an attention mechanism is employed to represent\nmultiple language processing cues and the connections among them are explicitly modeled\nas a recurrent neural network. Furthermore, the structure",
        "This paper presents a new dataset with annotations of products coming from\nonline cybercrime forums. The paper describes methods, tools and\ntechnologies used to create and enrich the corpus. The resulting\ndataset contains 226,113 products and 468,300 comments that\nacquired by analysis of 369,380 pages (268,989 unique).\nTo extract products and their annotations, the authors apply the\nTextronix MIRT system [1],",
        "This paper introduces UCCA as a target representation for semantic parsing and\nalso describes a general framework for building semantic parsing systems\nby unsupervisedly combining multiple domain-specific parsers. The\nunsupervised learning enables us to combine the best of supervised\nparsers without having to collect large amounts of data with different\ngrammars for each domain. Unsupervised learning is also effective",
        "This paper proposed a macro discourse structure scheme. The authors carried out\na pilot study annotating a corpus consisting of 97 news articles from four major media\norganizations from January to May 2015. Then the authors analyzed some selected\narticles to provide empirical support for the classification. The results",
        "This paper proposes a framework for evaluation of word embeddings based on data\nefficiency measures. We formulate data efficiency of word embeddings as a\nproperty of models, which we compute by maximizing data efficiency under\ncertain distributional regularization, using Lagrangian penalty function. Our\nmethod is based on a linear-scaling Lagrangian approximation of the data\nefficiency function. We test our approach",
        "This paper delves into the mathematical properties of the skip-gram model,\nexplaining the reason for its popularity and examining a few of the\nmany variants of the algorithm used commonly. The Skip-gram model is\nwidely used in deep learning to train an unsupervised language model using\nstatistical regularities in huge amounts of data. It",
        "This paper presents a neural sequence-to-sequence model for encoding dialog\ncontexts. Previous work has demonstrated the benefits that using dialog context\ncould provide to a conversational decoder. However, in many practical\nsettings, dialog context is not available. We present a neural encoding model for\ndialog",
        "This paper compares different ways of inducing embeddings for the task of\npolarised word class generation. Our motivation is that polarised generation is\ncurrently quite a common task, so that we should try to find a method for this\nthat is as efficient as possible, both in terms of training time and size of",
        "This paper presents a purpose-built neural network architecture for textual\nentailment/NLI based on a three step process of encoding, computing similarity, and\nclassifying the similarity relation between two given sentences. The architecture, called CCNRL\n(Compressed Convolutional Similarity Neural Logic), is developed based on our previous work\n(Wang et al. 2017) in",
        "This paper proposes a supervised deep learning model for event factuality\nidentification.  The empirical results show that the model outperforms the existing\nstate-of-the-art supervised deep learning model in FEVER, and the proposed\nmodel also achieves better performance than a sequence to sequence based\nunsupervised model.\nhttps://doi.org/10.2144/S1736-5734/tbss-68309\n2020-A-1-105 (673 KB) PDF\nLiu, Kai; Zhang, Jianan; Huang, Junyi\nKai",
        "This paper presents the gated self-matching network for reading comprehension\nstyle question answering. The gated self-matching network is a recurrent framework that connects\nquestion and answer through a shared vector representation, in which the self-matching\nnetwork replaces the traditional cross attention as the core module for both encoding",
        "This paper investigates the cold-start problem in review spam detection. The\nauthors first qualitatively identify factors that may affect the cold-start problem in\nreview spam detection. Then, a new dataset, with over 2,000 reviews and their\ncorresponding labels, is developed. The authors find that some users exhibit a strong\nspam preference as measured by their",
        "This paper details a method of achieving translation from morphologically\nimpoverished languages (e.g. Chinese) to morphologically rich ones.\nThe method involves creating auxiliary lexical entries to describe\nunassigned or missing morphemes, and translating from these additional\nentries. Preliminary results from an experiment examining the efficiency of\ntwo-way translation from Chinese show",
        "This paper addresses the network embedding problem by introducing a neural\nnetwork model which uses a set of convolutional layers, each followed by\na fully connected layer. These layers generate a low-dimensional mapping which\ngeneralizes features of the high-dimensional data and can be embedded into\na network of neurons. This mapping can then be used to",
        "This paper describes interesting and ambitious work: the automated conversion\nof Universal Dependencies (UD) annotations into a form suitable for use with the\nHippocrates system, an Open Web Application that helps biomedical researchers\nmatch papers to diseases and molecular pathways. We focus on the annotation of\nDiseases and Pathways in order",
        "This paper outlines a method to learn sense embeddings from unannotated corpora\nusing a modularized approach. Given unannotated multilingual data, the author constructs a neural network that predicts the correct part of speech from each text chunk. This is achieved by fine-tuning existing POS taggers on the data from an external",
        "This paper describes a state-of-the-art CCG parsing model that decomposes into\ntagging and dependency scores, and has an efficient learning algorithm. The\ntagging model is a tagged tree with a Hidden Markov Model (HMM) tag\ngenerator for training. Dependency parsing is done by parsing and\naggregating tagged trees with",
        "This paper presents evaluation metrics for lyrics generation exploring the need\nfor the lyrics to be original,but in a similar style to that of the original\nsong. The main evaluation methods are: (1) The Levenshtein distance which\nis also the distance between two sequence, it is used due to the ability to\nmodel similar sequences such as",
        "This paper proposed to explore discourse structure, as defined by Rhetorical\nStructure Theory (RST) to improve text categorization, and to introduce the\nhyponymy relations derived from WordNet as an effective feature extraction\nmethod for text categorization. We examined three major problems: (1) how to\ncompute discourse structure representations; (2) how to incorporate\nhyponymy relations into",
        "This paper proposes joint CTC-attention end-to-end ASR, which utilizes both\nadvantages in training and decoding. We first combine traditional CTC with attention and CTC to capture the correlations among phones for\nimproving recognition accuracy using joint training. Meanwhile, it is proposed\nto integrate attention into model decoding, which can leverage",
        "This paper proposes a method for generating datasets of pictures from simple\nbuilding blocks, as well as a procedure for automatic image description. The\nmethod is based on the building of multiple networks that will jointly\ncombining knowledge from both shape and appearance domains. We generate many\nexamples for each class and train different classifiers based",
        "This paper propose a general framework for analyzing similarities and\ndifferences found in the design of web sites for mobile phones. The\nproject involves a comparative usability analysis of five websites and\napplications targeted at mobile users. The framework presents an\nexplanation of the concepts of usability",
        "This paper modifies existing word embedding algorithms (GloVe, Skip Gram, PPMI,\nSVD) to include ngram-n representations of the input text (i.e. 1-, 2-, 3-, ..., n-grams). In other words, instead of being a bag of words, the text is a\nvector encoded in this new embedding space. We evaluate these variants",
        "This paper investigates the application of distributional vectors of meaning in\ntasks that involve the identification of semantic relations. Specifically, we\ncompare the performances of two vectorial approaches, one based on the most\nfrequently cooccurring terms in texts that belong to a given relation, and the other\ninvolving a measure of semantic relatedness of each document to",
        "This paper describes a straightforward extension to left-to-right beam search\nin order to provide a way to use context sensitive grammars for translating\nfrom a morphologically rich input language into an intermediate, context\nsensitive language where the morphology has been removed.\nHopman H, Favro A\nGrammar-based speech-centric translation of text into TTS\nCambridge, Royal Statistical Society\nProceedings of",
        "This paper introduces a new approach to semantic parsing in which the model is\nequipped with a neural sequence to sequence parser, a symbolic state model,\nand a dynamic Bayesian network. We define a unified framework which\njointly models the parse tree of a sentence composed of symbolic and\nsemantic features. We formulate the sequence to",
        "This paper proposes integrating word sense inventories into existing approaches\nfor the lexical substitution. Specifically, we take the view of the WordNet\ndatabase as a word sense inventory and a lexical substitution using WordNet\nsynsets.\nFujiwara, Atsuyuki\nHongo, Shigeo\nThe 29th Workshop on Japanese Natural Language Processing 62-70, Osaka, Japan, 2008/09.\nThe WordNet database",
        "This paper presents a corpus of annotated essay revisions. \n\nIt includes two examples of application for the corpus, the first being a model for scoring a paper and the second being on a model for improving automated essay scoring.\n\nIt should be noted that all statistics and figures are reported at the",
        "This paper presents a dialogue agent where the belief tracker and the dialogue\nmanager are jointly built for dialogue management. The proposed\nbelief tracker is fully-distributed and exploits asynchronous updates to\nthe beliefs from other agents in the system. Compared with two popular\ndistributional models, the proposed belief-tracking model demonstrates\nstatistically significant improvements on dialogue",
        "This paper presents a new state-of-the-art deep learning model for semantic\nrole labeling (SRL) that is a natural extension of the previous\nwork on the same task. In particular, for the first time, we consider\nextensive linguistic and semantic roles simultaneously, in that we\nformulate the task of SRL as a binary classification problem without\ndistinguishing",
        "This paper describes several ways to encode arbitrarily long sequences of\ndigits using something other than the full complement of 2 raised to\nthe number of bits required over the alphabet chosen to encode the\ndigits. We discuss the basic concept and show that: (1) this concept\ngeneralizes easily to a number of cases arising",
        "This paper presents a gated attention mechanism for machine reading. \nA key idea is to extend Attention Sum Reader (Kadlec et al. 2017) from RNN to CNN for text classification task in a semi-supervised manner. Attention Sum Reader (ASR) is a fully convolutional classifier with an attention mechanism for text classification. Specifically, the",
        "This paper proposes to use an encoder-decoder framework for keyphrase\ngeneration. Experimental results show that the proposed model can generate\nkeyphrases with a better phrase coherence than that of conventional LSTM\n(Recurrent Neural Network) based models.\n2016 IEEE 19th International Conference on Intelligent Computing (ICIC),\nVilamoura, Portugal, IEEE (Ed.), 2016, pp.",
        "This paper continues the line of work for applying word embeddings for the\nproblem of unsupervised morphological segmentation (e.g. Soricut & Och, 2017), thus, allowing automatic segmentation\nof unseen languages. It aims to show the advantages of using embeddings trained\non a small but diverse seed of sentences in different languages instead of using embeddings\nfrom",
        "This paper proposes a simple attention-based RNN model that outperforms traditional Recurrent Neural Networks (RNNs) in automatic speech recognition (ASR) and speaker identification (SID). Our approach combines recurrent and attention-based mechanisms to learn sequential dependencies over both local and distant features, with a single-hidden layer structure but a much",
        "This paper presents a graph-based approach for producing sense-disambiguated\nsynonym sets from a collection of document instances. As illustrated with the\nhelp of an English-Chinese translation example, our proposed approach\nallows sense disambiguated synonym sets to be easily constructed for any\nterm occurring in the set of document instances.\nThe",
        "This paper proposes a joint model of salient phrase selection and discourse\nrelation prediction in spoken meeting recordings, including the interactions\nbetween the two processes. Given the high variability of the two tasks, we\nconduct several experiments by varying the amount of data, the modeling\nframework, and the input and output sizes. Our",
        "This paper proposes a method for building dialogue agents involved in a\nsymmetric collaborative task, in which the agents can give instructions to each other.\nOur method is based on natural logic programs. The task model is first built in a\npre-production phase, and then a dialogue engine is dynamically generated during its\nexecution. To generate a dialogue engine, a",
        "This paper proposes an approach for classifying literal and metaphoric\nadjective-noun pairs. The authors create the initial conditions by means of\ncorpus linguistics methods on the basis of the Penn Paragraphs and Wikipedia\ncorpora. The created contexts, in the form of word-contexts, are represented\nby a set of probability density functions, which serve",
        "This paper proposes a novel strategy for zero-resource translation where\n(source, pivot) and (pivot, target) parallel corpora are available. Our baseline architecture alternates an oracle translation process between (source,pivot) and (pivot,target). This is further extended to incorporate in-domain cross-lingual alignment with the addition of a monolingual (pivot,target) parallel corpus.",
        "This paper considers the problem of KB completion and proposes ITransF for this\npurpose. Translation knowledge bases (TKBs) are key components in large-scale\nKnowledgeBased Interpreter Systems (KBIs), and must be completed in order to provide\nmeaningful language interpretation. ITransF is presented as a complete system for KB\ncompletion by extending the Trans-Ports concept to",
        "This paper presents a method for translating natural language descriptions into\nreferences to relevant, well-known ontologies. Given an ontology language and the\nontologies it supports, such a translation method enables the author of a description to\ninfer which ontologies are relevant to her by only using the ontology vocabulary.\nWe present a method of",
        "This paper focuses on interpreting sarcasm written in Twitter identifying\nsentiment words and then using a machine translation engine to find an\nequivalent not sarcastic tweet. The tweet is identified as sarcastic by\nhaving the opposite sentiment by the sentiment words the tweet contains.\nThe machine translation engine extracts the sentiment words, the word\ncontext and the",
        "This paper describes a system to assist written test scoring.\n\n- Strengths:\nThe paper represents an application of an interesting idea.\n\n- Weaknesses:\nThe idea is limited to the problem of assessing the\ncorrectness of arithmetic calculations. Extending the idea to assessments \nat other, more complex, cognitive levels is probably not straightforward.\n\n- Potential Applications:\nIn order to",
        "This paper introduces new configurations and training objectives, making them available to state-of-the-art neural reinforcement learning methods. The new algorithms are capable of training a model in an off-policy fashion. The new algorithms offer two major improvements over classic Actor-Critic algorithms:\nWe train a model for multiple environments",
        "This paper proposed a new phrasal RNN architecture for sequence to sequence\ngeneration. They have evaluated their architecture based on (i) the language model,\nand (ii) the quality of the training data and trained a model from both datasets using\ncharacter based representations. Then, they compared their model to a",
        "This paper proposes new prediction models for Japanese SRL task by adopting the\nEnglish state-of-the-art predictive processing models inspired by brain. First,\na novel probabilistic model was developed for the prediction by using the\nprobabilistic finite-state machine, which is able to consider the difference\namong the semantic class of a noun phrase. Second, in",
        "This paper develops an LSTM-based model for classifying and estimating the size of a tsunami from seismic signals. Since the LSTM model has been designed to capture the long-term dependence between recurring time-series data, it is more suitable for our task than the CNN-based models for the time-series classification",
        "This paper proposes a method for recognizing lexical entailment (specifically,\nhypernymy, hyponymy, and meronymy) from the dependency parse tree of texts.\nOur method starts from learning a classifier which identifies the dependency edges\nrepresenting entailment relations from the dependency parse tree as well as",
        "This paper proposes a method for evaluating the applicability of using a novel type of a power converter, i.e., a hybrid resonant transformer (HT) based pulse width modulation (PWM) buck converter to an uninterruptable power supply (UPS). By using HT and PWM, a UPS can provide",
        "This paper proposed a very interesting idea of using cognitive features for\nsentiment analysis and sarcasm detection. I think this approach is\nmore realistic since no machine can have the same cognitive features that\nhuman beings possess. Using a lot of features extracted from the sentence\nis a good idea to make the model robust.\nThe",
        "This paper proposes a neural-styled topic model, extending the objective of\nword2vec to also learn the topics of documents. We present a multitask\nobjective for topic modeling as a way of encoding the similarity\nbetween words and topics at training time. At testing, our model\nretrieves words, their topics, and the topic distribution of the\ncorresponding",
        "This paper describes four methods of obtaining multilingual word embeddings and\na modified QVEC metric for evaluating the efficacy of the models for zero resource languages.\nTo demonstrate the efficacy of the methods, we use a multi-domain evaluation task on\nmulti-lingual text classification with 5 language models per task using 4 datasets involving",
        "This paper proposes a method for discovering correspondences between points of interest in two sequences of images.\nThe correspondence detection algorithm is based on the detection of the relative position and motion of a point of interest in two sequences of images. The main contributions of the method are the introduction of",
        "This paper proposes an approach for multi-lingual named entity recognition\nusing features from Wikipedia content. We build on previous work on\nenriching entity names and propose the use of structural constraints\nprovided by Wikipedia's own page structures. To the best of our\nknowledge this is the first time structural constraints of this kind\nare",
        "This paper proposes the new (to my knowledge) step of proposing to treat a\nnumber of sentence pair scoring differences as an outcome variable,\n(1) Sentence pair = word pair\n(2) Word pair = token pair\n(3) Token pair = non-word token pair\nThis can be seen as an application",
        "This paper presents a transition-based graph parser able to cope with the rich\nrepresentations of a semantically typed graphical syntax. We propose a novel\ngeneralized model of transition graphs by proposing to de-regularize the basic\nblock structure. The first two blocks are enriched with so-called\ntransitional rules that allow for",
        "This paper presents a Stack LSTM parser based on the work of Henderson et al.\n(2008, 2013) on joint syntactic/semantic parsing. Our approach is able to jointly integrate various structural, syntactic and semantic features and perform semantic parsing without any pre-existing grammar in a manner which does not require large modifications to the original approach. The",
        "This paper investigates three simple weight-pruning techniques for NMT, and\nan extension (weight pruning with dropout) to further reduce parameters and stabilize learning.\nThese techniques are combined with the LSTM cell, which is expected to perform well in NMT.We experiment with a wide range of models and compare across three",
        "This paper presents results on the UD treebanks to test delexicalized transfer\nparsers and an unsupervised parser which is enriched with external\nprobabilities. The resulting systems exhibit good scores, although\nnot quite high enough to be regarded as conclusive, and also provide\nmuch more insight into the nature of the underlying grammatical\nThe datasets",
        "This paper presents an approach to tag word senses with temporal information\n(i.e. parts of speech, verbal frames, and tense) on the basis of large amounts of\ncorpus data. The approach relies on a corpus-based part-of-speech tagger using\nconditional random fields, and it combines the tagger with a template-based\nframework which computes context-dependent grammatical",
        "This paper models event linking using CNNs. Given event data, the task is to identify which event types occurred and in what frequency. We demonstrate that a novel convolutional architecture, that computes a sparse event-type encoding matrix, allows for effective link discovery. This type of encoding",
        "This paper describes a new deterministic dependency parsing algorithm and gives empirical evidence for its correctness and efficiency. The algorithm provides a full dependency structure, including disambiguation, and computes the probabilities of the dependency parse trees over the underlying treebank. The algorithm can also give a non-negative ranking of the n",
        "This paper improves significantly on prior work on predictive processing in auditory scene analysis by addressing a shortcoming of the original proposal: that it relies on a static and unpredictable model of sensory input. Given the predictiveness of speech signals, one might expect to be better able to extract reliable information about the acoustics",
        "This paper extends an approach to rate-distortion optimization to deep encoders. The approach decomposes the rate-distortion optimization problem into two steps: First, a low resolution representation is computed to reduce bandwidth. Second, the low resolution representation is refined to improve distortion while respecting the fixed bandwidth constraint.",
        "This paper describes a new approach to meta learning by interpreting the SVM (support vector machine) based meta learning method as a form of regularized least square. First we generalize the linear and quadratic loss functions to the class of smooth, continuous loss functions by penalizing their smoothness. Then we show that the non-convex, constrained",
        "I thought I was going to write about",
        "This paper makes a valuable contribution to provide a more clear understanding of the interaction between Islamic values and the public governance in Malaysia. It provides an insightful overview for government leaders to address the issue of value and public governance. From the paper, it clearly shows that Islamic values are an important tool for Malaysian",
        "This paper proposes a way of adding unsupervised auxiliary tasks to a deep RL learning controller to increase the robustness of its behavior. The proposed method does not require explicitly defining these auxiliary tasks, neither requires any manual re-training of the RL agent. The method requires just a small number of additional parameters in addition to the ones",
        "This paper proposed to use RL and RNN to design the architecture of networks for modeling time sequence and to analyze the impact of various factors which related to the prediction time on the prediction of the time sequence model. The architecture of the network is a time sequence with a fixed network structure. For the first prediction point, the input of model is",
        "This paper details the approach that won the VizDoom competition in 2016. Two techniques of the proposed approach were described in our previous paper [19]. In this paper, we present the third method. The combination of all three techniques allows us to predict the future of a player and to generate gameplay AI.\n@inproceedings{Petrushevskiy2016BetterBots,\nauthor",
        "This paper proposes learning on the way to detect if an object is an instrument or a natural one. The way to get this classification is to compute visual saliency with a spatio-temporal algorithm. This representation is used with a Random Forest (RF) for learning. The classification is evaluated in real experiments and is compared with other algorithms using the",
        "This paper proposes to investigate attention-based neural networks, and to answer a certain class of attention-based questions in neuroscience using computational neuroscience methods. Particular interest is on a neural network of the prefrontal cortex of the brain that has been found to exhibit a certain class of",
        "This paper investigates the benefits of visual servoing using a learned\nvisual representation. The authors  propose  a  system,  based  on deep\nreinforcement learning for vision-controlled manufacturing.  This  system\nis  composed  of  a network called a visual agent trained through\nreinforcement learning which",
        "This paper proposes a nonparametric two-step model selection procedure which addresses model instability in a nonlinear time series forecasting framework. The proposed approach enables the user to select the best combination of regressors within the forecasting model, rather than selecting the \u201cbest\u201d model for the series. The procedure is tested in a data-driven setting with the following extensions of",
        "This paper prunes entire groups of filters in CNN so that its parameters size decrease, which directly impacts on filter-set design and training process. In each group we delete a filter, then we evaluate the accuracy and we reduce one of the deleted filter parameters by setting its value as a linear combination of values of other",
        "This paper is well written, and well structured. The only point I make is for the writer to use either US English or British English only (but not combined).\n\"The following paragraphs of this paper will discuss what the U.N. should do to achieve its goals for peace, justice, and security. In",
        "This paper presents an approach for skills transfer from one task to another in a control setting (trained by RL). The basic intuition is to make the action at the current task as similar as possible to a trained action from a previously seen task. In this paper we show that we can utilize both actions from the task that we",
        "This paper proposes a model to learn across different views for a single task.\nDeep multiple kernel learning is widely studied, and there are two main strategies adopted: (1) learning a different kernel for each task(view), and (2) learning a shared kernel to combine the information from each individual view. In this paper, we adopt the second approach, which focuses on learning",
        "This paper proposed a neural attention model which has a learnable and a fixed attention mechanism, to jointly learn both features and interactions on multiple graph attention networks (GAT) to perform text representation learning. The proposed model has a fully differentiable structure for optimizing all attention weights in a unified way, which enhances the model robustness. Moreover,",
        "This paper presents an information theoretic framework to evaluate and compare the performance of the three well-known schemes for transmitting through a fading channel. The average throughput obtained by these schemes is characterized as a function of the time-varying fading channel conditions, including attenuation, the channel's frequency (spacing) between the",
        "This website is operated by the Vanderbilt University Libraries (\u201cVUL\u201d). Throughout the site, the terms \u201cwe\u201d, \u201cus\u201d, and \u201cour\u201d refer to the VUL. We offer this website, and all of the information, tools and services available through this site (collectively, the \u201cwebsite\u201d or \u201cservice\u201d) to you conditional upon your acceptance of all the",
        "This paper not only shows that a cache model on top of a pre-trained RNN can improve the performance of the original RNN on different tasks, but also introduces the concept of a hybrid structure that takes advantage of the power of both RNNs and cache. We experimentally determine which cache structure is ideal for a given application. In addition, we present",
        "This paper proposed a novel adversarial framework to train a model from demonstration. A novel adversarial network is designed to generate adversarial and real samples from same distribution and adversarial pairs are generated for the network to learn the different. Compared with the common training techniques of generating random samples or using different distributions,",
        "This paper combines variational RNN (VRNN) and domain adversarial networks (DANN)\n\\cite{ganin2016domain} to produce a domain-adversarial conditional variational RNN. Inspired by the DANN framework, we propose three losses in the training, which include a class conditional loss, a conditional unconditional loss, and a conditional adversarial loss. In particular, the conditional adversarial loss, which is new, forces the",
        "This paper introduces the method of the adaptive finite element method for solving the partial differential equation of poroelasticity, where the permeability of the rock is considered to vary with the water pressure by the coupled poromechanic theory. This method is applicable to both the cases of incompressible fluids and compressible fluids. As a",
        "This paper provides a principled and practical formulation of the Bayesian optimal design (BOD) in computer experiments. It consists of two parts. The first part is a theoretical analysis, which is based on the notion of the predictive distribution constructed from model-based simulation. The resulting optimal designs are shown to",
        "This paper aims to evaluate the evolution of global warming over the period 1961\u20132015 using a multiseries analysis based on data from six main meteorological station series, four ocean station series, global surface air temperature series, satellite-based gridded series and ocean gridded series.\nFor six",
        "This paper proposed an integration of memory network with reinforcement learning. The memory network with policy gradient based actor-critic model was designed, and an algorithm to improve the learning and generalization of the memory network was proposed. The experimental results on the three large datasets demonstrated the effectiveness of the proposed memory network. The proposed method",
        "This paper presents an integrated approach to estimate the effect of taxes on greenhouse gases (GHG). Such approach would take into account emission estimation methods, costs and tax incidence functions, accounting for household behaviors using an aggregated discrete choice model. In contrast with previous studies, where emission taxes have been taken into account, this research combines",
        "This paper introduces an approach for future frame prediction in videos by decoupling motion perception from trajectory estimation. The approach focuses on the future observation of the objects motion, rather than on their displacement. Based on this concept, motion perception for each object, obtained by a set of simple detectors,",
        "This paper provides an interesting framework for handling semi-supervised RL. It was first introduced in Evolution Strategy by Schmitz (2002) and since then it has been studied in other works such as Guez et al. (2003), Schmidhuber (2010). We reintroduce the RBF algorithm, provide a thorough description of implementation details, and provide more insights into the",
        "This paper proposes a new Bayesian method, GS-EEMV, for generalized sparse estimation of multivariate latent variables (such as states and latent class variables) with additive measurement errors. By adding a Gaussian shrinkage to the prior of the measurement error variance, the new method relaxes the sparsity assumption on $\\mathbf V$ so that the Bayesian analysis for sparsity",
        "\nThis papers adds to the literature on learning optimizers/algorithms that has gained much attention over the last few \\textcolor{black}{years}. \\textcolor{black}{Such} learning can have various benefits and drawbacks, such as enabling new applications and reducing the complexity of reinforcement learning algorithms, by relying on the \\textcolor{black}{expertise obtained during} training. However, it also introduces the possibility of",
        "This paper describes a method to estimate likelihood scores for a range of models of the joint distribution of age at menarche and age at menopause in families (Henderson, 1985). An outline of the MENOP score calculation algorithm is provided and an example of its application is given. Methods are provided for the estimation of variances, variances with",
        "This paper presents new way for compressing the speech signals, taking into account noise estimation of noise-free speech and estimation of total level of speech through noise. In order to compress speech signal using speech signal-to-noise ratio (SNR) model, the total level of the speech signal is estimated in our case through the noise level.",
        "This paper presents a training strategy for deep networks.  First, the network is trained in a standard fashion.  Next, the parameters of the network are fixed and only the final layers are backpropagated.  Finally, the weight tensor is updated by fixing the final layers.  Compared to standard training, the final layer method improves the final accuracy",
        "This paper proposes a new memory module for large scale life-long and one-shot learning. The module is general enough to be applicable in different network architectures, has very limited memory footprint as well as the ability to store training samples in a compressed format, and is able to operate at high speeds for efficient training.",
        "This paper presents a clear hierarchical taxonomy of transfer learning methods as applicable to text classification tasks within the information retrieval framework. The taxonomy provides a principled approach for assessment of approaches currently and potentially important in text classification. The taxonomy can be used to examine similarities between and relationships between different transfer learning",
        "This paper proposes a new gating mechanism to combine word and character representations. The proposed model sets a new state-of-the-art in the character-level bi-granular modeling. Our gating model is a multi-head attention mechanism between the word-level and character-level representation in the embedding space. The character-level context vectors are enhanced by the word-level",
        "This paper performs a very important service: exploring in a clear and systematic way the performance of four financial sector reforms \u2013 the abolition of exchange controls, the removal of price controls on international reserves, the establishment of new banking regulations, and the introduction of financial sector transparency \u2013 to see what impact they had on the",
        "This paper addresses one of the major shortcomings of generative adversarial networks - their lack of diversity - and introduces a novel, non-gradient-free algorithm to solve this problem. In our work, diversity is not only the number of distinct samples, but a broader notion of diversity: novelty. We study three variants of novel loss which,",
        "This paper presents a novel way of pruning filters from convolutional neural networks using a multi-armed bandit paradigm in the framework of active structured output model. An active structured learning problem is formulated through a non-parametric multi-armed bandit framework with structural constraints and a constrained bandit function. With the assistance of this formulation, the filters",
        "This paper provides two approaches to question answering: pointing to spans, and use of match-LSTM.\n\n## Citation\n[![Citations](https://gephi.github.io/badges/c-bar-b.svg?style=style-1&c=19)](https://scholar.google.com/scholar?start=10&num=10&q=%22This+paper+provides+two+approaches+to+question+answering%3A+pointing+to+spans%2C+and+use+of+match-LSTM.%22&hl=en&as_sdt=0%26)\n\n## 1. Introduction\nThere are various aspects to question answering that are considered more important \nthan others. For",
        "This paper proposes a modification of the parametric texture synthesis model of Gatys et al. to take into account long-term coherent motion. To do so, two additional models have been added to the synthesis component to address blurry motion information and to take advantage of the motion of the background. The result of this new architecture",
        "This paper proposed a dynamic coattention network for the question answering task with long contextual documents. \nThe model takes a dynamic coattention network to model the document sequence and takes a convolution operation with coattention to extract sentence features. The model jointly learns both sentence representation and document representation. It is worth",
        "Home Members > Jesse Fletcher >\nJesse Fletcher New Member\nMostly Fiction & Non-Fiction\n100 - 250 Hours, Under 100 Hours, Over 500 Hours, 500 - 1,000 Hours, 1,000 - 4,000 Hours,",
        "This paper optimizes autoencoders for lossy image compression. Minimal adaptation of the loss makes autoencoders work as robust lossy image compression techniques. Loss-based automatic compression/decompression by autoencoders is demonstrated. It shows a simple and very efficient method for lossy compression of digital images. Image quality in the compressed domain",
        "This paper tests zoneout against a variety of datasets - character level, word level, and penn treebank level - by applying the data to generate a set of features.\nThe feature set is generated by simply taking a word as a feature. It is tested against different measures of text quality and is compared",
        "This paper motivates the combination of autoregressive models with Variational Auto-Encoders and how to control the amount the amount of information stored in the latent code. The authors are interested in models that work well when used in small environments: the first half of the paper discusses the problem and how to attack it",
        "This paper proposes a method for significantly increasing the number of parameters in a single layer while keeping computation in par with (or even less than) that required for a standard neural network. We explore two types of nonlinear transformations: linear and local. The key features of the latter, which we call the Dense Neural Tangent Kernel (DNTK), are the introduction",
        "This paper discusses Hyperband, an extension of successive halving by Jamieson & Talwalkar (AISTATS\u20192017). Hyperband adapts the standard successive halving by proposing that the search begins with a larger population, and that at every step the population size shrinks by a smaller factor. While standard meta-optimizers use a geometric sequence (i.e., the original",
        "This paper introduces the Quasi-Recurrent Neural Network (QRNN) that dramatically limits the computational burden in the network training to the level of a single example per network instance, without limiting its ability to discover complex, recurrent concepts that are common in many real-life applications. However, there are several",
        "This paper explores ensemble optimisation in the context of policy-gradient training. Ensemble training has shown to improve generalisation performance by incorporating noise into learning processes and thus exploring the manifold of model space. We study a set of ensemble optimisation methods for policy gradient. We demonstrate that although some techniques provide benefits, the effect",
        "This paper studies the problem of transferring solutions of multi-component chemical reactions from an enabling, solvent-free medium [1\u20133] to an externally-facing, solvent-rich reaction front. Based on detailed, multi-scale simulations using a reduced chemical kinetic model, the relative ease and rates of transferring chemical reactions from the air phase to the liquid phase",
        "This paper proposes an approach to learning word vector representations for character sequences and their variants where each character is represented as an artificial neuron, i.e., word2vec algorithm with artificial neurons. The proposed algorithm, called artificial neuron word2vec (ANW2V), is based on the idea of character sequence and its variants\u2019 word2vec algorithms to capture longterm",
        "This paper introduces MusicNet, a new dataset. Application of ML techniques to music have been gaining popularity in recent years due to the rapid development of computing power and increased access to large amounts of data; however, most computational music research is limited to relatively small samples of music due to the difficulty of",
        "This paper applies REINFORCE to learn MCMC proposals within the existing STOKE scheme for super-optimization. It's novelty lies in the possibility that the policy updates become more data driven as data converges. Furthermore, a multi-task version of STOKE is presented which shows promising potential for model-based reinforcement learning. The paper is part of",
        "This paper presented a method of improving the efficiency of deep networks acting on irregularly sampled data for time series applications, without altering the structure of existing models with untangleable parameters.\nMany applications such as machine noise prediction, temperature or load forecasting, and stock market prediction use time sequences to estimate unknown features. This necessitates time series",
        "This paper applies the idea of normalizing flows (NFs), which allows us to build complex densities with tractable likelihoods, to the problem of clustering the coordinates of a data set into two clusters each of different shape. It allows us to model the joint density of data by factorizing it into two conditional Gaussians that",
        "This paper focusses on attention for neural language modeling and has two main tasks: 1) Improving the existing encoder to better represent the input; 2) Improving the attention mechanism to make it more useful for training.\nEncoder Modelling:\nThey propose to augment their model with extra attention layers. That is, after the sequence to matrix transformation, they",
        "This paper is a by-the-numbers extension of the hidden semi-Markov model to include nonlinear observations, which can be used to develop and compare learning algorithms. This nonlinear extension allows models to deal with problems where the conditional density is not separable, and also models can not work directly. A new method was built for",
        "This paper presents a variational inference based method for learning nonlinear dynamical models. Two inference methods, based on the gradient of the likelihood function, are proposed: a standard gradient-based approach that requires a second-order approximation of the covariance between latent state and observation vectors in the variational posterior distribution, and a recently",
        "This paper first discusses a general framework for improving optimization of a continuous-time system. The discussion centers on the concept of dynamic modeling of the system including optimization. A simple modeling framework is presented including assumptions and conditions under which the proposed modeling framework is viable. An example of a discrete-time model for an",
        "This paper extends preceding works to create a mapping between the word embedding space of two languages. We start by presenting an embedding model, which uses different features than the typical word embedding methods. The model is applied to two large databases. In the first experiment, a dictionary file containing about over two million tokens",
        "This paper proposes to learn decomposition of sequences (such as words) for speech recognition. It addresses the problem of predicting future words in an active learning (AL) framework. In these methods, a user specifies an initial list of candidate labels for the dataset, and a sequential decision algorithm decides which examples it wishes for an active classifier to",
        "This paper is technically sound. It highlights well the strengths and weaknesses of the proposed simplified analysis, and I believe that we should adopt a similar approach for the BLESS analysis.\nThis paper is great. We really appreciate the comment. We will try to address all your comments as far as as we can.\nLine 131-132: Please also",
        "This paper shows how policy gradient and Q-Learning may be combined together, improving learning speed and efficiency. The algorithm presented is inspired by the paper \"Priority Sampling for the Asynchronous-Q-Learning Algorithm\" by Yash K. Kapila. It combines the ideas of the Q-Learning algorithm and policy gradient algorithm, to present a novel method of optimising a",
        "This paper clearly lays out the recipe for a family of invertible density models, explores a few extensions and demonstrates the wide variety of useful estimators for the model parameters. The estimators include parametric and semiparametric forms, that is, using a small number of model parameters and a large number of data points, respectively. This paper also makes",
        "This paper extends batch normalization successfully to RNNs where batch normalization has previously failed or done with great success under some special conditions. The new approach combines the use of an explicit memory buffer with a novel recurrent mechanism, so that large batches can be accommodated while also leveraging the temporal",
        "This paper describes a way to speed up convergence through sudden increases of otherwise monotonically decreasing values of $\\alpha$ in gradient-based learning. It works by increasing $\\alpha$ so much that it causes a sudden switch to the higher order terms, allowing for more significant jumps as $\\alpha$ approaches $0$. This has the additional",
        "This paper proposes a weakly supervised, end-to-end neural network model for solving a challenging natural language understanding task: question answering. On real-world datasets, such as TriviaQA and Natural Questions, the data distributions are highly imbalanced and difficult to model using end-to-end multi-task learning methods that learn to perform multiple tasks jointly (e.g., word",
        "This paper introduces a 'GPU-friendly' variant of A3C which relaxes some synchronicity constraints in the original algorithm for the purpose of reducing the GPU time-per-iteration. Our approach employs a novel design which reduces the GPU time at the expense of a small latency accumulator buffer (SLA) and a synchronous back-propagation barrier (SBB). From a computational perspective",
        "This paper presents an approach to learn to generate programs. Instead of directly generating programs, we learn a transformation to a more concise intermediate representation based on a training set of input programs and their transformations. Training is then done by imitation learning. We focus on the simplest type of transformations: copy-and-paste with the help of a program template.",
        "This paper considers the problem of model-based policy search. The authors \nconsider the use of Bayesian Neural Networks to learn a model of the environment. A new\nmethod is developed for learning an MDP representation from a set of examples. An\nimitation learning algorithm is used to guide the agent towards the goal states.",
        "This paper describes a new way of variable computation, which uses a different number of units depending on the number of variables. The computational power is increased in general. The number of variables is assumed to be finite. An additional condition is introduced to reduce the risk of confusion. The conditions for when to perform binary operations are described.",
        "This paper presents a systematic approach to analyze and optimize an industrial robotic process line with regard to the application of force control, a technology that promises to enhance the performance and flexibility of industrial robots. We present a",
        "This paper proposes the neural noisy channel model, P(x|y), where (x, y) is a input-to-out sequence pair, \u03c7(i), is the non-Gaussian noise sequence. The probability density function (PDF) of (x, y) could be approximated by a mixture with a Gaussian for the mean sequence and for all others, either or noisy channel model. The probability",
        "This paper builds on the work of Weston (2016), using End-to-end memory network (EMN) models to explore their usefulness in the field of language documentation in a specific case study of one of the two U. We have two research aims: to extend the findings from Weston (2016) in a more empirical direction; and to compare EMN models to established",
        "This paper extends the GAN framework to allow for latent variables. The observed data set is expanded by drawing latent variables z from a conditional distribution q(z|x). The mean of the distribution q(x|z) is computed for each z, and each of these means is used to estimate the likelihood of the full distribution q(x). Experiments on generating synthetic",
        "This paper introduces a simulator and a set of synthetic tasks for evaluating a dialogue agent's ability to understand the goals of its human partner in a natural conversation. This is to the best of our knowledge, the first such system that can be shown to work with ordinary English sentences.\nThe synthetic task",
        "This paper proposes a design principle for computation blocks in convolutional neural networks that enables a computation block to be reused by other computation blocks. We call this reusable computation block Reusable Computation (RC) blocks herein. We consider a special type of reusable computation blocks, i.e., the Reusable Computation Unit (RCU).",
        "This paper studies the energy landscape of the loss function in neural networks.  It is generally believed that any smooth loss function has a smooth gradient but I show that this is false, even if the gradients are finite. This has important consequences for training neural networks. It introduces a notion of a gradient vector at the loss",
        "This paper provides a simple method to handle action repetitions. They make the action a tuple (a,x), where a is the action chosen, and x the number of repetitions. The method is presented in detail, and some applications are illustrated. Two main uses are: i) if we have two competing models for an action a, the probability of",
        "This paper proposed a proximal (quasi-) Newton\u2019s method to learn binary DNN. The main contribution of this paper is to incorporate information-seeking mechanism and reduce the complexity of gradient computation. We showed our proposed method significantly outperformed existing approaches.\nThis paper proposes a joint training framework of generative adversarial networks and discriminative model.",
        "This paper is a parallel work to Improving Generative Adversarial Networks with Denoising Feature Matching. The main solution of both papers is introducing per-channel discriminators, but here we will make a critical analysis of the proposed approach to show where it fails at being truly useful.\nGenerative modeling problems (GANs,VAEs, etc) are an"
    ]
}