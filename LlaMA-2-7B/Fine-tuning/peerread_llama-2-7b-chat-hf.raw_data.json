{
    "original": [
        "This paper addresses the problem of disambiguating/linking textual entity\nmentions into a given background knowledge base (in this case, English\nWikipedia).  (Its title and introduction are a little overblown/misleading,\nsince there is a lot more to bridging text and knowledge than the EDL task, but\nEDL is a core part of the overall task nonetheles",
        "This paper presents several weakly supervised methods for developing NERs. The\nmethods rely on some form of projection from English into another language. The\noverall approach is not new and the individual methods proposed are\nimprovements of existing methods. For an ACL paper I would have expected more\nnovel approaches.\n\nOne of the contributions o",
        "This paper describes a rule based approach to time expression extraction. Its\nkey insights are time expressions typically are short and contain at least 1\ntime token. It first recognizes the time token through a combination of\ndictionary lookup, regular expression match with POS tagging information. It\nthen expands the time segment from either dire",
        "This paper presents a neural network-based framework for dialogue state\ntracking.\nThe main contribution of this work is on learning representations of user\nutterances, system outputs, and also ontology entries, all of which are based\non pre-trained word vectors.\nParticularly for the utterance representation, the authors compared two\ndifferent neura",
        "This paper proposes a neural network architecture that represent structural\nlinguistic knowledge in a memory network for sequence tagging tasks (in\nparticular, slot-filling of the natural language understanding unit in\nconversation systems). Substructures (e.g. a node in the parse tree) is encoded\nas a vector (a memory slot) and a weighted sum of t",
        "This paper presents a new dataset with annotations of products coming from\nonline cybercrime forums. The paper is clear and well-written and the\nexperiments are good. Every hypothesis is tested and compared to each other.\n\nHowever, I do have some concerns about the paper:\n\n1. The authors took the liberty to change the font size and the line spacing",
        "This paper introduces UCCA as a target representation for semantic parsing and\nalso describes a quite successful transition-based parser for inference into\nthat representation. I liked this paper a lot. I believe there is a lot of\nvalue simply in the introduction of UCCA (not new, but I believe relatively new\nto this community), which has the poten",
        "This paper proposed a macro discourse structure scheme. The authors carried out\na pilot study annotating a corpus consisting of 97 news articles from Chinese\ntreebank 8.0. They then built a model to recognize the primary-secondary\nrelations and 5 discourse relations (joint, elaboration, sequence, background,\ncause-result) in this corpus.\n\nThe paper",
        "This paper proposes a framework for evaluation of word embeddings based on data\nefficiency and simple supervised tasks. The main motivation is that word\nembeddings are generally used in a transfer learning setting, where evaluation\nis done based on how faster is to train a target model. The approach uses a set\nof simple tasks evaluated in a supervi",
        "This paper delves into the mathematical properties of the skip-gram model,\nexplaining the reason for its success on the analogy task and for the general\nsuperiority of additive composition models. It also establishes a link between\nskip-gram and Sufficient Dimensionality Reduction.\n\nI liked the focus of this paper on explaining the properties of sk",
        "This paper presents a neural sequence-to-sequence model for encoding dialog\ncontexts followed by decoding system responses in open-domain conversations.\nThe authors introduced conditional variational autoencoder (CVAE) which is a\ndeep neural network-based generative model to learn the latent variables for\ndescribing responses conditioning dialog co",
        "This paper compares different ways of inducing embeddings for the task of\npolarity classification. The authors focus on different types of corpora and\nfind that not necessarily the largest corpus provides the most appropriate\nembeddings for their particular task but it is more effective to consider a\ncorpus (or subcorpus) in which a higher concentr",
        "This paper presents a purpose-built neural network architecture for textual\nentailment/NLI based on a three step process of encoding, attention-based\nmatching, and aggregation. The model has two variants, one based on TreeRNNs\nand the other based on sequential BiLSTMs. The sequential model outperforms all\npublished results, and an ensemble with the",
        "This paper proposes a supervised deep learning model for event factuality\nidentification.  The empirical results show that the model outperforms\nstate-of-the-art systems on the FactBank corpus, particularly in three classes\n(CT-, PR+ and PS+).  The main contribution of the paper is the proposal of an\nattention-based two-step deep neural model for e",
        "This paper presents the gated self-matching network for reading comprehension\nstyle question answering. There are three key components in the solution: \n\n(a) The paper introduces the gated attention-based recurrent network to obtain\nthe question-aware representation for the passage. Here, the paper adds an\nadditional gate to attention-based recurre",
        "This paper investigates the cold-start problem in review spam detection. The\nauthors first qualitatively and quantitatively analyze the cold-start problem.\nThey observe that there is no enough prior data from a new user in this\nrealistic scenario. The traditional features fail to help to identify review\nspam. Instead, they turn to rely on the abund",
        "This paper details a method of achieving translation from morphologically\nimpoverished languages (e.g. Chinese) to morphologically rich ones (e.g.\nSpanish) in a two-step process. First, a system translates into a simplified\nversion of the target language. Second, a system chooses morphological features\nfor each generated target word, and inflects t",
        "This paper addresses the network embedding problem by introducing a neural\nnetwork model which uses both the network structure and associated text on the\nnodes, with an attention model to vary the textual representation based on the\ntext of the neighboring nodes.\n\n- Strengths:\n\nThe model leverages both the network and the text to construct the late",
        "This paper describes interesting and ambitious work: the automated conversion\nof Universal Dependency grammar structures into [what the paper calls] semantic\nlogical form representations.  In essence, each UD construct is assigned a\ntarget construction in logical form, and a procedure is defined to effect the\nconversion, working \u2018inside-out\u2019 using ",
        "This paper outlines a method to learn sense embeddings from unannotated corpora\nusing a modular sense selection and representation process. The learning is\nachieved by a message passing scheme between the two modules that is cast as a\nreinforcement learning problem by the authors.\n\n- Strengths:\n\nThe paper is generally well written, presents most of",
        "This paper describes a state-of-the-art CCG parsing model that decomposes into\ntagging and dependency scores, and has an efficient A* decoding algorithm.\nInterestingly, the paper slightly outperforms Lee et al. (2016)'s more\nexpressive global parsing model, presumably because this factorization makes\nlearning easier. It's great that they also repor",
        "This paper presents evaluation metrics for lyrics generation exploring the need\nfor the lyrics to be original,but in a similar style to an artist whilst being\nfluent and co-herent. The paper is well written and the motivation for the\nmetrics are well explained.  \n\nThe authors describe both hand annotated metrics (fluency, co-herence and\nmatch) and ",
        "This paper proposed to explore discourse structure, as defined by Rhetorical\nStructure Theory (RST) to improve text categorization. A RNN with attention\nmechanism is employed to compute a representation of text. The experiments on\nvarious of dataset shows the effectiveness of the proposed method. Below are my\ncomments:\n\n(1) From Table 2, it shows t",
        "This paper proposes joint CTC-attention end-to-end ASR, which utilizes both\nadvantages in training and decoding. \n\n- Strengths:\nIt provides a solid work of hybrid CTC-attention framework in training and\ndecoding, and the experimental results showed that the proposed method could\nprovide an improvement in Japanese CSJ and Mandarin Chinese telephone ",
        "This paper proposes a method for generating datasets of pictures from simple\nbuilding blocks, as well as corresponding logical forms and language\ndescriptions.\nThe goal seems to be to have a method where the complexity of pictures and\ncorresponding desciptions can be controlled and parametrized. \n\n - The biggest downside seems to be that the maxima",
        "This paper propose a general framework for analyzing similarities and\ndifferences in term meaning and representation in different contexts.\n\n- Strengths:\n* The framework proposed in this paper is generalizable and can be applied to\ndifferent applications, and accommodate difference notation of context,\ndifferent similarity functions, different type",
        "This paper modifies existing word embedding algorithms (GloVe, Skip Gram, PPMI,\nSVD) to include ngram-ngram cooccurance statistics. To deal with the large\ncomputational costs of storing such expensive matrices, the authors propose an\nalgorithm that uses two different strategies to collect counts.  \n\n- Strengths:\n\n* The proposed work seems like a na",
        "This paper investigates the application of distributional vectors of meaning in\ntasks that involve the identification of semantic relations, similar to the\nanalogical reasoning task of Mikolov et al. (2013): Given an expression of the\nform \u201cX is for France what London is for the UK\u201d, X can be approximated by\nthe simple vector arithmetic operation L",
        "This paper describes a straightforward extension to left-to-right beam search\nin order to allow it to incorporate lexical constraints in the form of word\nsequences that must appear in MT output. This algorithm is shown to be\neffective for interactive translation and domain adaptation.\n\nAlthough the proposed extension is very simple, I think the pap",
        "This paper introduces a new approach to semantic parsing in which the model is\nequipped with a neural sequence to sequence (seq2seq) model (referred to as the\n\u201cprogrammer\u201d) which encodes a natural language question and produces a\nprogram. The programmer is also equipped with a \u2018key variable\u2019 memory\ncomponent which stores (a) entities in the questio",
        "This paper proposes integrating word sense inventories into existing approaches\nfor the lexical substitution task by using these inventories to filter\ncandidates. To do so, the authors first propose a metric to measure the mutual\nsubstitutability of sense inventories with human judgments for the lexsub task,\nand empirically measure the substitutabi",
        "This paper presents a corpus of annotated essay revisions. \n\nIt includes two examples of application for the corpus:\n\n1) Student Revision Behavior Analysis and 2) Automatic Revision Identification\n\nThe latter is essentially a text classification task using an SVM classifier\nand a variety of features. The authors state that the corpus will be freely",
        "This paper presents a dialogue agent where the belief tracker and the dialogue\nmanager are jointly optimised using the reinforce algorithm. It learns from\ninteraction with a user simulator. There are two training phases. The first is\nan imitation learning phase where the system is initialised using supervising\nlearning from a rule-based model. Then",
        "This paper presents a new state-of-the-art deep learning model for semantic\nrole labeling (SRL) that is a natural extension of the previous\nstate-of-the-art system (Zhou and Xu, 2015) with recent best practices for\ninitialization and regularization in the deep learning literature.\nThe model gives a 10% relative error reduction which is a big gain o",
        "This paper describes several ways to encode arbitrarily long sequences of\ndigits using something called the major system. In the major system, each digit\nis mapped to one or more characters representing consonantal phonemes; the\npossible mappings between digit and phoneme are predefined. The output of an\nencoding is typically a sequence of words co",
        "This paper presents a gated attention mechanism for machine reading. \nA key idea is to extend Attention Sum Reader (Kadlec et al. 2016) to multi-hop\nreasoning by fine-grained gated filter. \nIt's interesting and intuitive for machine reading. \nI like the idea along with significant improvement on benchmark datasets, but\nalso have major concerns to g",
        "This paper proposes to use an encoder-decoder framework for keyphrase\ngeneration. Experimental results show that the proposed model outperforms other\nbaselines if supervised data is available.\n\n- Strengths:\nThe paper is well-organized and easy to follow (the intuition of the proposed\nmethod is clear). It includes enough details to replicate experim",
        "This paper continues the line of work for applying word embeddings for the\nproblem of unsupervised morphological segmentation (e.g. Soricut & Och, 2015;\n\u00dcst\u00fcn & Can, 2016). The proposed method, MORSE, applies a local optimization\nfor segmentation of each word, based on a set of orthographic and semantic\nrules and a few heuristic threshold values as",
        "This paper proposes a simple attention-based RNN model for generating SQL\nqueries from natural language without any intermediate representation. Towards\nthis end they employ a data augmentation approach where more data is\niteratively collected from crowd annotation, based on user feedback on how well\nthe SQL queries produced by the model do. Result",
        "This paper presents a graph-based approach for producing sense-disambiguated\nsynonym sets from a collection of undisambiguated synonym sets.  The authors\nevaluate their approach by inducing these synonym sets from Wiktionary and from\na collection of Russian dictionaries, and then comparing pairwise synonymy\nrelations (using precision, recall, and F",
        "This paper proposes a joint model of salient phrase selection and discourse\nrelation prediction in spoken meeting. Experiments using meeting corpora show\nthat the proposed model has higher performance than the SVM-based classifier.\n\n- Strengths:\nThe paper is written to be easy to read. Technical details are described fully,\nand high performance is ",
        "This paper proposes a method for building dialogue agents involved in a\nsymmetric collaborative task, in which the agents need to strategically\ncommunicate to achieve a common goal.  \n\nI do like this paper.  I am very interested in how much data-driven techniques\ncan be used for dialogue management.  However, I am concerned that the approach\nthat t",
        "This paper proposes an approach for classifying literal and metaphoric\nadjective-noun pairs. The authors create a word-context matrix for adjectives\nand nouns where each element of the matrix is the PMI score. They then use\ndifferent methods for selecting dimensions of this matrix to represent each\nnoun/adjective as a vector. The geometric properti",
        "This paper proposes a novel strategy for zero-resource translation where\n(source, pivot) and (pivot, target) parallel corpora are available. A teacher\nmodel for p(target|pivot) is first trained on the (pivot, target) corpus, then\na student model for p(target|source) is trained to minimize relative entropy\nwith respect to the teacher on the (source,",
        "This paper considers the problem of KB completion and proposes ITransF for this\npurpose. Unlike STransE that assigns each relation an independent matrix, this\npaper proposes to share the parameters between different relations. A model is\nproposed where a tensor D is constructed that contains various relational\nmatrices as its slices and a selection",
        "This paper presents a method for translating natural language descriptions into\nsource code via a model constrained by the grammar of the programming language\nof the source code.  I liked this paper - it's well written, addresses a hard\nand interesting problem by taking advantage of inherent constraints, and shows\nsignificant performance improvemen",
        "This paper focuses on interpreting sarcasm written in Twitter identifying\nsentiment words and then using a machine translation engine to find an\nequivalent not sarcastic tweet. \n\nEDIT: Thank you for your answers, I appreaciate it. I added one line commenting\nabout it.\n\n- Strengths:\n\nAmong the positive aspects of your work, I would like to mention t",
        "This paper describes a system to assist written test scoring.\n\n- Strengths:\nThe paper represents an application of an interesting NLP problem --\nrecognizing textual entailment -- to an important task -- written test scoring.\n\n- Weaknesses:\nThere isn't anything novel in the paper. It consist of an application of an\nexisting technology to a known pro",
        "This paper introduces new configurations and training objectives for neural\nsequence models in a multi-task setting. As the authors describe well, the\nmulti-task setting is important because some tasks have shared information\nand in some scenarios learning many tasks can improve overall performance.\n\nThe methods section is relatively clear and logi",
        "This paper proposed a new phrasal RNN architecture for sequence to sequence\ngeneration. They have evaluated their architecture based on (i) the language\nmodelling test evaluated on PTB and FBIS and (ii) Chinese-English machine\ntranslation task on NIST MT02-08 evaluation sets. The phrasal RNN (pRNN)\narchitecture is achieved by generating subnetworks",
        "This paper proposes new prediction models for Japanese SRL task by adopting the\nEnglish state-of-the-art model of (Zhou and Xu, 2015).\nThe authors also extend the model by applying the framework of Grid-RNNs in\norder to handle the interactions between the arguments of multiple predicates.\n\nThe evaluation is performed on the well-known benchmark dat",
        "This paper develops an LSTM-based model for classifying connective uses for\nwhether they indicate that a causal relation was intended. The guiding idea is\nthat the expression of causal relations is extremely diverse and thus not\namenable to syntactic treatment, and that the more abstract representations\ndelivered by neural models are therefore more",
        "This paper proposes a method for recognizing lexical entailment (specifically,\nhypernymy) in context. The proposed method represents each context by\naveraging, min-pooling, and max-pooling its word embeddings. These\nrepresentations are combined with the target word's embedding via element-wise\nmultiplication. The in-context representation of the le",
        "This paper proposes a method for evaluating topic quality based on using word\nembeddings to calculate similarity (either directly or indirectly via matrix\nfactorisation), achieving impressive results over standard datasets.\n\nThe proposed method represents a natural but important next step in the\nevolutionary path of research on topic evaluation. Th",
        "This paper proposed a very interesting idea of using cognitive features for\nsentiment analysis and sarcasm detection. More specifically, the eye-movement\npatterns of human annotators are recorded to derive a new set of features. The\nauthors claim that this is the first work to include cognitive features into\nthe NLP community. \n\nStrength: \n1. The p",
        "This paper proposes a neural-styled topic model, extending the objective of\nword2vec to also learn document embeddings, which it then constrains through\nsparsification, hence mimicking the output of a topic model.\n\nI really liked the model that the authors proposed, and found the examples\npresented by the authors to be highly promising. What was re",
        "This paper describes four methods of obtaining multilingual word embeddings and\na modified QVEC metric for evaluating the efficacy of these embeddings. The\nembedding methods are: \n\n(1) multiCluster : Uses a dictionary to map words to multilingual clusters.\nCluster embeddings are then obtained which serve as embeddings for the words\nthat reside in e",
        "This paper proposes a method for discovering correspondences between languages\nbased on MDL. The author model correspondences between words sharing the same\nmeaning in a number of Slavic languages. They develop codes for rules that\nmatch substrings in two or more languages and formulate an MDL objective that\nbalances the description of the model an",
        "This paper proposes an approach for multi-lingual named entity recognition\nusing features from Wikipedia. By relying on a cross-lingual Wikifier, it\nidentifies English Wikipedia articles for phrases in a target language and uses\nfeatures based on the wikipedia entry. Experiments show that this new feature\nhelps not only in the monolingual case, but",
        "This paper proposes the new (to my knowledge) step of proposing to treat a\nnumber of sentence pair scoring tasks (e.g. Answer Set Scoring, RTE,\nParaphrasing,\namong others) as instances of a more general task of understanding semantic\nrelations\nbetween two sentences. Furthermore, they investigate the potential of learning\ngenerally-\napplicable neura",
        "This paper presents a transition-based graph parser able to cope with the rich\nrepresentations of a semantico-cognitive annotation scheme, instantiated in the\nUCCA corpora. The authors start first by exposing what, according to them,\nshould cover a semantic-based annotation scheme: (i) being graph-based\n(possibility for a token/node of having multi",
        "This paper presents a Stack LSTM parser based on the work of Henderson et al.\n(2008, 2013) on joint syntactic/semantic transition-based parsing and Dyer et\nal. (2015) on stack LSTM syntactic parsing. The use of the transition system\nfrom the former and the stack LSTM from the latter shows interesting results\ncompared to the joint systems on the CoN",
        "This paper investigates three simple weight-pruning techniques for NMT, and\nshows that pruning weights based on magnitude works best, and that retraining\nafter pruning can recover original performance, even with fairly severe\npruning.\n\nThe main strength of paper is that the technique is very straightforward and\nthe results are good. It\u00e2\u0080\u0099s also cle",
        "This paper presents results on the UD treebanks to test delexicalized transfer\nparsers and an unsupervised parser which is enriched with external\nprobabilities.\n\nThe paper is interesting, but I think it could be improved further.\n\n(5.2) \"McDonald et al. (2011) presented 61.7% of averaged accuracy over 8\nlanguages. On the same languages, our transfe",
        "This paper presents an approach to tag word senses with temporal information\n(past, present, future or atemporal). They model the problem using a\ngraph-based semi-supervised classification algorithm that allows to combine\nitem specific information - such as the presence of some temporal indicators in\nthe glosses - and the structure of Wordnet - tha",
        "This paper models event linking using CNNs. Given event mentions, the authors\ngenerate vector representations based on word embeddings passed through a CNN\nand followed by max-pooling. They also concatenate the resulting\nrepresentations with several word embeddings around the mention. Together with\ncertain pairwise features, they produce a vector o",
        "This paper describes a new deterministic dependency parsing algorithm and\nanalyses its behaviour across a range of languages.\nThe core of the algorithm is a set of rules defining permitted dependencies\nbased on POS tags.\nThe algorithm starts by ranking words using a slightly biased PageRank over a\ngraph with edges defined by the permitted dependenc",
        "This paper improves significantly upon the original NPI work, showing that the model generalizes far better when trained on traces in recursive form. The authors show better sample complexity and generalization results for addition and bubblesort programs, and add two new and more interesting tasks - topological sort and quicksort (added based on r",
        "This paper extends an approach to rate-distortion optimization to deep encoders and decoders, and from a simple entropy encoding scheme to adaptive entropy coding. In addition, the paper discusses the approach\u2019s relationship to variational autoencoders.\n\nGiven that the approach to rate-distortion optimization has already been published, the novelty",
        "This paper describes a new approach to meta learning by interpreting the SGD update rule as gated recurrent model with trainable parameters. The idea is original and important for research related to transfer learning. The paper has a clear structure, but clarity could be improved at some points.\n\nPros:\n\n- An interesting and feasible approach to me",
        "This paper was submitted to arXiv last week:\n\n",
        "This paper makes a valuable contribution to provide a more clear understanding of generative adversarial network (GAN) training procedure. \n\nWith the new insight of the training dynamics of GAN, as well as its variant, the authors reveal the reason that why the gradient is either vanishing in original GAN or unstable in its variant. More importantl",
        "This paper proposes a way of adding unsupervised auxiliary tasks to a deep RL agent like A3C. Authors propose a bunch of auxiliary control tasks and auxiliary reward tasks and evaluate the agent in Labyrinth and Atari. Proposed UNREAL agent performs significantly better than A3C and also learns faster. This is definitely a good contribution to the ",
        "This paper proposed to use RL and RNN to design the architecture of networks for specific tasks. The idea of the paper is quite promising and the experimental results on two datasets show that method is solid.\nThe pros of the paper are:\n1. The idea of using RNN to produce the description of the network and using RL to train the RNN is interesting a",
        "This paper details the approach that won the VizDoom competition - an on-policy reinforcement learning approach that predicts auxiliary variables, uses intrinsic motivation, and is a special case of a universal value function. The approach is a collection of different methods, but it yields impressive empirical results, and it is a clear, well-writ",
        "This paper proposes learning on the fly to represent a dialog as a graph (which acts as the memory), and is first demonstrated on the bAbI tasks. Graph learning is part of the inference process, though there is long term representation learning to learn graph transformation parameters and the encoding of sentences as input to the graph. This seems ",
        "This paper proposes to investigate attention transfers between a teacher and a student network. \n\nAttention transfer is performed by minimising the l2 distance between the teacher/student attention maps at different layers, in addition to minimising the classification loss and optionally a knowledge distillation term.\nAuthors define several activat",
        "This paper investigates the benefits of visual servoing using a learned\nvisual representation. The authors  propose to first learn an action-conditional\nbilinear model of the visual features (obtained from a pre-trained VGG net) from\nwhich a policy can be derived using a linearization of the dynamics. A multi-scale,\nmulti-channel and locally-connec",
        "This paper proposes a nonparametric neural network model, which automatically learns the size of the model during the training process. The key idea is to randomly add zero units and use sparse regularizer to automatically null out the weights that are irrelevant. The idea sounds to be a random search approach over discrete space with the help of s",
        "This paper prunes entire groups of filters in CNN so that they reduce computational cost and at the same time do not result in sparse connectivity. This result is important to speed up and compress neural networks while being able to use standard fully-connected linear algebra routines. \nThe results are a 10% improvements in ResNet-like and ImageNe",
        "This paper is well written, and well presented. This method is using denoise autoencoder to learn an implicit probability distribution helps reduce training difficulty, which is neat. In my view, joint training with an auto-encoder is providing extra auxiliary gradient information to improve generator. Providing auxiliary information may be a metho",
        "This paper presents an approach for skills transfer from one task to another in a control setting (trained by RL) by forcing the embeddings learned on two different tasks to be close (L2 penalty). The experiments are conducted in MuJoCo, with a set of experiments being from the state of the joints/links (5.2/5.3) and a set of experiments on the pix",
        "This paper proposes a model to learn across different views of objects.  The key insight is to use a triplet loss that encourages two different views of the same object to be closer than an image of a different object.  The approach is evaluated on object instance and category retrieval and compared against baseline CNNs (untrained AlexNet and Alex",
        "This paper proposed a neural attention model which has a learnable and differentiable sampling lattice. The work is well motivated as few previous work focus on learning the sampling lattice but with a fixed lattice. This work is quite similar to Spatial Transformer Networks (Jaderberg 2015), but the sampling lattice is learned by the model. The ex",
        "This paper presents an information theoretic framework for unsupervised learning. The framework relies on infomax principle, whose goal is to maximize the mutual information between input and output. The authors propose a two-step algorithm for learning in this setting. First, by leveraging an asymptotic approximation to the mutual information, the",
        "This paper provides a new perspective to understanding the ResNet and Highway net. The new perspective assumes that the blocks inside the networks with residual or skip-connection are groups of successive layers with the same hidden size, which performs to iteratively refine their estimates of the same feature instead of generate new representation",
        "This paper not only shows that a cache model on top of a pre-trained RNN can improve language modeling, but also illustrates a shortcoming of standard RNN models in that they are unable to capture this information themselves. Regardless of whether this is due to the small BPTT window (35 is standard) or an issue with the capability of the RNN itsel",
        "This paper proposed a novel adversarial framework to train a model from demonstrations in a third-person perspective, to perform the task in the first-person view. Here the adversarial training is used to extract a novice-expert (or third-person/first-person) independent feature so that the agent can use to perform the same policy in a different vi",
        "This paper combines variational RNN (VRNN) and domain adversarial networks (DANN) for domain adaptation in the sequence modelling domain.  The VRNN is used to learn representations for sequential data, which is the hidden states of the last time step.  The DANN is used to make the representations domain invariant, therefore achieving cross domain a",
        "This paper introduces a novel method for language modeling which is suitable for both modeling programming language as well as natural language. The approach uses a program synthesis algorithm to search over program space and uses count-based estimation of the weights of the program. This is a departure from neural network-based approaches which re",
        "This paper provides a principled and practical formulation for weight-sharing and quantization, using a simple mixture of Guassians on the weights, and stochastic variational inference. The main idea and results are presented clearly, along with illustrative side-experiments showing the properties of this method in practice. Also, the method is ill",
        "This paper essentially presents a new inductive bias in the architecture of (convolutional) neural networks (CNN). The mathematical motivations/derivations of the proposed architecture are detailed and rigorous. The proposed architecture promises to produce equivariant representations with steerable features using fewer parameters than traditional ",
        "This paper proposed an integration of memory network with reinforcement learning. The experimental data is simple, but the model is very interesting and relatively novel. There are some questions about the model:\n\n1. how does the model extend to the case with multiple variables in a single sentence?\n\n2. If the answer is out of vocabulary, how would",
        "This paper presents an interesting take on getting an ensemble for free whilst training a single network. However, your main accuracy comparison seems to exclude traditional ensemble methods, save for the very end of section 4.3, where the actual ensemble method you used is not mentioned. I would advise expanding this paragraph to explain what ense",
        "This paper introduces an approach for future frame prediction in videos by decoupling motion and content to be encoded separately, and additionally using multi-scale residual connections. Qualitative and quantitative results are shown on KTH, Weizmann, and UCF-101 datasets.\n\nThe idea of decoupling motion and content is interesting, and seems to wor",
        "This paper provides an interesting framework for handling semi-supervised RL problems, settings were one can interact with many MDPs drawn from some class, but where only a few have observable rewards; the agent then uses a policy derived from the labeled MDPs to estimate a reward function for the unlabeled MDPs. The approach is straightforward, an",
        "This paper proposes a new Bayesian neural network architecture for predicting the values of learning curves during the training of machine learning models. This is an exploratory paper, in that the ultimate goal is to use this method in a Bayesian optimization system, but for now the experiments are limited to assessing the quality of the predictio",
        "\nThis papers adds to the literature on learning optimizers/algorithms that has gained popularity recently. The authors choose to use the framework of guided policy search at the meta-level to train the optimizers. They also opt to train on random objectives and assess transfer to a few simple tasks.\n\nAs pointed below, this is a useful addition.\n\nHo",
        "This paper describes a method to estimate likelihood scores for a range of models defined by a decoder.\n \n This work has some issues. The paper mainly applies existing ideas. As discussed on openreview, the isotropic Gaussian noise model used to create a model with a likelihood is questionable, and it's unclear how useful likelihoods are when model",
        "This paper presents new way for compressing CNN weights. In particular this paper uses a new neural network quantization method that compresses network weights to ternary values.\nThe group has recently published multiple paper on this topic, and this one offers possibly the lowest returns I have seen. Only a fraction of percentage in ImageNet. Resu",
        "This paper presents a training strategy for deep networks.  First, the network is trained in a standard fashion.  Second, small magnitude weights are clamped to 0; the rest of the weights continue to be trained.  Finally, all the weights are again jointly trained.  Experiments on a variety of image, text, and speech datasets demonstrate the approac",
        "This paper proposes a new memory module for large scale life-long and one-shot learning. The module is general enough that the authors apply the module to several neural network architectures and show improvements in performance.\n\nUsing k-nearest neighbors for memory access is not completely new. This has been recently explored in Rae et al., 2016 ",
        "This paper presents a clear hierarchical taxonomy of transfer learning methods as applicable to sequence tagging problems. This contextualizes and unifies previous work on specific instances of this taxonomy. Moreover, the paper shows that previously unexplored places in this taxonomy are competitive with or superior to the state of the art in key ",
        "This paper proposes a new gating mechanism to combine word and character representations. The proposed model sets a new state-of-the-art on the CBT dataset; the new gating mechanism also improves over scalar gates without linguistic features on SQuAD and a twitter classification task. \n\nIntuitively, the vector-based gate working better than the sca",
        "This paper performs a very important service: exploring in a clear and systematic way the performance and trainability characteristics of a set of neural network architectures -- in particular, the basic RNN motifs that have recently been popular.   \n\nPros:\n\n* This paper addresses an important question I and many others would have liked to know the",
        "This paper addresses one of the major shortcomings of generative adversarial networks - their lack of mechanism for evaluating held-out data. While other work such as BiGANs/ALI address this by learning a separate inference network, here the authors propose to change the GAN objective function such that the optimal discriminator is also an energy f",
        "This paper presents a novel way of pruning filters from convolutional neural networks with a strong theoretical justification. The proposed methods is derived from the first order Taylor expansion of the loss change while pruning a particular unit. This leads to simple weighting of the unit activation with its gradient w.r.t. loss function and perf",
        "This paper provides two approaches to question answering: pointing to spans, and use of match-LSTM. The models are evaluated on SQuAD and MSMARCO. The reviewers we satisfied that, with the provision of additional comparisons and ablation studies submitted during discussion, the paper was acceptable to the conference, albeit marginally so.",
        "This paper proposes a modification of the parametric texture synthesis model of Gatys et al. to take into account long-range correlations of textures. To this end the authors add the Gram matrices between spatially shifted feature vectors to the synthesis loss. Some of the synthesised textures are visually superior to the original Gatys et al. meth",
        "This paper proposed a dynamic coattention network for the question answering task with long contextual documents. \nThe model is able to encode co-dependent representations of the question and the document, and a dynamic decoder iteratively pointing the potential answer spans to locate the final answer. \n\nOverall, this is a well-written paper. \nAlth",
        "This paper fairly clearly presents a totally sensible idea. The details of the method presented in this paper are clearly preliminary, but is enough to illustrate a novel approach.",
        "This paper optimizes autoencoders for lossy image compression. Minimal adaptation of the loss makes autoencoders competitive with JPEG2000 and computationally efficient, while the generalizability of trainable autoencoders offers the added promise of adaptation to new domains without domain knowledge.\n The paper is very clear and the authors have t",
        "This paper tests zoneout against a variety of datasets - character level, word level, and pMNIST classification - showing applicability in a wide range of scenarios. While zoneout acts as a regularizer to prevent overfitting, it also has similarities to residual connections. The continued analysis of this aspect, including analyzing how the gradien",
        "This paper motivates the combination of autoregressive models with Variational Auto-Encoders and how to control the amount the amount of information stored in the latent code. The authors provide state-of-the-art results on MNIST, OMNIGLOT and Caltech-101.\nI find that the insights provided in the paper, e.g. with respect to the effect of having a m",
        "This paper proposes a method for significantly increasing the number of parameters in a single layer while keeping computation in par with (or even less than) current SOTA models. The idea is based on using a large mixture of experts (MoE) (i.e. small networks), where only a few of them are adaptively activated via a gating network. While the idea ",
        "This paper discusses Hyperband, an extension of successive halving by Jamieson & Talwalkar (AISTATS 2016). Successive halving is a very nice algorithm that starts evaluating many configurations and repeatedly cuts off the current worst half to explore many configuration for a limited budget.\n\nHaving read the paper for the question period and just r",
        "This paper introduces the Quasi-Recurrent Neural Network (QRNN) that dramatically limits the computational burden of the temporal transitions in\nsequence data. Briefly (and slightly inaccurately) model starts with the LSTM structure but removes all but the diagonal elements to the transition\nmatrices. It also generalizes the connections from lower ",
        "This paper explores ensemble optimisation in the context of policy-gradient training. Ensemble training has been a low-hanging fruit for many years in the this space and this paper finally touches on this interesting subject. The paper is well written and accessible. In particular the questions posed in section 4 are well posed and interesting.\n\nTh",
        "This paper studies the problem of transferring solutions of existing tasks to tackle a novel task under the framework of reinforcement learning and identifies two important issues of avoiding negative transfer and being selective transfer. The proposed approach is based on a convex combination of existing solutions and the being-learned solution to",
        "This paper proposes an approach to learning word vector representations for character sequences and acoustic spans jointly. The paper is clearly written and both the approach and experiments seem reasonable in terms of execution. The motivation and tasks feel a bit synthetic as it requires acoustics spans for words that have already been segmented ",
        "This paper introduces MusicNet, a new dataset. Application of ML techniques to music have been limited due to scarcity of exactly the kind of data that is provided here: meticulously annotated, carefully verified and organized, containing enough \"hours\" of music, and where genre has been well constrained in order to allow for sufficient homogeneity",
        "This paper applies REINFORCE to learn MCMC proposals within the existing STOKE scheme for super-optimization. It's a neat paper, with interesting results.\n \n It's not clear whether interesting representations are learned, and the algorithms are not really new. However, it's a neat piece or work, that some ICLR reviewers found interesting, and could",
        "This paper presented a method of improving the efficiency of deep networks acting on a sequence of correlated inputs, by only performing the computations required to capture changes between adjacent inputs. The paper was clearly written, the approach is clever, and it's neat to see a practical algorithm driven by what is essentially a spiking netwo",
        "This paper applies the idea of normalizing flows (NFs), which allows us to build complex densities with tractable likelihoods, to maximum entropy constrained optimization.\n\nThe paper is clearly written and is easy to follow.\n\nNovelty is a weak factor in this paper. The main contributions come from (1) applying previous work on NFs to the problem of",
        "This paper focusses on attention for neural language modeling and has two major contributions:\n\n1. Authors propose to use separate key, value, and predict vectors for attention mechanism instead of a single vector doing all the 3 functions. This is an interesting extension to standard attention mechanism which can be used in other applications as w",
        "This paper is a by-the-numbers extension of the hidden semi-Markov model to include nonlinear observations, and neural network-based inference. The paper is fairly clear, although the English isn't great. The experiments are thorough.\n \n Where this paper really falls down is on originality. In particular, in the last two years there have been relat",
        "This paper presents a variational inference based method for learning nonlinear dynamical systems. Unlike the deep Kalman filter, the proposed method learns a state space model, which forces the latent state to maintain all of the information relevant to predictions, rather than leaving it implicit in the observations. Experiments show the proposed",
        "This paper first discusses a general framework for improving optimization of a complicated function using a series of approximations. If the series of approximations are well-behaved compared to the original function, the optimization can in principle be sped up. This is then connected to a particular formulation in which a neural network can behav",
        "This paper extends preceding works to create a mapping between the word embedding space of two languages. The word embeddings had been independently trained on monolingual data only, and various forms of bilingual information is used to learn the mapping. This mapping is then used to measure the precision of translations.\n\nIn this paper, the author",
        "This paper proposes to learn decomposition of sequences (such as words) for speech recognition. It addresses an important issue and I forsee it being useful for other applications such as machine translation. While the approach is novel and well-motivated, I would very much like to see a comparison against byte pair encoding (BPE). BPE is a very na",
        "This paper is technically sound. It highlights well the strengths and weaknesses of the proposed simplified model.\n\nIn terms of impact, its novelty is limited, in the sense that the authors did seemingly the right thing and obtained the expected outcomes. The idea of modeling deep learning computation is not in itself particularly novel. As a compa",
        "This paper shows how policy gradient and Q-Learning may be combined together, improving learning as demonstrated in particular in the Atari Learning Environment. The core idea is to note that entropy-regularized policy gradient leads to a Boltzmann policy based on Q values, thus linking pi & Q together and allowing both policy gradient and Q-Learni",
        "This paper clearly lays out the recipe for a family of invertible density models, explores a few extensions, and demonstrates the overall power of the approach. The work is building closely on previous approaches, so it suffers a bit in terms of originality. However, I expect this overall approach to become a standard tool for model-building.\n \n Th",
        "This paper extends batch normalization successfully to RNNs where batch normalization has previously failed or done poorly. The experiments and datasets tackled show definitively the improvement that batch norm LSTMs provide over standard LSTMs. They also cover a variety of examples, including character level (PTB and Text8), word level (CNN questi",
        "This paper describes a way to speed up convergence through sudden increases of otherwise monotonically decreasing learning rates. Several techniques are presented in a clear way and parameterized method is proposed and evaluated on the CIFAR task. The concept is easy to understand and the authors chose state-of-the-art models to show the performanc",
        "This paper proposes a weakly supervised, end-to-end neural network model for solving a challenging natural language understanding task. \nAs an extension of the Neural Programmer, this work aims at overcoming the ambiguities imposed by natural language. \nBy predefining a set of operations, the model is able to learn the interface between the languag",
        "This paper introduces a 'GPU-friendly' variant of A3C which relaxes some synchronicity constraints in the original A3C algorithm to make it more friendly to a high-throughput GPU device. The analysis of the effects of this added latency is thorough. The systems analysis of the algorithm is extensive. \n\nOne caveat is that the performance figures in ",
        "This paper presents an approach to learn to generate programs. Instead of directly trying to generate the program, the authors propose to train a neural net to estimate a fix set of attributes, which then condition a search procedure. This is an interesting approach, which make sense, as building a generative model of programs is a very complex tas",
        "This paper considers the problem of model-based policy search. The authors \nconsider the use of Bayesian Neural Networks to learn a model of the environment\nand advocate for the $\\alpha$-divergence minimization rather than the more usual \nvariational Bayes. \n\nThe ability of alpha-divergence to capture bi-modality however \ncomes at a price and most ",
        "This paper describes a new way of variable computation, which uses a different number of units depending on the input. This is different from other methods for variable computation that compute over multiple time steps. The idea is clearly presented and the results are shown on LSTMs and GRUs for language modeling and music prediction.\n \n Pros:\n - ",
        "This paper discussses applying an information bottleneck to deep networks using a variational lower bound and reparameterization trick. The paper is well written and the examples are compelling. The paper can be improved with more convincing results on MNIST.",
        "This paper proposes the neural noisy channel model, P(x|y), where (x, y) is a input-to-out sequence pair,  based on the authors' previous work on segment to segment neural transduction (SSNT) model. For the noisy channel model, the key difference from sequence-to-sequence is that the complete sequence y is not observed beforehand. SSNT handles this",
        "This paper builds on the work of Weston (2016), using End-to-end memory network models for a limited form of dialogue with teacher feedback. As the authors state in the comments, it is closely related to the question answering problem with the exception that a teacher provides a response after the model\u2019s answer, which does not always come with a p",
        "This paper extends the GAN framework to allow for latent variables. The observed data set is expanded by drawing latent variables z from a conditional distribution q(z|x). The joint distribution on x,z is then modeled using a joint generator model p(x,z)=p(z)p(x|z).  Both q and p are then trained by trying to fool a discriminator. This constitutes ",
        "This paper introduces a simulator and a set of synthetic tasks for evaluating a dialogue agent's ability to learn from user feedback. For solving these tasks, the paper uses memory networks (Sukhbaatar et al., 2015) learned through previously proposed supervised learning and reinforcement learning methods. In this setup, it is demonstrated that the",
        "This paper proposes a design principle for computation blocks in convolutional networks based on repeated application of expand and join operations resulting in a fractal-like structure. \n\nThis paper is primarily about experimental evaluation, since the objective is to show that a residual formulation is not necessary to obtain good performance, at",
        "This paper studies the energy landscape of the loss function in neural networks.  It is generally clearly written and nicely provides intuitions for the results.  One main contribution is to show that the level sets of the loss becomes connected as the network is increasingly overparameterized.  It also quantifies, in a way, the degree of disconnec",
        "This paper provides a simple method to handle action repetitions. They make the action a tuple (a,x), where a is the action chosen, and x the number of repetitions. Overall they report some improvements over A3C/DDPG, dramatic in some games, moderate in other. The idea seems natural and there is a wealth of experiment to support it.\n\nComments:\n\n- T",
        "This paper proposed a proximal (quasi-) Newton\u2019s method to learn binary DNN. The main contribution is to combine pre-conditioning with binarization in a proximal framework. It is interesting to have a proximal Newton\u2019s method to interpret the different DNN binarization schemes. This gives a new interpretation of existing approaches. However, the th",
        "This paper is a parallel work to Improving Generative Adversarial Networks with Denoising Feature Matching. The main solution of both papers is introducing autoencoder into discriminator to improve the stability and quality of GAN. Different to Denoising Feature Matching, EBGAN uses encoder-decoder instead of denoising only, and use hingle loss to "
    ],
    "sampled": [
        "This paper addresses the problem of disambiguating/linking textual entity\nmentions into a given background knowledge base (in this case, English Wikipedia).\nThe proposed approach relies on a combination of natural language processing (NLP)\ntechniques, specifically:\n\n1. Named Entity Recognition (NER): identifies and classifies named entities in the input text, such as people, organizations, and locations.\n2. Word",
        "This paper presents several weakly supervised methods for developing NERs. The\nmethods are based on various techniques, such as word embeddings,\nsequence labeling, and adversarial training. The\nauthors experiment with different data sets and\nevaluate the performance of the proposed methods\nusing standard evaluation metrics for NER.\n\nThe authors first propose a method based on\nword embeddings,",
        "This paper describes a rule based approach to time expression extraction. Its novelty lies in its ability to handle complex time expressions and to provide accurate results even in the presence of ambiguity.\nThe proposed system is based on a set of rules that capture the linguistic properties of time expressions, such",
        "This paper presents a neural network-based framework for dialogue state\ntracking.\nThe main idea is to use a Recurrent Neural Network (RNN) to\npredict the next state of a dialogue based on the\nprevious states and the current input. The RNN is\ntrained on a large corpus of dialogues,",
        "This paper proposes a neural network architecture that represent structural\nlinguistic knowledge in a memory network for sequence tagging tasks.\n\nIntroduction\n------------\n\nSequence tagging is a fundamental task in natural language processing,\nwhere the goal is to assign a label to each word in a sentence to\nrepresent its grammatical category (e.g. noun, verb, adjective, etc.).\nExisting",
        "This paper presents a new dataset with annotations of products coming from\nonline cybercrime forums. The paper also proposes a new approach for analyzing and\nunderstanding online cybercrime forums, based on the usage of\nnatural language processing techniques. The proposed\napproach allows to automatically analyze the content of the\nforums and to identify key aspects related to cybercrime,\nsuch as illegal",
        "This paper introduces UCCA as a target representation for semantic parsing and\nalso describes a method for learning UCCA from a set of parse trees.\n\nThe authors propose a method for learning a mapping from parse trees to a compact, interpretable representation called Unified Compositional Context Assignment (UCCA). They show that UCCA can capture the semantics",
        "This paper proposed a macro discourse structure scheme. The authors carried out\na pilot study annotating a corpus consisting of 97 news articles from different newspapers and magazines in order to test the reliability of the proposed scheme.\nThe results showed that the scheme succeeded in identifying macro",
        "This paper proposes a framework for evaluation of word embeddings based on data\nefficiency, theoretical justification, and ability to capture linguistic phenomena.\nThe proposed framework consists of three evaluation metrics:\n\n1. Data Efficiency: This metric measures the number of training examples required to achieve a certain level of performance on a downstream task. Lower values indicate that the",
        "This paper delves into the mathematical properties of the skip-gram model,\nexplaining the reason for its remarkable performance in learning word embeddings.\n\nThe skip-gram model is a type of neural network architecture that has gained popularity in recent years for its ability to learn word embeddings. Unlike traditional methods that rely on",
        "This paper presents a neural sequence-to-sequence model for encoding dialog\ncontexts in a conversational chatbot system. The model is trained on a large dataset\nof text chat logs and learns to map dialog contexts to a set of\nrepresentations that can be used to",
        "This paper compares different ways of inducing embeddings for the task of\npolarity detection in Social Media, which is the task of classifying a\ntweet as positive, negative, or neutral based on its content.\n\nWe evaluate the performance of four different methods for\ninducing embeddings: Word2Vec, GloVe, Doc2Vec, and Transformer-based methods. We\nuse a dataset of",
        "This paper presents a purpose-built neural network architecture for textual\nentailment/NLI based on a three step process of encoding, interaction, and\ndecoding. The proposed architecture, called TextEntail, leverages\nattention mechanisms to learn the dependencies between different\nword embeddings in a sequence of text, and uses a combination of\nbilateral and unilateral cross-attention",
        "This paper proposes a supervised deep learning model for event factuality\nidentification.  The empirical results show that the model outperforms traditional\nnatural language processing approaches, achieving an F1 score of\n0.71 on a test set.  The model is based on a neural network\narchitecture that incorporates both local and global\ninformation in the",
        "This paper presents the gated self-matching network for reading comprehension\nstyle question answering. This technique is based on the encoder-decoder\narchitecture, and includes a question-specific encoding\ngate to selectively focus on specific parts of the input when\nanswering a question. We evaluate the effectiveness of\nthis approach on four datasets",
        "This paper investigates the cold-start problem in review spam detection. The\nauthors first qualitatively analyze the characteristics of review spam and\nclassify them into three categories: \\emph{absurd spam},\n\\emph{benign spam}, and \\emph{malicious spam}. They then\npropose a deep learning model that leverages pre-trained\nlanguage models to address the cold-start problem. The\nmodel is trained on a combination",
        "This paper details a method of achieving translation from morphologically\nimpoverished languages (e.g. Chinese) to morphologically rich languages\n(e.g. English) using a technique called morphological\ndecomposition.  Using this technique, it is possible to\ndecompose the input morphologically impoverished language\nword into its constituent morphemes, and then use\nthese morphemes to generate",
        "This paper addresses the network embedding problem by introducing a neural\nnetwork model which uses the concept of network diffusion to model the spread of information or influence through a network. The model is based on the idea that the spread of information or influence through a network is driven by the diffusion",
        "This paper describes interesting and ambitious work: the automated conversion\nof Universal Dependencies (UD) trees to WordNet frames. The approach\nbuilds on recent advances in natural language processing (NLP)\nand leverages the well-established WordNet lexical\ndatabase. The authors claim that their method is the\nfirst to combine UD and WordNet for generating\nword",
        "This paper outlines a method to learn sense embeddings from unannotated corpora\nusing a modular architecture that combines weakly supervised contrastive and\nself-supervised learning. This method provides a way to learn robust\nrepresentations of words and contexts in a way that is not\ndependent on the availability of labeled training data. The\nproposed method leverages",
        "This paper describes a state-of-the-art CCG parsing model that decomposes into\ntagging and dependency scores, and has an efficient implementation that\n  uses GPU acceleration. Our model has been trained on a large\n  corpus of text data and has achieved high accuracy on\n  standard",
        "This paper presents evaluation metrics for lyrics generation exploring the need\nfor the lyrics to be original,but in a similar style to the input\nsong.  The evaluated metrics can be used to compare different\napproaches to lyrics generation and determine which approach\nresults in the most original and coherent lyrics.\nThe proposed evaluation metrics for lyrics generation",
        "This paper proposed to explore discourse structure, as defined by Rhetorical\nStructure Theory (RST) to improve text categorization using natural language processing (NLP) techniques. Specifically, the paper aimed to investigate the effectiveness of RST in enhancing the accuracy of text categorization, and to identify the most relevant features of RST for",
        "This paper proposes joint CTC-attention end-to-end ASR, which utilizes both\nadvantages in training and decoding.  First, the CTC loss function is used in the\ntraining stage to train the model to predict the duration and the\nacoustic features of the spoken language.  In the decoding stage, the\nattention mechanism",
        "This paper proposes a method for generating datasets of pictures from simple\nbuilding blocks, as well as a tool for converting images into these\nbuilding blocks. The key idea is to represent each image as a\ncollection of small, simple shapes (e.g. squares, circles) that\ncan be combined to form the entire image. The\ngeneration process involves",
        "This paper propose a general framework for analyzing similarities and\ndifferences between data mining and data science. This framework could be useful to researchers, practitioners, and educators who want to understand and interpret the various approaches and techniques used in these two fields. The",
        "This paper modifies existing word embedding algorithms (GloVe, Skip Gram, PPMI,\nSVD) to include ngram-nature word relationships into the embedding learning process.\n\nOur proposed approach uses the following three techniques:\n1. Word2Vec: This technique uses neural networks to map words to vectors in an infinite-dimensional space, where the vectors are learned based",
        "This paper investigates the application of distributional vectors of meaning in\ntasks that involve the identification of semantic similarity between pairs of words or phrases.\nThe authors use the concept of distributional vectors of meaning (DVs)\nintroduced by Mark D redes et al. in 2013. DVs are a type of distributional model that represents the meaning",
        "This paper describes a straightforward extension to left-to-right beam search\nin order to make it more efficient for solving the natural language processing (NLP) tasks. In particular,we propose to use the incremental parsing theory as a basis for the left-to-right beam search algorithm and employ incremental grammar construction to reduce the number",
        "This paper introduces a new approach to semantic parsing in which the model is\nequipped with a neural sequence to sequence (seq2seq) architecture and a\nself-attention mechanism. This allows the model to learn the\ndependencies between words in a sentence and to capture long-range dependencies.\n\nExisting approaches to semantic parsing rely on hand-crafted rules\nor syntactic features",
        "This paper proposes integrating word sense inventories into existing approaches\nfor the lexical substitution-based machine translation. A word\nsense inventory (WSI) is a list of word senses for a given\nlexical unit (i.e., a word or a short phrase). The WSI can be used\nto disambiguate words that have multiple meanings",
        "This paper presents a corpus of annotated essay revisions. \n\nIt includes two examples of application for the use of this corpus; a study on the impact of feedback on student learning and a study on the effectiveness of different feedback strategies.\n\nThe first example demonstrates how the corpus can be used to",
        "This paper presents a dialogue agent where the belief tracker and the dialogue\nmanager are jointly trained to make the agent more competent in handling\ntasks and responding to user inquiries. The agent is trained on\na dataset with different task-related and user-related\ninformation, and the model optimizes the learned factors\nthat determine the likelihood",
        "This paper presents a new state-of-the-art deep learning model for semantic\nrole labeling (SRL) that is a natural extension of the previous\nwork by (Kita et al., 2017). In this paper, we propose a\nnovel architecture that leverages both encoder-decoder and\nattention-based mechanisms to improve the accuracy of SRL.\nThe proposed model is based on a",
        "This paper describes several ways to encode arbitrarily long sequences of\ndigits using something other than an array, such as a linked list, a circular\nqueue, or a stack.  For each of these data structures, the\nauthors provide an algorithm for encoding the digits in a\nparticular way, such as using a randomized prefix\nfunction",
        "This paper presents a gated attention mechanism for machine reading. \nA key idea is to extend Attention Sum Reader (Kadlec et al. 2016) by adding a gating function to modulate the attention flow. By adding this gating function, we can selectively focus on important parts of the input sequence while ignoring irrelevant parts.",
        "This paper proposes to use an encoder-decoder framework for keyphrase\ngeneration. Experimental results show that the proposed approach outperforms\nstate-of-the-art keyphrase generation methods in terms of both\nquality and efficiency.\nThe proposed approach uses an encoder-decoder framework\nconsisting of a pre-training module and a keyphrase\ngeneration module. The pre-training module is used",
        "This paper continues the line of work for applying word embeddings for the\nproblem of unsupervised morphological segmentation (e.g. Soricut & Och, 2017;\nSainath et al., 2015). The key idea is to use the linguistic structure of a language\nas a prior knowledge to guide the learning of word embeddings.\nOur approach is based on the",
        "This paper proposes a simple attention-based RNN model for sequence tagging tasks, which combines the advantages of both attention mechanisms and RNNs. In the proposed model, an attention mechanism is used to selectively focus on specific parts of the input sequence when predicting the next tag. The attention mechanism",
        "This paper presents a graph-based approach for producing sense-disambiguated\nsynonym sets from a collection of text documents. The proposed method\nfocuses on identifying and disambiguating sense-ambiguous terms in\ndocuments, and then grouping those terms into sets based on their senses. The\nmethod uses graph-based algorithms to efficiently handle the\nComplexity",
        "This paper proposes a joint model of salient phrase selection and discourse\nrelation prediction in spoken meeting conversations. The proposed model utilizes\na novelty detection approach to identify salient phrases in each\nspeaker's utterance, and a sequence-to-sequence neural network\nmodel to predict the next speaker's utterance based on the\nprevious speaker's utterance and the",
        "This paper proposes a method for building dialogue agents involved in a\nsymmetric collaborative task, in which the agents have complementary\ninformation and must work together to achieve a mutually beneficial\ngoal. The agents communicate through natural language\ninteractions, and the task is designed to require the agents to\ncoordinate their actions and exchange information in a\ncooperative manner. The proposed method",
        "This paper proposes an approach for classifying literal and metaphoric\nadjective-noun pairs. The authors create a dataset of English adjective-noun pairs,\n annotated with their literal or metaphorical relationship, and use this\ndataset to train and test a machine learning model. The model is\nbased on a combination of word embeddings and neural",
        "This paper proposes a novel strategy for zero-resource translation where\n(source, pivot) and (pivot, target) parallel corpora are available.\nExisting zero-resource translation approaches often rely on large-scale parallel corpora, which may not be available for many languages. Our approach leverages the rich linguistic features of parallel corpora to learn to",
        "This paper considers the problem of KB completion and proposes ITransF for this\npurpose. ITransF is a hierarchical framework that combines the strengths of\nknowledge graph embedding (KGE) and translation-based methods.\n\nKeywords: Knowledge Graph Embedding (KGE), Translation-based methods,\nHierarchical framework, KB completion, Entity disambiguation\n\nThe rapid growth of digital data has led to an unprecedented",
        "This paper presents a method for translating natural language descriptions into\n\n```\nThis paper proposes a method for translating natural language descriptions into formal specifications using a novel approach. The proposed approach leverages recent advances in natural language processing (NLP) and formal methods to enable the automated translation of complex specifications from",
        "This paper focuses on interpreting sarcasm written in Twitter identifying\nsentiment words and then using a machine translation engine to find an\nequivalent not sarcastic tweet. Existing systems rely heavily on the choice and\nquality of pre-trained machine translation models and their ability to\nunderstand and translate sentiment-bearing words in the input text. We\nintroduce a novel",
        "This paper describes a system to assist written test scoring.\n\n- Strengths:\nThe paper represents an application of an interesting approach to automatic scoring of open-ended essay questions, and provides a detailed description of the system they have developed. The authors provide a thorough analysis of the system's strengths, including its ability to",
        "This paper introduces new configurations and training objectives for the Titan-based Simultaneous Localization and Mapping (SLAM) system, which is widely used in various robotics and autonomous systems. Titan is a scalable and flexible robot operating system that enables the development of more sophisticated SLAM algorithms. The proposed",
        "This paper proposed a new phrasal RNN architecture for sequence to sequence\ngeneration. They have evaluated their architecture based on (i) the language modeling task (ii) machine translation task.\n\nThey have proposed two main contributions:\n\n1. A new training objective for RNNs, called the `phrase-to-phrase training objective', which encourages the",
        "This paper proposes new prediction models for Japanese SRL task by adopting the\nEnglish state-of-the-art deep learning techniques, such as LSTM and\nTransfer learning. The proposed models are trained on a dataset\nconsisting of corpora of Japanese sentences with grammatical errors and\ncorrect sentences. An experimental evaluation on several Japanese\nSRL benchmark datasets shows that",
        "This paper develops an LSTM-based model for classifying lung cancer tissue images using a convolutional neural network (CNN). The dataset used is a combination of 300 images with an even balance of adenocarcinoma and squamous cell carcinoma, and 100 images with an uneven balance of these two types.\nThe CNN",
        "This paper proposes a method for recognizing lexical entailment (specifically,\nhypernymy and hyponymy) in text using a deep learning\nmodel. The proposed method is based on a combination of word embeddings and a\nneural network architecture, and it is trained on a large corpus",
        "This paper proposes a method for evaluating the reliability of a system using a graphical approach. The reliability of a system is defined as the probability of the system being operational and meeting its performance requirements over a given period of time. The graphical approach proposed",
        "This paper proposed a very interesting idea of using cognitive features for\nsentiment analysis and sarcasm detection. They use a dataset of tweets and\n Label them as either sarcastic or non-sarcastic. Then, they\n Propose a new method that combines both sentiment and\n Sarcasm analysis using cognitive features. These features\n Include intonation, tone,",
        "This paper proposes a neural-styled topic model, extending the objective of\nword2vec to also learn topics in a document. Our proposed model,\nTopic2Vec, uses a neural network to model the distribution of\nwords within each topic and the relationships between them. We\nevaluate Topic2Vec on several benchmark datasets and show that it\noutperforms traditional methods in",
        "This paper describes four methods of obtaining multilingual word embeddings and\na modified QVEC metric for evaluating the efficacy of these methods.\nWord embeddings are dense vector representations of words that capture their semantic properties.\nMultilingual word embeddings are obtained by mapping each word in one language to its corresponding vector representation in",
        "This paper proposes a method for discovering correspondences between atoms in different molecules based on their similarity in chemical structure. Using support vector machines (SVMs) as the classification algorithm, we developed a system that can identify correspondences between atoms in different molecules based on their chemical structure similarity. We tested the",
        "This paper proposes an approach for multi-lingual named entity recognition\nusing features from unsupervised machine translation. The approach was tested on six languages, and outperformed other state-of-the-art systems on four of them.\nBackground and related work:\nNamed entity recognition (NER) is an important task in natural language processing, which involves identifying and",
        "This paper proposes the new (to my knowledge) step of proposing to treat a\nnumber of sentence pair scoring operations as a hierarchical clustering\nproblem, with the goal of identifying which sentence pairs are semantically similar,\nand which are not. The approach involves treating the scores from\nthe evaluation",
        "This paper presents a transition-based graph parser able to cope with the rich\nrepresentations of a semantically-enhanced Petri net (SENet) formalism.\n\nSENet is an extension of Petri net (PN) formalism that\nadds semantics to the token behavior, allowing to represent\ncomputation and communication protocols in a more formal\nway. SENet formalism",
        "This paper presents a Stack LSTM parser based on the work of Henderson et al.\n(2008, 2013) on joint syntactic/semantic parsing. The parser is designed to handle both word-level and character-level information, and is able to capture complex dependencies between words in a sentence. The proposed parser is evaluated on several benchmark datasets, and compares favorably",
        "This paper investigates three simple weight-pruning techniques for NMT, and\n\n1. **Sparse Matrix Factorization**: This method approximates the weight matrix of the NMT model using a sparse matrix factorization technique. The weights are sparse, and the model is trained using the sparse weights. This method results in a smaller",
        "This paper presents results on the UD treebanks to test delexicalized transfer\nparsers and an unsupervised parser which is enriched with external\nprobabilities. The treebanks used for testing are the Universal Dependencies\n(UD) treebanks, which are a collection of gold-standard syntactic\nannotations for several languages. We compare the\nperformance of the three parsers on",
        "This paper presents an approach to tag word senses with temporal information\n(i.e., time expressions) in a fine-grained manner. The proposed method\nis based on the concept of \"time frames\" and allows to capture the\nvariability in the meaning of a word over time. The proposed\napproach is evaluated on a large corpus of",
        "This paper models event linking using CNNs. Given event linking involves identifying relationships between events in a sequence of time steps, the authors propose to use a CNN to learn a representation of the event sequence that captures the temporal relationships between the events.\nTo build the",
        "This paper describes a new deterministic dependency parsing algorithm and its evaluation on the Penn Treebank corpus. The algorithm is based on a combination of syntactic and semantic features and uses a conditional random field (CRF) to model the probability of each possible parse tree. The authors claim that their algorithm",
        "This paper improves significantly the previously proposed deep learning-based method for image segmentation by employing a combination of convolutional neural networks (CNNs) and reinforcement learning (RL). The proposed Deep Reinforcement Learning (DRL) method leverages the strengths of both CNNs and RL to achieve high-quality image segmentation.\nThe paper is structured as follows:\n* In Section 2,",
        "This paper extends an approach to rate-distortion optimization to deep encoders capable of generating diverse and realistic outputs. The idea is to modify the usual rate-distortion optimization to encourage the encoder to produce diverse outputs by penalizing overly similar outputs. The proposed method is evaluated on two",
        "This paper describes a new approach to meta learning by interpreting the Siamese network architecture as a nonlinear dimensionality reduction technique.\nThe key idea of the proposed method is to use the Siamese network to learn a lower-dimensional representation of the input space that preserves the similarity structure between input samples. The learned representation can be",
        "\u0444\u0435\u0432();`\n\nIt looks like you are trying to use",
        "This paper makes a valuable contribution to provide a more clear understanding of the complex relationship between urbanization and mental health. The authors examine the dynamic relationship between urbanization and mental health in a holistic manner, considering the interplay between urban structures, social networks, and individual psychological factors. They also consider the impact of urbanization on",
        "This paper proposes a way of adding unsupervised auxiliary tasks to a deep RL agent to improve its performance on the primary task by leveraging the knowledge learned from the auxiliary tasks. The idea is to use the auxiliary tasks to learn a representation that is useful for both the primary task and the auxiliary tasks, and then",
        "This paper proposed to use RL and RNN to design the architecture of networks for controlling robots navigating in dynamic environments The authors claimed that their method could learn and adapt to changing conditions and that the proposed architecture could be used to control a robot s motions in real time.\n\nThe authors proposed to use RL and RNN to design the architecture of networks",
        "This paper details the approach that won the VizDoom competition 2020, hosted by the University of California, Berkeley.\n\nThe competition involves using computer vision and deep learning to solve a series of Doom-related tasks, such as object detection, segmentation, and tracking. The approach presented in this paper combines state-of-the-art models and techniques from computer",
        "This paper proposes learning on the fly, as a way of using the computational power of the cloud to adapt the neural network to new types of data, without the need to retrain the entire model.\n\nThe authors propose a method that can learn a new task from a small set of labeled samples, and adapt the model such that it",
        "This paper proposes to investigate attention mechanism in deep learning models, with a focus on its implementation in natural language processing tasks. The goal of this investigation is to gain a deeper understanding of attention mechanisms and their role in improving NLP models. In particular, this research",
        "This paper investigates the benefits of visual servoing using a learned\nvisual representation. The authors  propose  a  new  method  that  learns  a  continuous  function  that  maps  the  visual  representation  of  the  robot's",
        "This paper proposes a nonparametric test for detecting the presence of a nonlinear relationship between two continuous variables in the presence of measurement error.\n\nThe proposed test is based on the following assumptions:\n\n1. The data are observed with measurement error, represented by an independent random variable $\\epsilon$ with finite variance.\n2. The relationship between the two continuous variables is nonlinear, modeled",
        "This paper prunes entire groups of filters in CNN so that it can accelerate the inference by reducing the number of computations. The authors propose a dynamic pruning method that can prune filters in the CNN based on their contribution to the overall accuracy of the model during the training process.\nThe authors train a CNN on various",
        "This paper is well written, and well cited. One of its most important arguments is that the use of technology in education can have a profound impact on the learning experience, and that it is essential for educators to understand how to use technology to enhance teaching and learning.\n\nOne of the",
        "This paper presents an approach for skills transfer from one task to another in a control setting (trained by RL) without requiring explicit reward functions. In traditional RL settings, skills are acquired through trial and error by learning from rewards received after executing actions. However, in many applications, the rewards are not available or are hard to define. Moreover, the skills",
        "This paper proposes a model to learn across different views and modalities for visual question answering (VQA). In VQA, the goal is to answer questions about images by generating an answer that is correct according to the image contents. While current VQA models have achieved impressive performance on few-shot learning settings, they are limited to a single modality (e.g., vision) and",
        "This paper proposed a neural attention model which has a learnable and adaptive representation for different sub-tasks of natural language processing (NLP) tasks. The model uses a multi-head self-attention mechanism to learn and represent different sub-tasks in one shared representation. The model is trained using a combination of reconstruction loss and adversarial loss, and it's able to",
        "This paper presents an information theoretic framework for comparing the performance of different machine learning algorithms for multi-class classification tasks. The proposed framework uses the concept of entropy to evaluate the quality of a classifier and compares the performance of different algorithms in terms of their ability to reduce the",
        "This is a small collection of my personal projects and contributions to open-source communities.\n\n1. **WebGL Interactive Visualizer**: A web-based application for visualizing 3D models, using WebGL and Three.js. This project was built as a demonstration of the potential of web-based 3D graphics, and to showcase the capabilities of Three.js.\n2. **PyInstaller**: A tool for",
        "This paper not only shows that a cache model on top of a pre-trained RNN can improve the performance of a sequence-to-sequence model for various tasks, but also provides a thorough analysis of the cache model and demonstrates its effectiveness in terms of reducing the computational costs and memory usage while maintaining the accuracy of the model.\nThe authors propose a cache model",
        "This paper proposed a novel adversarial framework to train a model from demonstrations (Do-Re-Mi), which is a challenging problem in machine learning. The key idea is to use a generative model to learn the distribution of the demonstrations and then use this distribution to generate new demonstrations that are similar to the original ones.",
        "This paper combines variational RNN (VRNN) and domain adversarial networks (DANN) to address the challenges of open-set recognition in computer vision.\nOpen-set recognition refers to the task of recognizing objects in a scene where some of the objects are unknown or belong to a different class than the objects in the training data.\nExisting approaches to open-set recognition",
        "This paper introduces a new method for designing and optimizing active aerodynamic control systems for aircraft. It is based on a novel approach that uses a combination of model predictive control and gradient-based optimization techniques to find the optimal control inputs that minimize the aircraft's drag and maximize its lift. The method is validated",
        "This paper provides a principled and practical formulation for designing decentralized architectures for large-scale machine learning (ML) tasks, which are crucial in many real-world applications.\nFirst, we identify the key challenges in designing decentralized ML systems, such as scalability, data heterogeneity, and security. We then propose a general framework for decentralized",
        "This paper presents a novel approach for efficient and secure data aggregation in distributed systems, using a combination of cryptographic techniques and data sampling.\n\nBackground:\nData aggregation is a crucial function in many distributed systems, such as data warehousing, where data from multiple sources needs to",
        "This paper proposed an integration of memory network with reinforcement learning. The authors propose a new architecture called the Differentiable Memory Replay (DMR) that allows the model to learn from its past experiences and to perform better in reinforcement learning tasks.\nThe DMR model is based on the idea of storing past experiences in a memory buffer,",
        "This paper presents an overview of the current state of knowledge on the psychological impact of cannabis use, including both the short-term and long-term effects on cognition, emotion, and social functioning. Here, we review the psychoactive ingredients of cannabis, the various methods of consumption, and the range of effects on different brain regions. We also discuss",
        "This paper introduces an approach for future frame prediction in videos by decoupling motion and appearance information using a two-stream CNN. The two-stream CNN splits the video into two branches: one for motion information and one for appearance information. The motion branch learns to predict future motion patterns in the",
        "This paper provides an interesting framework for handling semi-supervised RL tasks, where the agent has access to both labeled and unlabeled data. The main idea is to use the labeled data to learn a reward model, and then use this model to train an actor-critic agent on the unlabeled data. The key insight is that the",
        "This paper proposes a new Bayesian paradigm for estimating the number of clusters in a dataset. The proposed method, called the Bayesian Information Criteria (BIC) for Clustering (BICC), combines the concepts of the Bayesian Information Criteria (BIC) and the Chinese Remainder Theorem (CRT) to provide a comprehensive and flexible framework for identifying the number of clusters in",
        "\nThis papers adds to the literature on learning optimizers/algorithms that has gained significant attention in recent years. The seminal paper by \\citet{snoek2012practical} introduced the Adam optimizer, which has since become a popular choice for many deep learning applications. More recent work has introduced new optimizers, such as RMSProp and Adagrad, as well as variations on",
        "This paper describes a method to estimate likelihood scores for a range of models in a complex statistical analysis. The method uses a Bayesian approach to incorporate all of the available data into the analysis, while also providing an accurate estimate of the uncertainty associated with each model. The method is demonstrated using a real-world example of a",
        "This paper presents new way for compressing images using the Discrete Cosine Transform (DCT) and the Lempel-Ziv-Welch (LZW) algorithm. The DCT is a widely used transform for image compression, which divides the image into a set of coefficients in the frequency domain. The LZW algorithm is a lossless compression algorithm that finds repeated patterns in",
        "This paper presents a training strategy for deep networks.  First, the network is trained in a standard fashion.  Next, the weights of the network are reset, and the network is trained on the original data with a new set of random weights.  This process is repeated multiple times, with the network being trained on the new set",
        "This paper proposes a new memory module for large scale life-long and one-shot learning. The module is general enough to learn multiple tasks and has several desirable properties such as:\n\n1. **Stability**: The module is trained on a large variety of tasks and data, and yet it can learn new tasks quickly and without forgetting previous",
        "This paper presents a clear hierarchical taxonomy of transfer learning methods as applicable in computer vision. The authors provide a comprehensive review of various state-of-the-art transfer learning methods and highlight their strengths, weaknesses, and limitations. By organizing the transfer learning methods into different categories, the authors enable readers to easily understand and identify the",
        "This paper proposes a new gating mechanism to combine word and character representations. The proposed model sets a new state-of-the-art in various benchmark datasets for text classification, sentiment analysis, and keyword extraction. The proposed model is designed to address three major limitations of existing word embeddings: (1) the word-level bias, (2) the",
        "This paper performs a very important service: exploring in a clear and systematic way the performance of different machine learning algorithms on real-world datasets, and assessing their strengths and weaknesses.\nThe authors consider a wide range of datasets and algorithms, and provide a detailed analysis of their performance in terms of accuracy, computational cost, and other relevant metrics.",
        "This paper addresses one of the major shortcomings of generative adversarial networks - their lack of interpretability.\n\nGenerative Adversarial Networks (GANs) have emerged as a powerful tool for generating realistic and diverse synthetic data, such as images and videos. However, one of the major shortcomings of GANs is their lack of interpretability. It is often difficult",
        "This paper presents a novel way of pruning filters from convolutional neural networks (CNNs) that significantly reduces the number of parameters and computations required while maintaining the accuracy of the model.\nPruning is a technique that has been used in various neural network architectures, including CNNs, to improve their efficiency and reduce their computational requirements. The",
        "This paper provides two approaches to question answering: pointing to spans, and use of match-LSTM to answer questions over text.\n\n### Pointing to Spans:\n\nThe authors propose a novel approach to answer questions over text by pointing to the relevant spans of text. This approach involves defining a set of keywords for",
        "This paper proposes a modification of the parametric texture synthesis model of Gatys et al. to take into account long-distance dependencies in the texture image. The proposed model, called Dual-Pyramid Patch-based Texture Synthesis (DPST), uses a dual-pyramid representation of the texture image and a patch-based approach to capture long-distance dependencies. Experimental results demonstrate the effectiveness of",
        "This paper proposed a dynamic coattention network for the question answering task with long contextual documents. \nThe main idea is to use the attention mechanism to focus on the relevant part of the input context, and then use a multi-layer bidirectional transformer encoder to generate a sequence of hidden states that capture",
        "everybody nobody likes the new banner\n\u2014 JT (@JT__72) November 26, 2020\nI am so glad they got rid of that ridiculous banner. It was distracting and took away from the",
        "This paper optimizes autoencoders for lossy image compression. Minimal adaptation of the loss makes autoencoders suitable for this task, as images lose information during transmission or storage. Autoencoders compress images by reducing the number of data points and learn features that encode the most important information in the image.\n\nThe",
        "This paper tests zoneout against a variety of datasets - character level, word level, and phrase level. The results show that zoneout consistently outperforms other password-based password entry methods and is a promising approach for low-resource languages.\nThe results of this paper show that zoneout is a promising method for password entry in low-resource",
        "This paper motivates the combination of autoregressive models with Variational Auto-Encoders and how to control the amount the amount of information stored in the latent code. The authors propose the use of an additional term in the Variational Autoencoders architecture to model the latent code as a hierarchical process and encourage the code to",
        "This paper proposes a method for significantly increasing the number of parameters in a single layer while keeping computation in par with (or even less than) the number of parameters in a deeper network.\nBy introducing a novel activation function, called the \"Multi-Resolution Activation Function\" (MRAF), the proposed method is able to increase the number of parameters in each layer while still",
        "This paper discusses Hyperband, an extension of successive halving by Jamieson & Talwalkar (AISTATS 2017) for solving optimization problems with non-convex constraints. The proposed algorithm hyper-divides the space into smaller subspaces, leading to a more efficient exploration of the search space. Results are shown on several benchmark problems, demonstrating Hyperband's ability to find",
        "This paper introduces the Quasi-Recurrent Neural Network (QRNN) that dramatically limits the computational burden of recurrent neural networks (RNNs) for time series forecasting. The QRNN architecture combines the strengths of traditional RNNs with the efficiency of convolutional neural networks (CNNs). The proposed QRNN consists of a series of",
        "This paper explores ensemble optimisation in the context of policy-gradient training. Ensemble training has been used in machine learning for improving generalization and reducing overfitting, but it can also be used to improve policy-gradient training by combining the predictions of multiple policy gradient models. The paper presents an ensemble of policy gradient methods that",
        "This paper studies the problem of transferring solutions of partial differential equations (PDEs) from a privileged domain to a less privileged one, where the PDEs are not well-posed. Here, we use the method of pseudodifferential operators, which are a generalization of classical differential operators, to transform the PDEs and adapt them to",
        "This paper proposes an approach to learning word vector representations for character sequences and text documents based on the observation that the distribution of word vectors in a vocabulary shapes the overall meaning of a text. The proposed approach leverages the semantic similarity between words and the context in which they appear to learn vector",
        "This paper introduces MusicNet, a new dataset. Application of ML techniques to music have been growing in recent years, with music information retrieval (MIR) being a key area of interest. However, most existing MIR datasets are limited in scope and quality, and often lack a large amount of diverse and structured musical data.\nMusicNet is",
        "This paper applies REINFORCE to learn MCMC proposals within the existing STOKE scheme for super-optimization. It's a nice combination of two existing methods to make the optimization process more efficient. The authors also provide a theoretical analysis of the learned proposal, which is a nice touch and can help with understanding the limitations",
        "This paper presented a method of improving the efficiency of deep networks acting on large datasets by randomly dropping a portion of the input data during training. The technique, called \"dropout,\" was able to learn multiple representations of the data simultaneously, allowing the network to generalize better to new data.\n\nThe main idea behind dropout is to",
        "This paper applies the idea of normalizing flows (NFs), which allows us to build complex densities with tractable likelihoods, to the problem of anomaly detection in multivariate time series data.\nNormalizing Flows (NFs) are a class of generative models that have shown great promise in modeling complex probability distributions. They have been successfully applied to a",
        "This paper focusses on attention for neural language modeling and has two main contributions:\n\n1. We propose a new attention mechanism, called monotonic attention, which reduces the computational complexity of standard attention while maintaining its ability to focus on relevant parts of the input sequence.\n2. We introduce a new training method, called monotonic adversarial training (MAT),",
        "This paper is a by-the-numbers extension of the hidden semi-Markov model to include nonlinear observations, and is based on the following template:\n\n1. Introduction:\n\t* Motivation: The HMM is widely used for latent state modeling, but its basic structure is limited to linear observations.\n\t* Objective: To extend the HMM to model nonlinear observations by incorporating nonlinear",
        "This paper presents a variational inference based method for learning non-parametric Bayesian models from data. Model building is often a challenging task, particularly when working with complex and high-dimensional data sets. This is because traditional Bayesian methods, which rely on Markov chain Monte Carlo (MCMC) algorithms, can be computationally expensive and may",
        "This paper first discusses a general framework for improving optimization of a complex system with multiple conflicting objectives, which is applicable to a wide range of fields, including engineering, economics, social sciences, and computer sciences. The paper then presents several specific applications of this framework, including a case study on the optimization of a",
        "This paper extends preceding works to create a mapping between the word embedding space of two languages. The idea is to learn a mapping that preserves the semantic similarity between words.  The authors use a simple architecture based on an encoder-decoder framework and train it on parallel corpora. The encoder maps English and Spanish",
        "This paper proposes to learn decomposition of sequences (such as words) for speech recognition. It addresses the problem of learning the hierarchical structure of a language, or more specifically, the hierarchical structure of a sequence of words in a language. The main approach is based on the idea of \"comparative sequence\". This approach consists of comparing two sequences",
        "This paper is technically sound. It highlights well the strengths and weaknesses of the proposed simplified climate model (SCM) and it provides a sufficient amount of supporting evidence from the literature. The paper also recognizes and discusses some of the limitations of the SCM, which is a significant strength. However, there are some areas where the",
        "This paper shows how policy gradient and Q-Learning may be combined together, improving learning in Markov decision processes. The policy gradient method, which updates the policy directly according to the gradient of the expected return, has been widely used in reinforcement learning. Q-Learning, which updates the Q-function directly according to the gradient of the expected",
        "This paper clearly lays out the recipe for a family of invertible density models, explores a few extensions of this basic framework, and provides a detailed analysis of the structure of these models. It presents a wealth of examples and a comparison of the different models, allowing the reader to appreciate the trade-offs and applications of each model.",
        "This paper extends batch normalization successfully to RNNs where batch normalization has previously failed or done poorly. Here, we make normalization more flexible and resilient by introducing a novel technique called 'time-resolved batch normalization' that adapts the batch normalization window to the internal dynamics of the RNN. Experimental results on several",
        "This paper describes a way to speed up convergence through sudden increases of otherwise monotonic iterative methods, known as \"surprise\" methods. The unexpected increase in the step size can allow the method to converge more rapidly to the desired solution.\n\nThe paper starts with a gentle introduction, explaining the context and motivation for the",
        "This paper proposes a weakly supervised, end-to-end neural network model for solving a challenging natural language understanding task: question answering (QA). The proposed model, named Weakly-Supervised Neural Question Answering (WSNQA), leverages weak supervision signals, such as in-context examples and seed labels, to learn to predict the answer to a question given a context.",
        "This paper introduces a 'GPU-friendly' variant of A3C which relaxes some synchronicity constraints in the original A3C algorithm, while maintaining its high performance. With the growing trend of using deep learning for tasks beyond image classification, there is a growing need for more efficient and scalable training methods that can take advantage of multi-GPU environments. However,",
        "This paper presents an approach to learn to generate programs. Instead of directly training a model to generate programs like in previous work, we propose to train a model to predict the next token in a sequence of tokens, given the context of the previous tokens. This enables the model to generate programs iteratively, one token at a time.",
        "This paper considers the problem of model-based policy search. The authors \nconsider the use of Bayesian Neural Networks to learn a model of the environment \nand use this model to perform policy search. The key contribution of the \npaper is the introduction of a new tool, called the Upper Confidence Bound \n(UCB)",
        "This paper describes a new way of variable computation, which uses a different number of units depending on the calculation conditions. In traditional computing, a fixed number of units or stages are used for all calculations, regardless of the complexity of the calculation. However, this can lead to inefficiencies, as some calculations require more units than others. In contrast,",
        "This paper examines the impact of business-university collaboration on the innovation performance of firms in the technology industry. Using a dataset of publicly traded firms in the United States, we find that collaborations with universities are positively associated with",
        "This paper proposes the neural noisy channel model, P(x|y), where (x, y) is a input-to-out sequence pair,  x is the input sequence and  y is the output sequence, as a generative model for language. The authors argue that this model can be used to generate coherent and fluent text, and that it has",
        "This paper builds on the work of Weston (2016), using End-to-end memory network to improve the performance of the traditional speech recognition system.\n\nIntroduction:\n\nSpeech recognition has been a fundamental aspect of human-computer interaction for several decades, with the goal of transcribing spoken language into text. Traditional speech recognition systems rely on statistical models, such as Hidden Markov Models (HMMs), to recognise",
        "This paper extends the GAN framework to allow for latent variables. The observed data set is expanded by drawing latent variables z from a conditional distribution q(z|x). The generator and discriminator networks are modified to operate in the latent space, rather than in the original data space. This allows for more flexible and powerful generative models, capable of",
        "This paper introduces a simulator and a set of synthetic tasks for evaluating a dialogue agent's ability to engage in goal-directed dialogue. The simulator is based on a novel graph-based framework for describing and reasoning about dialogue scenarios, and allows for the creation of complex and diverse dialogue scenarios. The tasks are designed",
        "This paper proposes a design principle for computation blocks in convolutional neural networks (CNNs) that enables the computation of spatial pyramid features for image recognition tasks. Here, a computation block is defined as a sequence of layers that process an image and produce a set of feature maps. The proposed design",
        "This paper studies the energy landscape of the loss function in neural networks.  It is generally known that a non-convex loss function can have many local minima, leading to suboptimal performance in deep learning models. The authors propose a new method to visualize the energy landscape of a loss function, which is a map of the optimization path",
        "This paper provides a simple method to handle action repetitions. They make the action a tuple (a,x), where a is the action chosen, and x the number of times the action is repeated.\n\nHere is an example:\n\n* A player chooses an action (a,1) to move one step to the west\n* A player chooses an action (c,3) to move three",
        "This paper proposed a proximal (quasi-) Newton\u2019s method to learn binary DNN. The main contribution is the introduction of a proximal mapping, which enables to include the binary constraint into the optimization process. The proximal mapping is used in conjunction with the classical Newton\u2019s method to solve the optimization problem. The proposed",
        "This paper is a parallel work to Improving Generative Adversarial Networks with Denoising Feature Matching. The main solution of both papers is introducing the concept of denoising feature matching into GANs.\nThe key idea is to use a denoising autoencoder to learn a mapping between the original data and a denoised version of"
    ]
}