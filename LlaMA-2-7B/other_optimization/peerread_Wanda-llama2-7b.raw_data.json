{
    "original": [
        "This paper addresses the problem of disambiguating/linking textual entity\nmentions into a given background knowledge base (in this case, English\nWikipedia).  (Its title and introduction are a little overblown/misleading,\nsince there is a lot more to bridging text and knowledge than the EDL task, but\nEDL is a core part of the overall task nonetheles",
        "This paper presents several weakly supervised methods for developing NERs. The\nmethods rely on some form of projection from English into another language. The\noverall approach is not new and the individual methods proposed are\nimprovements of existing methods. For an ACL paper I would have expected more\nnovel approaches.\n\nOne of the contributions o",
        "This paper describes a rule based approach to time expression extraction. Its\nkey insights are time expressions typically are short and contain at least 1\ntime token. It first recognizes the time token through a combination of\ndictionary lookup, regular expression match with POS tagging information. It\nthen expands the time segment from either dire",
        "This paper presents a neural network-based framework for dialogue state\ntracking.\nThe main contribution of this work is on learning representations of user\nutterances, system outputs, and also ontology entries, all of which are based\non pre-trained word vectors.\nParticularly for the utterance representation, the authors compared two\ndifferent neura",
        "This paper proposes a neural network architecture that represent structural\nlinguistic knowledge in a memory network for sequence tagging tasks (in\nparticular, slot-filling of the natural language understanding unit in\nconversation systems). Substructures (e.g. a node in the parse tree) is encoded\nas a vector (a memory slot) and a weighted sum of t",
        "This paper presents a new dataset with annotations of products coming from\nonline cybercrime forums. The paper is clear and well-written and the\nexperiments are good. Every hypothesis is tested and compared to each other.\n\nHowever, I do have some concerns about the paper:\n\n1. The authors took the liberty to change the font size and the line spacing",
        "This paper introduces UCCA as a target representation for semantic parsing and\nalso describes a quite successful transition-based parser for inference into\nthat representation. I liked this paper a lot. I believe there is a lot of\nvalue simply in the introduction of UCCA (not new, but I believe relatively new\nto this community), which has the poten",
        "This paper proposed a macro discourse structure scheme. The authors carried out\na pilot study annotating a corpus consisting of 97 news articles from Chinese\ntreebank 8.0. They then built a model to recognize the primary-secondary\nrelations and 5 discourse relations (joint, elaboration, sequence, background,\ncause-result) in this corpus.\n\nThe paper",
        "This paper proposes a framework for evaluation of word embeddings based on data\nefficiency and simple supervised tasks. The main motivation is that word\nembeddings are generally used in a transfer learning setting, where evaluation\nis done based on how faster is to train a target model. The approach uses a set\nof simple tasks evaluated in a supervi",
        "This paper delves into the mathematical properties of the skip-gram model,\nexplaining the reason for its success on the analogy task and for the general\nsuperiority of additive composition models. It also establishes a link between\nskip-gram and Sufficient Dimensionality Reduction.\n\nI liked the focus of this paper on explaining the properties of sk",
        "This paper presents a neural sequence-to-sequence model for encoding dialog\ncontexts followed by decoding system responses in open-domain conversations.\nThe authors introduced conditional variational autoencoder (CVAE) which is a\ndeep neural network-based generative model to learn the latent variables for\ndescribing responses conditioning dialog co",
        "This paper compares different ways of inducing embeddings for the task of\npolarity classification. The authors focus on different types of corpora and\nfind that not necessarily the largest corpus provides the most appropriate\nembeddings for their particular task but it is more effective to consider a\ncorpus (or subcorpus) in which a higher concentr",
        "This paper presents a purpose-built neural network architecture for textual\nentailment/NLI based on a three step process of encoding, attention-based\nmatching, and aggregation. The model has two variants, one based on TreeRNNs\nand the other based on sequential BiLSTMs. The sequential model outperforms all\npublished results, and an ensemble with the",
        "This paper proposes a supervised deep learning model for event factuality\nidentification.  The empirical results show that the model outperforms\nstate-of-the-art systems on the FactBank corpus, particularly in three classes\n(CT-, PR+ and PS+).  The main contribution of the paper is the proposal of an\nattention-based two-step deep neural model for e",
        "This paper presents the gated self-matching network for reading comprehension\nstyle question answering. There are three key components in the solution: \n\n(a) The paper introduces the gated attention-based recurrent network to obtain\nthe question-aware representation for the passage. Here, the paper adds an\nadditional gate to attention-based recurre",
        "This paper investigates the cold-start problem in review spam detection. The\nauthors first qualitatively and quantitatively analyze the cold-start problem.\nThey observe that there is no enough prior data from a new user in this\nrealistic scenario. The traditional features fail to help to identify review\nspam. Instead, they turn to rely on the abund",
        "This paper details a method of achieving translation from morphologically\nimpoverished languages (e.g. Chinese) to morphologically rich ones (e.g.\nSpanish) in a two-step process. First, a system translates into a simplified\nversion of the target language. Second, a system chooses morphological features\nfor each generated target word, and inflects t",
        "This paper addresses the network embedding problem by introducing a neural\nnetwork model which uses both the network structure and associated text on the\nnodes, with an attention model to vary the textual representation based on the\ntext of the neighboring nodes.\n\n- Strengths:\n\nThe model leverages both the network and the text to construct the late",
        "This paper describes interesting and ambitious work: the automated conversion\nof Universal Dependency grammar structures into [what the paper calls] semantic\nlogical form representations.  In essence, each UD construct is assigned a\ntarget construction in logical form, and a procedure is defined to effect the\nconversion, working \u2018inside-out\u2019 using ",
        "This paper outlines a method to learn sense embeddings from unannotated corpora\nusing a modular sense selection and representation process. The learning is\nachieved by a message passing scheme between the two modules that is cast as a\nreinforcement learning problem by the authors.\n\n- Strengths:\n\nThe paper is generally well written, presents most of",
        "This paper describes a state-of-the-art CCG parsing model that decomposes into\ntagging and dependency scores, and has an efficient A* decoding algorithm.\nInterestingly, the paper slightly outperforms Lee et al. (2016)'s more\nexpressive global parsing model, presumably because this factorization makes\nlearning easier. It's great that they also repor",
        "This paper presents evaluation metrics for lyrics generation exploring the need\nfor the lyrics to be original,but in a similar style to an artist whilst being\nfluent and co-herent. The paper is well written and the motivation for the\nmetrics are well explained.  \n\nThe authors describe both hand annotated metrics (fluency, co-herence and\nmatch) and ",
        "This paper proposed to explore discourse structure, as defined by Rhetorical\nStructure Theory (RST) to improve text categorization. A RNN with attention\nmechanism is employed to compute a representation of text. The experiments on\nvarious of dataset shows the effectiveness of the proposed method. Below are my\ncomments:\n\n(1) From Table 2, it shows t",
        "This paper proposes joint CTC-attention end-to-end ASR, which utilizes both\nadvantages in training and decoding. \n\n- Strengths:\nIt provides a solid work of hybrid CTC-attention framework in training and\ndecoding, and the experimental results showed that the proposed method could\nprovide an improvement in Japanese CSJ and Mandarin Chinese telephone ",
        "This paper proposes a method for generating datasets of pictures from simple\nbuilding blocks, as well as corresponding logical forms and language\ndescriptions.\nThe goal seems to be to have a method where the complexity of pictures and\ncorresponding desciptions can be controlled and parametrized. \n\n - The biggest downside seems to be that the maxima",
        "This paper propose a general framework for analyzing similarities and\ndifferences in term meaning and representation in different contexts.\n\n- Strengths:\n* The framework proposed in this paper is generalizable and can be applied to\ndifferent applications, and accommodate difference notation of context,\ndifferent similarity functions, different type",
        "This paper modifies existing word embedding algorithms (GloVe, Skip Gram, PPMI,\nSVD) to include ngram-ngram cooccurance statistics. To deal with the large\ncomputational costs of storing such expensive matrices, the authors propose an\nalgorithm that uses two different strategies to collect counts.  \n\n- Strengths:\n\n* The proposed work seems like a na",
        "This paper investigates the application of distributional vectors of meaning in\ntasks that involve the identification of semantic relations, similar to the\nanalogical reasoning task of Mikolov et al. (2013): Given an expression of the\nform \u201cX is for France what London is for the UK\u201d, X can be approximated by\nthe simple vector arithmetic operation L",
        "This paper describes a straightforward extension to left-to-right beam search\nin order to allow it to incorporate lexical constraints in the form of word\nsequences that must appear in MT output. This algorithm is shown to be\neffective for interactive translation and domain adaptation.\n\nAlthough the proposed extension is very simple, I think the pap",
        "This paper introduces a new approach to semantic parsing in which the model is\nequipped with a neural sequence to sequence (seq2seq) model (referred to as the\n\u201cprogrammer\u201d) which encodes a natural language question and produces a\nprogram. The programmer is also equipped with a \u2018key variable\u2019 memory\ncomponent which stores (a) entities in the questio",
        "This paper proposes integrating word sense inventories into existing approaches\nfor the lexical substitution task by using these inventories to filter\ncandidates. To do so, the authors first propose a metric to measure the mutual\nsubstitutability of sense inventories with human judgments for the lexsub task,\nand empirically measure the substitutabi",
        "This paper presents a corpus of annotated essay revisions. \n\nIt includes two examples of application for the corpus:\n\n1) Student Revision Behavior Analysis and 2) Automatic Revision Identification\n\nThe latter is essentially a text classification task using an SVM classifier\nand a variety of features. The authors state that the corpus will be freely",
        "This paper presents a dialogue agent where the belief tracker and the dialogue\nmanager are jointly optimised using the reinforce algorithm. It learns from\ninteraction with a user simulator. There are two training phases. The first is\nan imitation learning phase where the system is initialised using supervising\nlearning from a rule-based model. Then",
        "This paper presents a new state-of-the-art deep learning model for semantic\nrole labeling (SRL) that is a natural extension of the previous\nstate-of-the-art system (Zhou and Xu, 2015) with recent best practices for\ninitialization and regularization in the deep learning literature.\nThe model gives a 10% relative error reduction which is a big gain o",
        "This paper describes several ways to encode arbitrarily long sequences of\ndigits using something called the major system. In the major system, each digit\nis mapped to one or more characters representing consonantal phonemes; the\npossible mappings between digit and phoneme are predefined. The output of an\nencoding is typically a sequence of words co",
        "This paper presents a gated attention mechanism for machine reading. \nA key idea is to extend Attention Sum Reader (Kadlec et al. 2016) to multi-hop\nreasoning by fine-grained gated filter. \nIt's interesting and intuitive for machine reading. \nI like the idea along with significant improvement on benchmark datasets, but\nalso have major concerns to g",
        "This paper proposes to use an encoder-decoder framework for keyphrase\ngeneration. Experimental results show that the proposed model outperforms other\nbaselines if supervised data is available.\n\n- Strengths:\nThe paper is well-organized and easy to follow (the intuition of the proposed\nmethod is clear). It includes enough details to replicate experim",
        "This paper continues the line of work for applying word embeddings for the\nproblem of unsupervised morphological segmentation (e.g. Soricut & Och, 2015;\n\u00dcst\u00fcn & Can, 2016). The proposed method, MORSE, applies a local optimization\nfor segmentation of each word, based on a set of orthographic and semantic\nrules and a few heuristic threshold values as",
        "This paper proposes a simple attention-based RNN model for generating SQL\nqueries from natural language without any intermediate representation. Towards\nthis end they employ a data augmentation approach where more data is\niteratively collected from crowd annotation, based on user feedback on how well\nthe SQL queries produced by the model do. Result",
        "This paper presents a graph-based approach for producing sense-disambiguated\nsynonym sets from a collection of undisambiguated synonym sets.  The authors\nevaluate their approach by inducing these synonym sets from Wiktionary and from\na collection of Russian dictionaries, and then comparing pairwise synonymy\nrelations (using precision, recall, and F",
        "This paper proposes a joint model of salient phrase selection and discourse\nrelation prediction in spoken meeting. Experiments using meeting corpora show\nthat the proposed model has higher performance than the SVM-based classifier.\n\n- Strengths:\nThe paper is written to be easy to read. Technical details are described fully,\nand high performance is ",
        "This paper proposes a method for building dialogue agents involved in a\nsymmetric collaborative task, in which the agents need to strategically\ncommunicate to achieve a common goal.  \n\nI do like this paper.  I am very interested in how much data-driven techniques\ncan be used for dialogue management.  However, I am concerned that the approach\nthat t",
        "This paper proposes an approach for classifying literal and metaphoric\nadjective-noun pairs. The authors create a word-context matrix for adjectives\nand nouns where each element of the matrix is the PMI score. They then use\ndifferent methods for selecting dimensions of this matrix to represent each\nnoun/adjective as a vector. The geometric properti",
        "This paper proposes a novel strategy for zero-resource translation where\n(source, pivot) and (pivot, target) parallel corpora are available. A teacher\nmodel for p(target|pivot) is first trained on the (pivot, target) corpus, then\na student model for p(target|source) is trained to minimize relative entropy\nwith respect to the teacher on the (source,",
        "This paper considers the problem of KB completion and proposes ITransF for this\npurpose. Unlike STransE that assigns each relation an independent matrix, this\npaper proposes to share the parameters between different relations. A model is\nproposed where a tensor D is constructed that contains various relational\nmatrices as its slices and a selection",
        "This paper presents a method for translating natural language descriptions into\nsource code via a model constrained by the grammar of the programming language\nof the source code.  I liked this paper - it's well written, addresses a hard\nand interesting problem by taking advantage of inherent constraints, and shows\nsignificant performance improvemen",
        "This paper focuses on interpreting sarcasm written in Twitter identifying\nsentiment words and then using a machine translation engine to find an\nequivalent not sarcastic tweet. \n\nEDIT: Thank you for your answers, I appreaciate it. I added one line commenting\nabout it.\n\n- Strengths:\n\nAmong the positive aspects of your work, I would like to mention t",
        "This paper describes a system to assist written test scoring.\n\n- Strengths:\nThe paper represents an application of an interesting NLP problem --\nrecognizing textual entailment -- to an important task -- written test scoring.\n\n- Weaknesses:\nThere isn't anything novel in the paper. It consist of an application of an\nexisting technology to a known pro",
        "This paper introduces new configurations and training objectives for neural\nsequence models in a multi-task setting. As the authors describe well, the\nmulti-task setting is important because some tasks have shared information\nand in some scenarios learning many tasks can improve overall performance.\n\nThe methods section is relatively clear and logi",
        "This paper proposed a new phrasal RNN architecture for sequence to sequence\ngeneration. They have evaluated their architecture based on (i) the language\nmodelling test evaluated on PTB and FBIS and (ii) Chinese-English machine\ntranslation task on NIST MT02-08 evaluation sets. The phrasal RNN (pRNN)\narchitecture is achieved by generating subnetworks",
        "This paper proposes new prediction models for Japanese SRL task by adopting the\nEnglish state-of-the-art model of (Zhou and Xu, 2015).\nThe authors also extend the model by applying the framework of Grid-RNNs in\norder to handle the interactions between the arguments of multiple predicates.\n\nThe evaluation is performed on the well-known benchmark dat",
        "This paper develops an LSTM-based model for classifying connective uses for\nwhether they indicate that a causal relation was intended. The guiding idea is\nthat the expression of causal relations is extremely diverse and thus not\namenable to syntactic treatment, and that the more abstract representations\ndelivered by neural models are therefore more",
        "This paper proposes a method for recognizing lexical entailment (specifically,\nhypernymy) in context. The proposed method represents each context by\naveraging, min-pooling, and max-pooling its word embeddings. These\nrepresentations are combined with the target word's embedding via element-wise\nmultiplication. The in-context representation of the le",
        "This paper proposes a method for evaluating topic quality based on using word\nembeddings to calculate similarity (either directly or indirectly via matrix\nfactorisation), achieving impressive results over standard datasets.\n\nThe proposed method represents a natural but important next step in the\nevolutionary path of research on topic evaluation. Th",
        "This paper proposed a very interesting idea of using cognitive features for\nsentiment analysis and sarcasm detection. More specifically, the eye-movement\npatterns of human annotators are recorded to derive a new set of features. The\nauthors claim that this is the first work to include cognitive features into\nthe NLP community. \n\nStrength: \n1. The p",
        "This paper proposes a neural-styled topic model, extending the objective of\nword2vec to also learn document embeddings, which it then constrains through\nsparsification, hence mimicking the output of a topic model.\n\nI really liked the model that the authors proposed, and found the examples\npresented by the authors to be highly promising. What was re",
        "This paper describes four methods of obtaining multilingual word embeddings and\na modified QVEC metric for evaluating the efficacy of these embeddings. The\nembedding methods are: \n\n(1) multiCluster : Uses a dictionary to map words to multilingual clusters.\nCluster embeddings are then obtained which serve as embeddings for the words\nthat reside in e",
        "This paper proposes a method for discovering correspondences between languages\nbased on MDL. The author model correspondences between words sharing the same\nmeaning in a number of Slavic languages. They develop codes for rules that\nmatch substrings in two or more languages and formulate an MDL objective that\nbalances the description of the model an",
        "This paper proposes an approach for multi-lingual named entity recognition\nusing features from Wikipedia. By relying on a cross-lingual Wikifier, it\nidentifies English Wikipedia articles for phrases in a target language and uses\nfeatures based on the wikipedia entry. Experiments show that this new feature\nhelps not only in the monolingual case, but",
        "This paper proposes the new (to my knowledge) step of proposing to treat a\nnumber of sentence pair scoring tasks (e.g. Answer Set Scoring, RTE,\nParaphrasing,\namong others) as instances of a more general task of understanding semantic\nrelations\nbetween two sentences. Furthermore, they investigate the potential of learning\ngenerally-\napplicable neura",
        "This paper presents a transition-based graph parser able to cope with the rich\nrepresentations of a semantico-cognitive annotation scheme, instantiated in the\nUCCA corpora. The authors start first by exposing what, according to them,\nshould cover a semantic-based annotation scheme: (i) being graph-based\n(possibility for a token/node of having multi",
        "This paper presents a Stack LSTM parser based on the work of Henderson et al.\n(2008, 2013) on joint syntactic/semantic transition-based parsing and Dyer et\nal. (2015) on stack LSTM syntactic parsing. The use of the transition system\nfrom the former and the stack LSTM from the latter shows interesting results\ncompared to the joint systems on the CoN",
        "This paper investigates three simple weight-pruning techniques for NMT, and\nshows that pruning weights based on magnitude works best, and that retraining\nafter pruning can recover original performance, even with fairly severe\npruning.\n\nThe main strength of paper is that the technique is very straightforward and\nthe results are good. It\u00e2\u0080\u0099s also cle",
        "This paper presents results on the UD treebanks to test delexicalized transfer\nparsers and an unsupervised parser which is enriched with external\nprobabilities.\n\nThe paper is interesting, but I think it could be improved further.\n\n(5.2) \"McDonald et al. (2011) presented 61.7% of averaged accuracy over 8\nlanguages. On the same languages, our transfe",
        "This paper presents an approach to tag word senses with temporal information\n(past, present, future or atemporal). They model the problem using a\ngraph-based semi-supervised classification algorithm that allows to combine\nitem specific information - such as the presence of some temporal indicators in\nthe glosses - and the structure of Wordnet - tha",
        "This paper models event linking using CNNs. Given event mentions, the authors\ngenerate vector representations based on word embeddings passed through a CNN\nand followed by max-pooling. They also concatenate the resulting\nrepresentations with several word embeddings around the mention. Together with\ncertain pairwise features, they produce a vector o",
        "This paper describes a new deterministic dependency parsing algorithm and\nanalyses its behaviour across a range of languages.\nThe core of the algorithm is a set of rules defining permitted dependencies\nbased on POS tags.\nThe algorithm starts by ranking words using a slightly biased PageRank over a\ngraph with edges defined by the permitted dependenc",
        "This paper improves significantly upon the original NPI work, showing that the model generalizes far better when trained on traces in recursive form. The authors show better sample complexity and generalization results for addition and bubblesort programs, and add two new and more interesting tasks - topological sort and quicksort (added based on r",
        "This paper extends an approach to rate-distortion optimization to deep encoders and decoders, and from a simple entropy encoding scheme to adaptive entropy coding. In addition, the paper discusses the approach\u2019s relationship to variational autoencoders.\n\nGiven that the approach to rate-distortion optimization has already been published, the novelty",
        "This paper describes a new approach to meta learning by interpreting the SGD update rule as gated recurrent model with trainable parameters. The idea is original and important for research related to transfer learning. The paper has a clear structure, but clarity could be improved at some points.\n\nPros:\n\n- An interesting and feasible approach to me",
        "This paper was submitted to arXiv last week:\n\n",
        "This paper makes a valuable contribution to provide a more clear understanding of generative adversarial network (GAN) training procedure. \n\nWith the new insight of the training dynamics of GAN, as well as its variant, the authors reveal the reason that why the gradient is either vanishing in original GAN or unstable in its variant. More importantl",
        "This paper proposes a way of adding unsupervised auxiliary tasks to a deep RL agent like A3C. Authors propose a bunch of auxiliary control tasks and auxiliary reward tasks and evaluate the agent in Labyrinth and Atari. Proposed UNREAL agent performs significantly better than A3C and also learns faster. This is definitely a good contribution to the ",
        "This paper proposed to use RL and RNN to design the architecture of networks for specific tasks. The idea of the paper is quite promising and the experimental results on two datasets show that method is solid.\nThe pros of the paper are:\n1. The idea of using RNN to produce the description of the network and using RL to train the RNN is interesting a",
        "This paper details the approach that won the VizDoom competition - an on-policy reinforcement learning approach that predicts auxiliary variables, uses intrinsic motivation, and is a special case of a universal value function. The approach is a collection of different methods, but it yields impressive empirical results, and it is a clear, well-writ",
        "This paper proposes learning on the fly to represent a dialog as a graph (which acts as the memory), and is first demonstrated on the bAbI tasks. Graph learning is part of the inference process, though there is long term representation learning to learn graph transformation parameters and the encoding of sentences as input to the graph. This seems ",
        "This paper proposes to investigate attention transfers between a teacher and a student network. \n\nAttention transfer is performed by minimising the l2 distance between the teacher/student attention maps at different layers, in addition to minimising the classification loss and optionally a knowledge distillation term.\nAuthors define several activat",
        "This paper investigates the benefits of visual servoing using a learned\nvisual representation. The authors  propose to first learn an action-conditional\nbilinear model of the visual features (obtained from a pre-trained VGG net) from\nwhich a policy can be derived using a linearization of the dynamics. A multi-scale,\nmulti-channel and locally-connec",
        "This paper proposes a nonparametric neural network model, which automatically learns the size of the model during the training process. The key idea is to randomly add zero units and use sparse regularizer to automatically null out the weights that are irrelevant. The idea sounds to be a random search approach over discrete space with the help of s",
        "This paper prunes entire groups of filters in CNN so that they reduce computational cost and at the same time do not result in sparse connectivity. This result is important to speed up and compress neural networks while being able to use standard fully-connected linear algebra routines. \nThe results are a 10% improvements in ResNet-like and ImageNe",
        "This paper is well written, and well presented. This method is using denoise autoencoder to learn an implicit probability distribution helps reduce training difficulty, which is neat. In my view, joint training with an auto-encoder is providing extra auxiliary gradient information to improve generator. Providing auxiliary information may be a metho",
        "This paper presents an approach for skills transfer from one task to another in a control setting (trained by RL) by forcing the embeddings learned on two different tasks to be close (L2 penalty). The experiments are conducted in MuJoCo, with a set of experiments being from the state of the joints/links (5.2/5.3) and a set of experiments on the pix",
        "This paper proposes a model to learn across different views of objects.  The key insight is to use a triplet loss that encourages two different views of the same object to be closer than an image of a different object.  The approach is evaluated on object instance and category retrieval and compared against baseline CNNs (untrained AlexNet and Alex",
        "This paper proposed a neural attention model which has a learnable and differentiable sampling lattice. The work is well motivated as few previous work focus on learning the sampling lattice but with a fixed lattice. This work is quite similar to Spatial Transformer Networks (Jaderberg 2015), but the sampling lattice is learned by the model. The ex",
        "This paper presents an information theoretic framework for unsupervised learning. The framework relies on infomax principle, whose goal is to maximize the mutual information between input and output. The authors propose a two-step algorithm for learning in this setting. First, by leveraging an asymptotic approximation to the mutual information, the",
        "This paper provides a new perspective to understanding the ResNet and Highway net. The new perspective assumes that the blocks inside the networks with residual or skip-connection are groups of successive layers with the same hidden size, which performs to iteratively refine their estimates of the same feature instead of generate new representation",
        "This paper not only shows that a cache model on top of a pre-trained RNN can improve language modeling, but also illustrates a shortcoming of standard RNN models in that they are unable to capture this information themselves. Regardless of whether this is due to the small BPTT window (35 is standard) or an issue with the capability of the RNN itsel",
        "This paper proposed a novel adversarial framework to train a model from demonstrations in a third-person perspective, to perform the task in the first-person view. Here the adversarial training is used to extract a novice-expert (or third-person/first-person) independent feature so that the agent can use to perform the same policy in a different vi",
        "This paper combines variational RNN (VRNN) and domain adversarial networks (DANN) for domain adaptation in the sequence modelling domain.  The VRNN is used to learn representations for sequential data, which is the hidden states of the last time step.  The DANN is used to make the representations domain invariant, therefore achieving cross domain a",
        "This paper introduces a novel method for language modeling which is suitable for both modeling programming language as well as natural language. The approach uses a program synthesis algorithm to search over program space and uses count-based estimation of the weights of the program. This is a departure from neural network-based approaches which re",
        "This paper provides a principled and practical formulation for weight-sharing and quantization, using a simple mixture of Guassians on the weights, and stochastic variational inference. The main idea and results are presented clearly, along with illustrative side-experiments showing the properties of this method in practice. Also, the method is ill",
        "This paper essentially presents a new inductive bias in the architecture of (convolutional) neural networks (CNN). The mathematical motivations/derivations of the proposed architecture are detailed and rigorous. The proposed architecture promises to produce equivariant representations with steerable features using fewer parameters than traditional ",
        "This paper proposed an integration of memory network with reinforcement learning. The experimental data is simple, but the model is very interesting and relatively novel. There are some questions about the model:\n\n1. how does the model extend to the case with multiple variables in a single sentence?\n\n2. If the answer is out of vocabulary, how would",
        "This paper presents an interesting take on getting an ensemble for free whilst training a single network. However, your main accuracy comparison seems to exclude traditional ensemble methods, save for the very end of section 4.3, where the actual ensemble method you used is not mentioned. I would advise expanding this paragraph to explain what ense",
        "This paper introduces an approach for future frame prediction in videos by decoupling motion and content to be encoded separately, and additionally using multi-scale residual connections. Qualitative and quantitative results are shown on KTH, Weizmann, and UCF-101 datasets.\n\nThe idea of decoupling motion and content is interesting, and seems to wor",
        "This paper provides an interesting framework for handling semi-supervised RL problems, settings were one can interact with many MDPs drawn from some class, but where only a few have observable rewards; the agent then uses a policy derived from the labeled MDPs to estimate a reward function for the unlabeled MDPs. The approach is straightforward, an",
        "This paper proposes a new Bayesian neural network architecture for predicting the values of learning curves during the training of machine learning models. This is an exploratory paper, in that the ultimate goal is to use this method in a Bayesian optimization system, but for now the experiments are limited to assessing the quality of the predictio",
        "\nThis papers adds to the literature on learning optimizers/algorithms that has gained popularity recently. The authors choose to use the framework of guided policy search at the meta-level to train the optimizers. They also opt to train on random objectives and assess transfer to a few simple tasks.\n\nAs pointed below, this is a useful addition.\n\nHo",
        "This paper describes a method to estimate likelihood scores for a range of models defined by a decoder.\n \n This work has some issues. The paper mainly applies existing ideas. As discussed on openreview, the isotropic Gaussian noise model used to create a model with a likelihood is questionable, and it's unclear how useful likelihoods are when model",
        "This paper presents new way for compressing CNN weights. In particular this paper uses a new neural network quantization method that compresses network weights to ternary values.\nThe group has recently published multiple paper on this topic, and this one offers possibly the lowest returns I have seen. Only a fraction of percentage in ImageNet. Resu",
        "This paper presents a training strategy for deep networks.  First, the network is trained in a standard fashion.  Second, small magnitude weights are clamped to 0; the rest of the weights continue to be trained.  Finally, all the weights are again jointly trained.  Experiments on a variety of image, text, and speech datasets demonstrate the approac",
        "This paper proposes a new memory module for large scale life-long and one-shot learning. The module is general enough that the authors apply the module to several neural network architectures and show improvements in performance.\n\nUsing k-nearest neighbors for memory access is not completely new. This has been recently explored in Rae et al., 2016 ",
        "This paper presents a clear hierarchical taxonomy of transfer learning methods as applicable to sequence tagging problems. This contextualizes and unifies previous work on specific instances of this taxonomy. Moreover, the paper shows that previously unexplored places in this taxonomy are competitive with or superior to the state of the art in key ",
        "This paper proposes a new gating mechanism to combine word and character representations. The proposed model sets a new state-of-the-art on the CBT dataset; the new gating mechanism also improves over scalar gates without linguistic features on SQuAD and a twitter classification task. \n\nIntuitively, the vector-based gate working better than the sca",
        "This paper performs a very important service: exploring in a clear and systematic way the performance and trainability characteristics of a set of neural network architectures -- in particular, the basic RNN motifs that have recently been popular.   \n\nPros:\n\n* This paper addresses an important question I and many others would have liked to know the",
        "This paper addresses one of the major shortcomings of generative adversarial networks - their lack of mechanism for evaluating held-out data. While other work such as BiGANs/ALI address this by learning a separate inference network, here the authors propose to change the GAN objective function such that the optimal discriminator is also an energy f",
        "This paper presents a novel way of pruning filters from convolutional neural networks with a strong theoretical justification. The proposed methods is derived from the first order Taylor expansion of the loss change while pruning a particular unit. This leads to simple weighting of the unit activation with its gradient w.r.t. loss function and perf",
        "This paper provides two approaches to question answering: pointing to spans, and use of match-LSTM. The models are evaluated on SQuAD and MSMARCO. The reviewers we satisfied that, with the provision of additional comparisons and ablation studies submitted during discussion, the paper was acceptable to the conference, albeit marginally so.",
        "This paper proposes a modification of the parametric texture synthesis model of Gatys et al. to take into account long-range correlations of textures. To this end the authors add the Gram matrices between spatially shifted feature vectors to the synthesis loss. Some of the synthesised textures are visually superior to the original Gatys et al. meth",
        "This paper proposed a dynamic coattention network for the question answering task with long contextual documents. \nThe model is able to encode co-dependent representations of the question and the document, and a dynamic decoder iteratively pointing the potential answer spans to locate the final answer. \n\nOverall, this is a well-written paper. \nAlth",
        "This paper fairly",
        "This paper optimizes autoencoders for lossy image compression. Minimal adaptation of the loss makes autoencoders competitive with JPEG2000 and computationally efficient, while the generalizability of trainable autoencoders offers the added promise of adaptation to new domains without domain knowledge.\n The paper is very clear and the authors have t",
        "This paper tests zoneout against a variety of datasets - character level, word level, and pMNIST classification - showing applicability in a wide range of scenarios. While zoneout acts as a regularizer to prevent overfitting, it also has similarities to residual connections. The continued analysis of this aspect, including analyzing how the gradien",
        "This paper motivates the combination of autoregressive models with Variational Auto-Encoders and how to control the amount the amount of information stored in the latent code. The authors provide state-of-the-art results on MNIST, OMNIGLOT and Caltech-101.\nI find that the insights provided in the paper, e.g. with respect to the effect of having a m",
        "This paper proposes a method for significantly increasing the number of parameters in a single layer while keeping computation in par with (or even less than) current SOTA models. The idea is based on using a large mixture of experts (MoE) (i.e. small networks), where only a few of them are adaptively activated via a gating network. While the idea ",
        "This paper discusses Hyperband, an extension of successive halving by Jamieson & Talwalkar (AISTATS 2016). Successive halving is a very nice algorithm that starts evaluating many configurations and repeatedly cuts off the current worst half to explore many configuration for a limited budget.\n\nHaving read the paper for the question period and just r",
        "This paper introduces the Quasi-Recurrent Neural Network (QRNN) that dramatically limits the computational burden of the temporal transitions in\nsequence data. Briefly (and slightly inaccurately) model starts with the LSTM structure but removes all but the diagonal elements to the transition\nmatrices. It also generalizes the connections from lower ",
        "This paper explores ensemble optimisation in the context of policy-gradient training. Ensemble training has been a low-hanging fruit for many years in the this space and this paper finally touches on this interesting subject. The paper is well written and accessible. In particular the questions posed in section 4 are well posed and interesting.\n\nTh",
        "This paper studies the problem of transferring solutions of existing tasks to tackle a novel task under the framework of reinforcement learning and identifies two important issues of avoiding negative transfer and being selective transfer. The proposed approach is based on a convex combination of existing solutions and the being-learned solution to",
        "This paper proposes an approach to learning word vector representations for character sequences and acoustic spans jointly. The paper is clearly written and both the approach and experiments seem reasonable in terms of execution. The motivation and tasks feel a bit synthetic as it requires acoustics spans for words that have already been segmented ",
        "This paper introduces MusicNet, a new dataset. Application of ML techniques to music have been limited due to scarcity of exactly the kind of data that is provided here: meticulously annotated, carefully verified and organized, containing enough \"hours\" of music, and where genre has been well constrained in order to allow for sufficient homogeneity",
        "This paper applies REINFORCE to learn MCMC proposals within the existing STOKE scheme for super-optimization. It's a neat paper, with interesting results.\n \n It's not clear whether interesting representations are learned, and the algorithms are not really new. However, it's a neat piece or work, that some ICLR reviewers found interesting, and could",
        "This paper presented a method of improving the efficiency of deep networks acting on a sequence of correlated inputs, by only performing the computations required to capture changes between adjacent inputs. The paper was clearly written, the approach is clever, and it's neat to see a practical algorithm driven by what is essentially a spiking netwo",
        "This paper applies the idea of normalizing flows (NFs), which allows us to build complex densities with tractable likelihoods, to maximum entropy constrained optimization.\n\nThe paper is clearly written and is easy to follow.\n\nNovelty is a weak factor in this paper. The main contributions come from (1) applying previous work on NFs to the problem of",
        "This paper focusses on attention for neural language modeling and has two major contributions:\n\n1. Authors propose to use separate key, value, and predict vectors for attention mechanism instead of a single vector doing all the 3 functions. This is an interesting extension to standard attention mechanism which can be used in other applications as w",
        "This paper is a by-the-numbers extension of the hidden semi-Markov model to include nonlinear observations, and neural network-based inference. The paper is fairly clear, although the English isn't great. The experiments are thorough.\n \n Where this paper really falls down is on originality. In particular, in the last two years there have been relat",
        "This paper presents a variational inference based method for learning nonlinear dynamical systems. Unlike the deep Kalman filter, the proposed method learns a state space model, which forces the latent state to maintain all of the information relevant to predictions, rather than leaving it implicit in the observations. Experiments show the proposed",
        "This paper first discusses a general framework for improving optimization of a complicated function using a series of approximations. If the series of approximations are well-behaved compared to the original function, the optimization can in principle be sped up. This is then connected to a particular formulation in which a neural network can behav",
        "This paper extends preceding works to create a mapping between the word embedding space of two languages. The word embeddings had been independently trained on monolingual data only, and various forms of bilingual information is used to learn the mapping. This mapping is then used to measure the precision of translations.\n\nIn this paper, the author",
        "This paper proposes to learn decomposition of sequences (such as words) for speech recognition. It addresses an important issue and I forsee it being useful for other applications such as machine translation. While the approach is novel and well-motivated, I would very much like to see a comparison against byte pair encoding (BPE). BPE is a very na",
        "This paper is technically sound. It highlights well the strengths and weaknesses of the proposed simplified model.\n\nIn terms of impact, its novelty is limited, in the sense that the authors did seemingly the right thing and obtained the expected outcomes. The idea of modeling deep learning computation is not in itself particularly novel. As a compa",
        "This paper shows how policy gradient and Q-Learning may be combined together, improving learning as demonstrated in particular in the Atari Learning Environment. The core idea is to note that entropy-regularized policy gradient leads to a Boltzmann policy based on Q values, thus linking pi & Q together and allowing both policy gradient and Q-Learni",
        "This paper clearly lays out the recipe for a family of invertible density models, explores a few extensions, and demonstrates the overall power of the approach. The work is building closely on previous approaches, so it suffers a bit in terms of originality. However, I expect this overall approach to become a standard tool for model-building.\n \n Th",
        "This paper extends batch normalization successfully to RNNs where batch normalization has previously failed or done poorly. The experiments and datasets tackled show definitively the improvement that batch norm LSTMs provide over standard LSTMs. They also cover a variety of examples, including character level (PTB and Text8), word level (CNN questi",
        "This paper describes a way to speed up convergence through sudden increases of otherwise monotonically decreasing learning rates. Several techniques are presented in a clear way and parameterized method is proposed and evaluated on the CIFAR task. The concept is easy to understand and the authors chose state-of-the-art models to show the performanc",
        "This paper proposes a weakly supervised, end-to-end neural network model for solving a challenging natural language understanding task. \nAs an extension of the Neural Programmer, this work aims at overcoming the ambiguities imposed by natural language. \nBy predefining a set of operations, the model is able to learn the interface between the languag",
        "This paper introduces a 'GPU-friendly' variant of A3C which relaxes some synchronicity constraints in the original A3C algorithm to make it more friendly to a high-throughput GPU device. The analysis of the effects of this added latency is thorough. The systems analysis of the algorithm is extensive. \n\nOne caveat is that the performance figures in ",
        "This paper presents an approach to learn to generate programs. Instead of directly trying to generate the program, the authors propose to train a neural net to estimate a fix set of attributes, which then condition a search procedure. This is an interesting approach, which make sense, as building a generative model of programs is a very complex tas",
        "This paper considers the problem of model-based policy search. The authors \nconsider the use of Bayesian Neural Networks to learn a model of the environment\nand advocate for the $\\alpha$-divergence minimization rather than the more usual \nvariational Bayes. \n\nThe ability of alpha-divergence to capture bi-modality however \ncomes at a price and most ",
        "This paper describes a new way of variable computation, which uses a different number of units depending on the input. This is different from other methods for variable computation that compute over multiple time steps. The idea is clearly presented and the results are shown on LSTMs and GRUs for language modeling and music prediction.\n \n Pros:\n - ",
        "This paper discussses applying an information bottleneck to deep networks using a variational lower bound and reparameterization trick. The paper is well written and the examples are compelling. The paper can be improved with more convincing results on MNIST.",
        "This paper proposes the neural noisy channel model, P(x|y), where (x, y) is a input-to-out sequence pair,  based on the authors' previous work on segment to segment neural transduction (SSNT) model. For the noisy channel model, the key difference from sequence-to-sequence is that the complete sequence y is not observed beforehand. SSNT handles this",
        "This paper builds on the work of Weston (2016), using End-to-end memory network models for a limited form of dialogue with teacher feedback. As the authors state in the comments, it is closely related to the question answering problem with the exception that a teacher provides a response after the model\u2019s answer, which does not always come with a p",
        "This paper extends the GAN framework to allow for latent variables. The observed data set is expanded by drawing latent variables z from a conditional distribution q(z|x). The joint distribution on x,z is then modeled using a joint generator model p(x,z)=p(z)p(x|z).  Both q and p are then trained by trying to fool a discriminator. This constitutes ",
        "This paper introduces a simulator and a set of synthetic tasks for evaluating a dialogue agent's ability to learn from user feedback. For solving these tasks, the paper uses memory networks (Sukhbaatar et al., 2015) learned through previously proposed supervised learning and reinforcement learning methods. In this setup, it is demonstrated that the",
        "This paper proposes a design principle for computation blocks in convolutional networks based on repeated application of expand and join operations resulting in a fractal-like structure. \n\nThis paper is primarily about experimental evaluation, since the objective is to show that a residual formulation is not necessary to obtain good performance, at",
        "This paper studies the energy landscape of the loss function in neural networks.  It is generally clearly written and nicely provides intuitions for the results.  One main contribution is to show that the level sets of the loss becomes connected as the network is increasingly overparameterized.  It also quantifies, in a way, the degree of disconnec",
        "This paper provides a simple method to handle action repetitions. They make the action a tuple (a,x), where a is the action chosen, and x the number of repetitions. Overall they report some improvements over A3C/DDPG, dramatic in some games, moderate in other. The idea seems natural and there is a wealth of experiment to support it.\n\nComments:\n\n- T",
        "This paper proposed a proximal (quasi-) Newton\u2019s method to learn binary DNN. The main contribution is to combine pre-conditioning with binarization in a proximal framework. It is interesting to have a proximal Newton\u2019s method to interpret the different DNN binarization schemes. This gives a new interpretation of existing approaches. However, the th",
        "This paper is a parallel work to Improving Generative Adversarial Networks with Denoising Feature Matching. The main solution of both papers is introducing autoencoder into discriminator to improve the stability and quality of GAN. Different to Denoising Feature Matching, EBGAN uses encoder-decoder instead of denoising only, and use hingle loss to "
    ],
    "sampled": [
        "This paper addresses the problem of disambiguating/linking textual entity\nmentions into a given background knowledge base (in this case, English Wikipedia).\nWe use statistical methods to determine whether a piece of text refers to the Wikipedia article\nwith the same name or is instead describing an altogether different entity. There are similar challenges\nof character disambiguation,",
        "This paper presents several weakly supervised methods for developing NERs. The\nmethods are evaluated on a benchmark dataset, showing that when weak supervision is achieved by\nuser input, the methods out-perform state-of-the-art methods trained on the full dataset (i.e., supervised\nby gold standard labels).\nThis paper presents weakly supervised neural network (NER) models that",
        "This paper describes a rule based approach to time expression extraction. Its motivation is the need for more efficient generation of text based representations of time expression. To this end, the rule set has been adapted to the needs of the European Computer Dendrite Agreement (ECDA) and used successfully during recent",
        "This paper presents a neural network-based framework for dialogue state\ntracking.\nThe main problem considered is that of being able to learn an initial representation of dialogue states and dialogue\nstate changes when dialogue examples are presented for teaching. This representation is built by a neural network",
        "This paper proposes a neural network architecture that represent structural\nlinguistic knowledge in a memory network for sequence tagging tasks. The\ntraining set is comprised of a large amount of tag errors for the vast majority\nof words within the training set. The training set is comprised of data from the WikiSpecies project",
        "This paper presents a new dataset with annotations of products coming from\nonline cybercrime forums. The paper reports an analysis of its corpus.\nThe analysis was conducted by employing two machine-learning techniques: i)\nthe bag-of-words model and ii) the text classification via frequency analysis technique.\nThe results of this study are:\ni) The cybercrime user groups that publish their cybercrime-related\nmaterial",
        "This paper introduces UCCA as a target representation for semantic parsing and\nalso describes a method for training a semantic parsimonious representation. It is then\ndemonstrated in different settings such as in ontological mappings, question answering or\nsearching with text-grounding, including results obtained from the 2009 SemWeb\nChallenge. The paper ends by showing that UCCA-represented sentences are more",
        "This paper proposed a macro discourse structure scheme. The authors carried out\na pilot study annotating a corpus consisting of 97 news articles from a\nsingle national newspaper that covered a major political scandal. The\nresearch team tested the scheme in the annotated corpus to validate that their\ntheoretical scheme",
        "This paper proposes a framework for evaluation of word embeddings based on data\nefficiency, i.e. the proportion of data points sampled to represent a lexicon of interest.\nEmbedding spaces are introduced in order to quantify this efficiency, and a\nframework for comparing different spaces is formalised in terms of data efficiency.\nThe framework is then evaluated by comparing different",
        "This paper delves into the mathematical properties of the skip-gram model,\nexplaining the reason for its recent uptake. It goes on to present how well it performs in relation with models such as BERT and GPT-3. It is meant to stimulate the curiosity of the reader by opening some windows of",
        "This paper presents a neural sequence-to-sequence model for encoding dialog\ncontext models by neural networks. Our model encodes dialog context models that\nare composed of phrases formed by concatenating pairs of words. The input to the\ncomputational model is an index of the user's",
        "This paper compares different ways of inducing embeddings for the task of\npolar-directed embedding, defined as the closest embedding of a data point to the center of the 180\u00b0 sphere. A key observation made with polar directed embeddings is that the best embedding is not always the same for all points in",
        "This paper presents a purpose-built neural network architecture for textual\nentailment/NLI based on a three step process of encoding, decision and evaluation,\neach implemented according to principles of a learning model. We employ the architecture\ndesigned for neural networks in the form of a multi-layer perceptron, where the number\nof layers",
        "This paper proposes a supervised deep learning model for event factuality\nidentification.  The empirical results show that the model outperforms the state-of-the-art in event factuality classification task achieved by machine learning methods.\nThe supervised deep learning framework and associated empirical evaluation can serve as a building block in developing models that",
        "This paper presents the gated self-matching network for reading comprehension\nstyle question answering.\nThe proposed gated SMN consists of two main phases, namely \u201cSentence-phase\u201d and the\n\u201cAnswer-phase\u201d. For a given sentence, a subset of SMN features is activated in the\n\u201cSentence-phase\u201d. The activated features are then matched with the",
        "This paper investigates the cold-start problem in review spam detection. The\nauthors first qualitatively analysed the most widely used datasets on the web. They found\nthat the cold-start problem was significantly larger. Then they used a spam set as training dataset\nand validated some techniques.\nChen and Li studied the cold-start problem in spam detection",
        "This paper details a method of achieving translation from morphologically\nimpoverished languages (e.g. Chinese) to morphologically richer (e.g. English)\nusing both a computer program and the participant. As the first step of a two-\nstep procedure we provide a method for translating into an initial machine\ntranslation that we call",
        "This paper addresses the network embedding problem by introducing a neural\nnetwork model which uses neural networks for different stages of embedding.\nIn the recent years, the concept of neural network embedding\nhas been introduced with the aim to embed the network and to produce an\nembedding vector which can be used as a feature for",
        "This paper describes interesting and ambitious work: the automated conversion\nof Universal Dependencies from Japanese into Spanish, which was designed to support both teaching and research. Some background and features of UDep are described in Sec. II. An overview of Universal Dependency is given in Sec. III. The",
        "This paper outlines a method to learn sense embeddings from unannotated corpora\nusing a modular strategy from the GENSEC project.\nIt describes two different sense embeddings that can be derived from the project\ndataset, and it outlines how the modules present a flexible system that can\nbe adjusted to any situation, from language modelling",
        "This paper describes a state-of-the-art CCG parsing model that decomposes into\ntagging and dependency scores, and has an efficient parallel implementation.\nWe present a comparison between our model and a conventional\ngrammar parser that contains three of the most common parsers: head\ndependency scoring, LFG head and non-head scoring,",
        "This paper presents evaluation metrics for lyrics generation exploring the need\nfor the lyrics to be original,but in a similar style to the existing songs.\nThe metrics explore the originality of lyrics and the style similarity to the existing songs.\nHowever, the work focuses on only the originality. In the future, the authors plan to extend\nthe",
        "This paper proposed to explore discourse structure, as defined by Rhetorical\nStructure Theory (RST) to improve text categorization. While RST has been well-received as\ntheory, it has been heavily criticized. Many researchers in the NLP community have reported RST\nas their method of choice in the creation of text classifiers and, especially, text",
        "This paper proposes joint CTC-attention end-to-end ASR, which utilizes both\nadvantages in training and decoding. The CTC is used for decoding by using the\ninterlinear representation, while the attention model is able to efficiently represent\nboth speech, audio and text signals with limited computational resources.\nThe proposed ASR system is able",
        "This paper proposes a method for generating datasets of pictures from simple\nbuilding blocks, as well as methods for automatic verification and debugging.\nIt has been applied in several automatic verification tools that verify if it is\npossible to obtain images (such verification tools were built to deal with image\ndata in large scale distributed systems",
        "This paper propose a general framework for analyzing similarities and\ndifferences in software quality, by adapting the Quality Assurance\n(QA) framework for software development to also include Quality of\nService (QoS). The authors believe that for service-oriented software systems\nit is useful to perform analysis on a",
        "This paper modifies existing word embedding algorithms (GloVe, Skip Gram, PPMI,\nSVD) to include ngram-ngram, ngram-word, and word-word pairings as well as the computation methods for ngrams. The modifications are primarily applied to the two word embedding algorithms PPMI and SVDP, and we find the resulting approaches allow for the",
        "This paper investigates the application of distributional vectors of meaning in\ntasks that involve the identification of semantic properties that are common to many items.\nWe test the use of two semantic vectors: semantic similarity vectors, which are derived by applying the Gauss-Saratow Algorithm to semantic data; and semantic commonality vectors, which are based on",
        "This paper describes a straightforward extension to left-to-right beam search\nin order to improve the output. We will keep left-to-right beam search.\nHowever, we will have a new variable lr_pos, which will be reset back\nto being zero at the end of left-to-right beam search in addition to\nhaving a value of 39 or 27",
        "This paper introduces a new approach to semantic parsing in which the model is\nequipped with a neural sequence to sequence encoder and takes as additional input a rich context embedding. While the sequence to sequence encoder outputs embeddings for each word generated as a result of parsing from a sentence to a",
        "This paper proposes integrating word sense inventories into existing approaches\nfor the lexical substitution of a phrase by means of an adjective. Specifically, we\nintroduce the Adjective Lexical Substitution Machine (ALSM), a data structure that\ncontains adjective lexical units, semantic information about them, and a set of algorithms\nutilized to generate",
        "This paper presents a corpus of annotated essay revisions. \n\nIt includes two examples of application for the annotation scheme. The annotation corpus is presented along with two annotated student essays. The first student essay was annotated using the annotation scheme that was designed for the second iteration of the system (second",
        "This paper presents a dialogue agent where the belief tracker and the dialogue\nmanager are jointly trained using an architecture that combines the features of Generative Modelling (GM) and Learning with a Simulated Environment (LwSE). We propose using Multi-Objective Belief Tracker (MOBT) to provide an approximate measure of the knowledge contained",
        "This paper presents a new state-of-the-art deep learning model for semantic\nrole labeling (SRL) that is a natural extension of the previous\ndeep learning models proposed by authors at INI. First, several\nexperiencial models were proposed on INI datasets for\nSRL and for semantic segmentation. Based on the good model\nperformance, we consider semantic super-classes in",
        "This paper describes several ways to encode arbitrarily long sequences of\ndigits using something which looks and behaves like an index into a dictionary. We\nuse this type of encoding system for a specific type of problem involving long codes for\nnationals in Europe.\nThere are several such index-based encoding schemes. Each one presents slightly",
        "This paper presents a gated attention mechanism for machine reading. \nA key idea is to extend Attention Sum Reader (Kadlec et al. 2000) to the specific problem of machine reading. Attention Sum Reader takes as input a sequence of regions of a scene.\nAt each iteration, the algorithm starts by sorting the regions based",
        "This paper proposes to use an encoder-decoder framework for keyphrase\ngeneration. Experimental results show that the proposed model outperforms the state-the-art by a significant margin. These superior results make for new opportunities and challenges in this domain.\nThis paper shows how the encoder-decoder model can be used to",
        "This paper continues the line of work for applying word embeddings for the\nproblem of unsupervised morphological segmentation (e.g. Soricut & Och, 2015a;\nChen et al., 2015; Aure, Martens & Belthasar, 2015; Mimou, D'Alvydars, Belthazer &\nGarbin, 2016; Zhao et al., 2015). After segmenting the morphologically complex terms in\na word embedding, such words now carry",
        "This paper proposes a simple attention-based RNN model with the convolutional layers. As we show below, this convolutional RNN model can be trained by backpropagating through several layers of the network. This would mean that the layers are akin to one-dimensional, even though the layers can be seen as",
        "This paper presents a graph-based approach for producing sense-disambiguated\nsynonym sets from a collection of Wikipedia synonym lists. This is motivated by the fact that there\nis a relatively large discrepancy between the entries present in Wikipedia and official lexicons\nsuch as SOWPO and LDOCE. The issue is",
        "This paper proposes a joint model of salient phrase selection and discourse\nrelation prediction in spoken meeting data. The joint model adopts a simple probabilistic model and a linear regression model. It is the latter model that is more appropriate to this task than the former. For the former, while",
        "This paper proposes a method for building dialogue agents involved in a\nsymmetric collaborative task, in which the agents know only their environment.\nMore concretely, we assume that each agent has access to a dialogue manager that\ncontains the information that the current task has been assigned to it. This\ndialogue manager further contains the information about other agents with",
        "This paper proposes an approach for classifying literal and metaphoric\nadjective-noun pairs. The authors create a classification model capable of identifying the\nclass a text belongs to by considering its syntactic components. To do so, the authors look\nfirst to adverbs to represent the class of text and distinguish literal adjectives and",
        "This paper proposes a novel strategy for zero-resource translation where\n(source, pivot) and (pivot, target) parallel corpora are available. In\nparticular, we present (pivot, target), which provides source sentences at the\npivot sentence. We investigate the impact of pivot sentences for translation by\nstudying source sentences for (pivot, target) corpora where the",
        "This paper considers the problem of KB completion and proposes ITransF for this\npurpose. IStransF has an innovative and practical feature: unlike previously reported approaches, ITransF does not attempt to infer a KB completion program. The paper compares IStransF with other existing approaches.\nThis paper consists of two parts:\nAn introduction part discusses",
        "This paper presents a method for translating natural language descriptions into\nUsing the translator, you can go from natural language description to the\nfinal schema. The method consists of two main steps: (1) it maps the concepts of\nthe natural language description to the concepts of the underlying schema,\nand (2) it generates the",
        "This paper focuses on interpreting sarcasm written in Twitter identifying\nsentiment words and then using a machine translation engine to find an\nequivalent not sarcastic message. To this we add an emotive analysis that\ntries to detect the emotion expressed in the source message.\n2018.conf-10.pdf(pdf 1M)\n2018.conf-10.pdf(PDFs 100-100)\n2018_conf.pdf(PDFs 40-40)\nMohammed Abdel-Hamid, David C. Moises, Mert Gurel, Ekin Lah,",
        "This paper describes a system to assist written test scoring.\n\n- Strengths:\nThe paper represents an application of an interesting new model to a scoring problem.\n\n- Weaknesses:\nThe model is somewhat complicated and may be difficult to use.\n\n- Novel contributions:\nA completely new model for written test scoring. The scoring system is not based on",
        "This paper introduces new configurations and training objectives in two ongoing research lines, namely, a method based on a generic approach to multi-agent learning and a method for modelling an agent as a finite state machine in order to study how the training algorithm can help an",
        "This paper proposed a new phrasal RNN architecture for sequence to sequence\ngeneration. They have evaluated their architecture based on (i) the language model (LM),\n(ii) the order of phoneme and (iii) the order of semantic features for the training set.\nThey have chosen four data sets-one for each case",
        "This paper proposes new prediction models for Japanese SRL task by adopting the\nEnglish state-of-the-art models. To build these new models this paper\nadopts DMLZ state-of-the-art Japanese SRL models and then extracts parameters.\nFor model learning, the following models are used: DMLZ prediction models,\nDMLZ baseline models trained on Japanese sentences, and other DMLZ",
        "This paper develops an LSTM-based model for classifying image data into well-defined categories according to a decision tree that determides the classes according to the type of image. Data was obtained from the 302 images in the 2001 AIST Database Challenge. The classifying function is a linear combination of",
        "This paper proposes a method for recognizing lexical entailment (specifically,\nhypernymy and hyponymy) and the lexical properties of this recognition: it suggests that lexical properties,\nlexical relations and the language in which they are studied are the essential factors for lexical recognition. An\nautomatic",
        "This paper proposes a method for evaluating the potential impact of changes at the national level to the climate and ocean at the regional level. However, this method is constrained by the presence of climate-sensitive phenomena and regional characteristics. This study has an application to the",
        "This paper proposed a very interesting idea of using cognitive features for\nsentiment analysis and sarcasm detection. This method was developed by\nAyaneza, D., et al, in 2014.\nMore, there is a possibility of integrating these two features.\nHere are the points to remember for the paper:\n1) If the algorithm is implemented on computers, then",
        "This paper proposes a neural-styled topic model, extending the objective of\nword2vec to also learn latent features from sentences, that are orthogonal to the words that characterize a document. We present a new neural framework of word2vec, called Pose, with three layers. The main learning objective in Pose is to learn positional",
        "This paper describes four methods of obtaining multilingual word embeddings and\na modified QVEC metric for evaluating the efficacy of those methods. The embedding models have been designed with the aim of facilitating effective and efficient use of embeddings in low-resource languages, such as languages for which the annotated corpus is",
        "This paper proposes a method for discovering correspondences between a single text and multiple documents. It exploits machine learning (ML) for discovering regularities, which then acts as the foundation element for the search. The ML is a probabilistic generative model, with training data representing instances corresponding to each text-document combination, in",
        "This paper proposes an approach for multi-lingual named entity recognition\nusing features from multilingual language models. The approach is based on the assumption that\nentity names are unique not only in any given text, but across all texts. The method for finding\nentity names in a test text includes: generating a list",
        "This paper proposes the new (to my knowledge) step of proposing to treat a\nnumber of sentence pair scoring results with regression on a single, standardized\nscore, thus reducing the need to deal with many types of data. In the past, it was\nmore common to try to",
        "This paper presents a transition-based graph parser able to cope with the rich\nrepresentations of a semantically-enhanced graph grammar language known as the Semi-Parsed\nForm Language (SPL). These SPL representations can be arbitrarily complex and can lead to incom-\nhabilitation of other transition-based graph parser techniques. The algorithm developed",
        "This paper presents a Stack LSTM parser based on the work of Henderson et al.\n(2008, 2013) on joint syntactic/semantic processing. The parser was created using\nexisting LSTM parsers (Hulshof et al. 2017) and incorporated new strategies which\nwere developed in their work. An experimental comparison will be shown between the\nsystems presented in the paper and in comparison",
        "This paper investigates three simple weight-pruning techniques for NMT, and\neconomically analyses the three techniques, the weights pruned by them as well as their computational costs, to find out which one is more efficient.\nWe study 3 simple weight-pruning techniques, whose complexity relies on either a single pass of the",
        "This paper presents results on the UD treebanks to test delexicalized transfer\nparsers and an unsupervised parser which is enriched with external\nprobabilities. Results show that the UD parser generates the best results\nfor the full-range parser. It also shows that the parser which is enriched\nwith external probabilities offers the best results",
        "This paper presents an approach to tag word senses with temporal information\n(time of appearance and vanish) by exploiting the temporal information encoded in the contexts of the word senses. Word senses and corresponding contexts are linked by a binary flag (Tagging flag) that can be set or cleared as the",
        "This paper models event linking using CNNs. Given event data, we first extract the information of the events, based on the input features extracted from the event data. Second, the CNN-based model predicts the most likely type of events. Third, we compare these results by calculating",
        "This paper describes a new deterministic dependency parsing algorithm and the results it leads to. It is part of an ambitious program to make better use of machine learning techniques to address all the different ways in which linguists have developed automatic sentence parsers, and thereby find a way to combine",
        "This paper improves significantly upon previous work related to the subject. it is not, however, new in the sense that it presents novel research. The paper addresses some points not previously touched upon, and also provides the basis for other work to be conducted by other authors.\nTo date, much of the published body of",
        "This paper extends an approach to rate-distortion optimization to deep encodings with a simple cost model for the bits used by each deep encoding with an additional cost model for code-switches, and shows that combining rate and distortion optimizations is feasible in the simplest instances of video",
        "This paper describes a new approach to meta learning by interpreting the SOM-based model as an instance of a learning model and representing it as a neural network whose input is the neural activity level produced by the model. To demonstrate the approach we consider the SOM-based model, and use its two parameters to represent",
        "\u2206\ufffd\u00de\u00de\u00e0\u00de\u00e5\u00c0\u00de\u00c7\u00d9\u00c1\u00c7\u00c1\u00ca\u00c5\u00cc\u00da\u00df\u00f0\u00c8\u00c0\u00c5\u00c0\u00db\u00db\u00e0\u00da\u00c8\u00db\u00db\n\n## Examples\n\nSee [here](https://github.com/davidjch/text-slur)  for example.\n\n## Credits\n\nThis project",
        "This paper makes a valuable contribution to provide a more clear understanding of the differences between healthcare providers regarding how they perceive their role in providing preventive treatment.gaben to patients. The authors explain that in many cases healthcare providers tend to be resistant to offering disease prevention treatment, which leads to a lack of patient acceptance",
        "This paper proposes a way of adding unsupervised auxiliary tasks to a deep RL policy in order to facilitate learning.\u0448\u0443\u0436\u0435\u043d\u0430\u0436\u0447\u0433\u043c \u0432\u0430\u043d\u0434\u0438 \u0430\u043a\u0443\u0447\u0430\u043b\u0430\u0440\u0438 \u043d\u0430 \u0434\u043e\u043f \u0435\u0434 \u0440\u0430\u043b\u043f\u043e\u0434\u0435\u043f \u0432\u043e\u0440\u0443 \u0430\u043a\u0443\u0447\u0430\u0440\u0438 \u043d\u044c\u0435\u043e\u0434\u0438 \u0430\u043a\u0443\u0447\u0430\u0440\u0438 \u043d\u044c\u0435\u043e\u0434\u0438 \u0430\u043a\u0443\u0447\u0430\u0440\u0438 \u0438 \u043e\u0434\u0438 \u0430\u043a\u0443\u0447\u0430\u0440\u0438 \u043d\u044c\u0435\u043e\u0434\u0438 \u0430\u043a\u0443\u0447\u0430\u0440\u0438 \u0430\u0434\u0430\u0435\u0434 \u043a\u0430\u0435\u0440\u043e\u0434 \u043e\u0435\u0434 \u043a\u0430\u0430\u0440\u0430\u0438 \u043f\u0443\u0438 \u043d\u044d\u0430\u043c\u0432\u044d.\nThe paper is available on arXiv.\nIf we run into a situation where we cannot trust our",
        "This paper proposed to use RL and RNN to design the architecture of networks for image classification on public and private datasets. Using these two architectures will allow us to get a better understanding of network architecture in terms of its power, its effectiveness to detect small objects when compared to classical neural network architectures.\nRL (Self Taught) RL Self Taught (Noise & Discordance) RL",
        "This paper details the approach that won the VizDoom competition. An entry of 1799 ranked seventh. If one compares all the entries and takes that entry as a representative sample. One finds an average of 1563/1799 = roughly 0.87 compared with the average of 1094/1098 = about 0.9. Thus I win with an",
        "This paper proposes learning on the concept of how to deal with the complex problems. This is important to us because it is essential for us, an agency, to be able to understand how to deal with complex problems. This proposal suggests the use of a methodology known as QM. QM is a methodology based on the principle that complex",
        "This paper proposes to investigate attention in the context of multilingual contexts that are characterized by the presence of multiple, superimposed languages. everybody who has a mobile knows about this, but for our purposes we shall focus explicitly on this phenomenon. The reasons are that first, multilingual",
        "This paper investigates the benefits of visual servoing using a learned\nvisual representation. The authors  propose a neural network trained on a collection\nof datasets to learn a better visual representation. The data for this\nresearch came from the datasets used previously for visual servoing.\n\n# Publications\n\nThis paper was presented at",
        "This paper proposes a nonparametric approach to the identification of nonlinear dynamics models in the sequential identification of dynamic parameter models approach using the linear Kalman filters with state and parameter identification. This process reduces the problems associated with the estimation of states and parameters to only a state estimation. The state estimation is computed with a linear Kalman",
        "This paper prunes entire groups of filters in CNN so that the groups contain the relevant filters. Each filter is represented in the corresponding domain by a vector of filter sizes and filter densities, where each filter size and its density are values among the filters. The set of values is a sample from the corresponding domain",
        "This paper is well written, and well referenced. This is exactly what one might expect from someone at Harvard. You present the issue, give the background information, provide the evidence for both sides, and draw conclusions. You also suggest how this new information might change the policy.\nTherefore, the policy is not",
        "This paper presents an approach for skills transfer from one task to another in a control setting (trained by RL), where the agent has to learn an action (e.g., pressing a button) given new information (e.g., the shape of the control panel). The problem arises when both tasks are related under some common control features, but also include some features that",
        "This paper proposes a model to learn across different views in heterogeneous communities. In first the community is heterogeneous in terms of its views. We will study the learning process at two levels. The first level is the learning process related to the beliefs of a community about a target topic and the second is the learning process related to the",
        "This paper proposed a neural attention model which has a learnable and parameterized attention for processing the sequence of data over long sequence of documents, with the use of deep neural networks (NN) for processing data from a wide array of sources: a long document, a short document, a graph, text, audio, video, etc. By introduing a",
        "This paper presents an information theoretic framework for analysing and designing algorithms for distributed control systems. This approach is developed from the perspective of a decision theory founded upon information theoretic tools such as mutual information and information transfer. This perspective can also be used to provide decision models for",
        "This page shows you how to do an Advanced Search to obtain lists of the most important papers in a given subject field.You will find a tutorial to conduct a basic search. A tutorial is also available to create alert notices.\nSearch in the Advanced Search screen will select the most important papers in",
        "This paper not only shows that a cache model on top of a pre-trained RNN can improve the performance even without any additional parameters, but also provides a new way to make an efficient language model for the pre-trained RNN by learning the parameters in an efficient way. Finally, the paper provides how the pre-trained RNN can be used for speech-to-text tasks",
        "This paper proposed a novel adversarial framework to train a model from demonstration datasets with an adversary. Moreover, adversary takes images generated by the DNN, which is trained using a model trained on the demonstration data. Training models from demonstration datasets by generating pseudo data has been reported to reduce model's performance and the",
        "This paper combines variational RNN (VRNN) and domain adversarial networks (DAN) to improve machine translation. Using VRNN as a base network for DAN allows to combine the strength of machine-learned VRNN with a strong adversarial network for generating more accurate translations. This method was proposed by the author for the DeepLWC challenge 2017 and was considered",
        "This paper introduces the idea of a model of cycling that is capable of performing various cycling-related tasks, is programmed in a computer, and is capable of interacting with a human user. The cycling model proposed and described in this paper is a framework in which the individual cycling models designed by the authors",
        "This paper provides a principled and practical formulation of what we may call an \u201cexplanatory\u201d approach to conceptual metaphor, by considering its various facets. ultimately providing a basis for a new approach to the phenomenon of conceptual metaphor. As such our approach is novel and stands apart from the vast",
        "This paper reviews the evidence of the use of the Prosecutor\u2019s Discretionary Tools, in particular Prosecutorial Discretion in the administration of justice. everybody uses Prosecutorial Discretion with a single goal in mind which is to secure Justice and equality in law enforcement. This paper",
        "This paper proposed an integration of memory network with reinforcement learning. An important difference between the two methods is that reinforcement learning trains agents to pursue behaviors which improve overall performance whereas memory network does not necessarily improve performance. Rather, memory network can simply use all its previous experience to produce agents which are better than",
        "This paper presents an analysis of the potential cost-saving benefits associated with the provision of a universal basic income in Finland relative to the other Nordic countries. Finland is currently the least developed economy of the Nordic region: its gross social product (PPP) is about half the Nordic median, unemployment is about twice as high as",
        "This paper introduces an approach for future frame prediction in videos by decoupling motion estimation and frame prediction, resulting in a more accurate and computationally efficient prediction. ultimately leading to a better quality of the final results. In addition, it offers a solution for an improved reconstruction of the video",
        "This paper provides an interesting framework for handling semi-supervised RL and we demonstrate its strengths by comparing the traditional RL and semi-supervised RL algorithms. A case study based benchmark on the popular Atari benchmark is also provided to empirically evaluate the capabilities of the semi-supervised RL algorithms.\nOur paper uses Semi-supervised Reinforcement Learning algorithms. In these algorithms",
        "This paper proposes a new Bayesian estimator called the Gibbs sampler. The Gibbs sampler is a Bayesian version of the adaptive Metropolis sampler. It consists of three components: (1) conditional prior, which serves as an estimator of model parameters, (2) proposal, which is generated by using the posterior distribution from the first component, and (3) the chain-rule,",
        "\nThis papers adds to the literature on learning optimizers/algorithms that has gained momentum in the recent years. In particular, this paper focuses on learning optimizers for optimization problems. The contributions focus on learning optimizers that learn the shape of the objective function, in order to better perform at task learning in terms of accuracy.\nThe contributions",
        "This paper describes a method to estimate likelihood scores for a range of models of genetic relatedness based on a particular set of microsatellite data. hopefully, the techniques developed here can aid the user of genetic linkage theory in deciding which tests to choose and in assessing the potential size of the groups that are relevant when testing",
        "This paper presents new way for compressing and decompressing DWAC codes based on the original idea of Dmitry Zherebov. It considers the idea of the original DWAC codes, proposes some modifications, gives a more precise description of the algorithm including its parameters, and presents some of its applications. The latter can be found e.g. in",
        "This paper presents a training strategy for deep networks.  First, the network is trained in a standard fashion.  Afterward, the model is trained in a way that provides a greater number of outputs, increasing its representational power (the additional information can be used as a new criterion for selecting appropriate models, for example).\nThis is just a short summary",
        "This paper proposes a new memory module for large scale life-long and one-shot learning. The module is general enough to handle many types of inputs, yet is small to process the entire input at once. It consists of a memory cube followed by a multi-layer feed-forward network capable of both feeding forward memories and carrying",
        "This paper presents a clear hierarchical taxonomy of transfer learning methods as applicable to medical image data. The taxonomy is based on a hierarchical view of medical image learning, which we refer to as medical learning domains when referring to multiple aspects of learning such as classification, segmentation and regression. These domains, in turn",
        "This paper proposes a new gating mechanism to combine word and character representations. The proposed model sets a new state-of-the-art record on the U.S. National Institute of Standards and Technology (NIST\u2019s) benchmark, challenging the current state of the art. The proposed model is also capable of learning from small numbers of sentences",
        "This paper performs a very important service: exploring in a clear and systematic way the performance challenges faced by the emergency management sector in Western Australia. Since the sector is not well understood and is not always appreciated in Australia, this article should be viewed by practitioners as an opportunity to understand how the sector operates and",
        "This paper addresses one of the major shortcomings of generative adversarial networks - their lack of support for input data lying outside the original training dataset, i. This makes it a little more difficult for the AI 2 work for you. For our purposes, let\u2019s assume that our data set is already complete, with its",
        "This paper presents a novel way of pruning filters from convolutional neural network models, which reduce model complexity substantially while improving training performance. Model sizes can be reduced as much as 30-50% using pruning methods, and the pruning methods can be combined with traditional techniques (e.g., learning without backprop) to further reduce training times, as",
        "This paper provides two approaches to question answering: pointing to spans, and use of match-LSTMs which are more flexible, but perform worse on the general question answering task than the models. These models have both been trained and tested on the same task: an open-ended general question answering task on",
        "This paper proposes a modification of the parametric texture synthesis model of Gatys et al. to take into account long-term texture evolution. We propose to model long-term texture evolution in terms of the evolution model of texture defined by Gatys et al.\nDuring the processing of an image, texture features may be extracted and combined to produce",
        "This paper proposed a dynamic coattention network for the question answering task with long contextual documents. \nThe proposed network outperforms the state-of-the-art neural network models in several datasets and shows a large improvement in the open domain dataset.\n\nThe paper proposes a dynamic coattention neural network that is task specific: the contextual document",
        "\ufffd\ufffd\u2020\u040c\u040c\u040c\u0490\u203a\u045b \u0403\u201a\u0403\u201a\u0403\u20ac\u0403\u201a\u20ac\u0403\u20ac\u0403\u20ac\u0403\u20ac\u20ac\u0403\u20ac\u0403\u20ac\u0403\u20ac\u0403\u20ac\u0403\u20ac\u0403\u20ac\u0403\u20ac\u0403\u20ac\u0403\u20ac\u0403\u20ac\u0403\u20ac\u0403\u20ac\u0403\u20ac\u0403\u20ac\u0403\u20ac\u0403\u20ac\u0403\u20ac\u0403\u20ac\u0403\u20ac\u0403\u20ac\u0403\u20ac\u0403\u20ac\u0403\u20ac\u0403\u20ac\u0403\u20ac\u0403\u20ac\u0403\u20ac\u0403\u20ac\u0403\u20ac\u0403\u20ac\u0403\u20ac\u0403\u20ac\u0403\u20ac\u0403\u20ac\u0403\u20ac\u0403\u20ac\u0403\u20ac\u0403\u20ac\u0403\u0413\u040b\u045b \u0403\u201a\ufffd",
        "This paper optimizes autoencoders for lossy image compression. Minimal adaptation of the loss makes autoencoding of lossy images comparable for performance against the current state of the art, in the context of lossily compressed images of arbitrary dimensions. This gives new opportunities for lossily compressed images of large dimensions",
        "This paper tests zoneout against a variety of datasets - character level, word level, and pinyin pronunciation level - using zonesout and zonesout15. pr\u00fcben.\nEach dataset comprises a training set (75%) and a test set (25%) and a reference test set of the same size. The zonesout algorithm, using only the zones defined by",
        "This paper motivates the combination of autoregressive models with Variational Auto-Encoders and how to control the amount the amount of information stored in the latent code. The authors use the concept of Variational Auto-Encoder (VAE) to approximate a Gaussian mixture. The mixture is approximated using approximate normalization weights. In addition, they use VAE as",
        "This paper proposes a method for significantly increasing the number of parameters in a single layer while keeping computation in par with (or even less expensive than) that of a fully connected network. In particular, the training process for learning this model is very efficient. In this paper' the authors demonstrate the capabilities of the proposed method to be a robust",
        "This paper discusses Hyperband, an extension of successive halving by Jamieson & Talwalkar (AISTATS 2010) to allow the use of partial successive halving in hyper-uniform distributions. An efficient algorithm for computing probability, the H2W algorithm, is proposed. Several distributions proposed by Jamieson and Talwalkar are shown to be hyper-uniform, thereby reducing the computation",
        "This paper introduces the Quasi-Recurrent Neural Network (QRNN) that dramatically limits the computational burden that is essential to recurrent neural network architectures. essentially, the QRNN limits the amount of computations made inside a neural network by using a restricted subset of the inputs. in the end result, the",
        "This paper explores ensemble optimisation in the context of policy-gradient training. Ensemble training has traditionally been reserved for problems requiring large amounts of data and large learning rates. In fact, the majority of data generated each day is generated and stored at large organisations and is frequently labelled as \u201cbig data\u201d problems. However, ensemble",
        "This paper studies the problem of transferring solutions of a large, multi-dimensional dynamical system to other parameterizations. If we make a parameterization of the full dynamical system we often need to change our parameters after a computation of the solutions in a different parameterization. For example a set of data, e.g., on",
        "This paper proposes an approach to learning word vector representations for character sequences and their phonological embeddings, using character vector embeddings. potentially useful for Machine Translation, Text-to-Speech and Speech Recognition. It is a modest work and is intended to help progress in Machine Translation, if it can lead to a better understanding of these two",
        "This paper introduces MusicNet, a new dataset. Application of ML techniques to music have been studied in separate domains, which are isolated from one another. We address this gap in the research community by taking an end-to day perspective to investigate an integrated system that combines aspects of both music and audio technologies. MusicNet",
        "This paper applies REINFORCE to learn MCMC proposals within the existing STOKE scheme for super-optimization. It's shown that the REINFORCE can efficiently improve an already optimized, non-stationary MCMC proposal to decrease the run-time. Thus, the efficiency of the proposed approach is further shown by the improvement of a previously optimized MCMC proposal. It",
        "This paper presented a method of improving the efficiency of deep networks acting on the last iteration by remapping the weight of each layer as a simple concatenation matrix where the matrix contains the hidden (layer), output (decision), and hidden (layer) weight. \u0433\u043e\u0440\u043eczy\u0144ski2006 .\nFigure 1. Dataflow with concatenation matrix. Image courtesy of Rados\u0142aw Gorostowicz\nWhen used in",
        "This paper applies the idea of normalizing flows (NFs), which allows us to build complex densities with tractable likelihoods and a few parameters, which has only rarely been achieved in practice. ultimately we aim to provide a step toward data assimilation with NFs, even while the theoretical underpinnings still stand.\nWe introduce Normalizing Flows on the",
        "This paper focusses on attention for neural language modeling and has two major aspects of attention: (1) the role of the attention model in neural language models\u2014it can be understood as an approximation of the actual data generator (i. A., the human brain), and (2) the role of attention as an explanation for phenomena such",
        "This paper is a by-the-numbers extension of the hidden semi-Markov model to include nonlinear observations, nonlinear time-invariant state variables, external constraints, and partial observation, including an arbitrary number of state variables. We call it the nonlinear semimodel, and we show that the model fits are no worse than the hidden semi-Markov model for the",
        "This paper presents a variational inference based method for learning nonlinear latent variables for sparse data that has proven useful for many applications in statistics and a variety of applications in a wide field of data driven disciplines. Using recent variational inference results for a nonlinear latent variable, we show it to",
        "This paper first discusses a general framework for improving optimization of a multi-stage workflow by allowing it to be modular. As one might expect, this paper assumes that a workflow can be divided into two phases \u2013 the preparatory phase which occurs before actual processing and the final stage \u2013 which takes place after",
        "This paper extends preceding works to create a mapping between the word embedding space of two languages. Finally, we discuss how the embedding space of two languages can be visualized. We hope that through the embedding space, more efficient word-match algorithms in bilingual translation can be developed.\nbilingual translation\nembedding space\ninter-language mapping\nDive into the World of Innovation:",
        "This paper proposes to learn decomposition of sequences (such as words) for speech recognition. It addresses some problems that exist in learning techniques for speech recognition. First, a speech recognition system based on the hypothesis of a statistical, fuzzy model to recognize speech. The fuzzy model and sequence decomposition, as well as their recognition for speech, are introduced.",
        "This paper is technically sound. It highlights well the strengths and weaknesses of the proposed simplified model. Apart from the practical advantages of its simplicity it has the great merit of being a model that is easy to simulate.\nThis study shows that we can get reasonable agreement to the experimental results of this model, and I",
        "This paper shows how policy gradient and Q-Learning may be combined together, improving learning performance.\nThe paper describes two learning algorithms used to tune a Lindenbaum-Wright-Jones model. When the model and policy gradient work with a realistic data set, the resulting agent performs close to optimality, however if one uses random data, the performance is not",
        "This paper clearly lays out the recipe for a family of invertible density models, explores a few extensions of the basic family into the inversion engine family, and also describes the main features and challenges of the invertible density inference engine (IDSINE), which is built on these models and will be used for inference using the SGLD engine.",
        "This paper extends batch normalization successfully to RNNs where batch normalization has previously failed or done very clumsily to obtain convergence. As it turns out, the fundamental difference that underlies the success of batch normalization on the one hand and batch normalization extensions on the other hand is that we can",
        "This paper describes a way to speed up convergence through sudden increases of otherwise monotonous training processes such as the EM algorithm or Monte Carlo Markov Chain methods for the analysis of complex problems. It is demonstrated that such solutions can be found even for tasks that cannot be solved with conventional methods",
        "This paper proposes a weakly supervised, end-to-end neural network model for solving a challenging natural language understanding task. It uses a new supervision method which is much less noisy than the conventional label supervision and enables to learn high-quality models for language understanding.\nOne should not confuse this paper with a similar paper entitled",
        "This paper introduces a 'GPU-friendly' variant of A3C which relaxes some synchronicity constraints in the original A3C so that GPUs can more fully contribute to the execution of the algorithm. literally meanings of A3C, as well as the limitations of A3C which hinder further GPU use. In GPU environments, A3C is an excellent tool for exploring",
        "This paper presents an approach to learn to generate programs. Instead of directly programming the output values in the output variable and executing the program, the user must specify the target output variables and programs to achieve them. For the approach to achieve the targets specified by the user, we first generate programs using artificial intelligence, where both domain",
        "This paper considers the problem of model-based policy search. The authors \nconsider the use of Bayesian Neural Networks to learn a model of the environment from data.\n\n### Questions asked\nThis paper asks the following questions:\n\n* What is the best Bayesian Neural Network architecture for model search?\n* Given the best Bayesian Neunal Network architecture,",
        "This paper describes a new way of variable computation, which uses a different number of units depending on the number of decimal places the variable is. surely, there will be many people familiar with multiplication or division with a variable. For example, multiplying a variable with an integer number and dividing a variable with another variable are very simple",
        "This paper investigates the potential of the FINS methodology to monitor arable upland fields. It seeks to assess the potential of the methodology to provide useful spatial information regarding crop production and the environment, with respect to the management",
        "This paper proposes the neural noisy channel model, P(x|y), where (x, y) is a input-to-out sequence pair, \u03b7 is a nonzero noise term where \u03b7 = 1.P(x|y) 1.0 1 0.75 where x = random input to a channel and Y = random output. This is a model of stochastic data. The neural noisy channel model",
        "This paper builds on the work of Weston (2016), using End-to-end memory network (End2end Net; Bender and Bouchard, 2009) to investigate the memory span in an artificially controlled environment. Rats with specialized lesions were trained to memorize either shape or material stimuli, and were then tested in an endpoint memory task that made both shape and material available throughout testing.",
        "This paper extends the GAN framework to allow for latent variables. The observed data set is expanded by drawing latent variables z from a conditional distribution q(z|x). This can be seen as a latent space and the latent variables take the characteristics of the latent space. The latent variables can be treated as inputs into the generative model",
        "This paper introduces a simulator and a set of synthetic tasks for evaluating a dialogue agent's ability to engage in conversation with humans through text and speech. surely we see lots of chatbots online, all those are designed and built to interact with us through text only. as technology is expanding to include",
        "This paper proposes a design principle for computation blocks in convolutional neural networks.\nThe paper focuses on design principles for compute units and the corresponding software stack. In designing such units, we first need to decide a number and dimensionality of parameters. For the layer parameters, the design space depends on both",
        "This paper studies the energy landscape of the loss function in neural networks.  It is generally understood that networks are approximators of nonlinear functions whose energy (loss) is minimized as one reduces a training instance set into models. This results in the objective of minimizing cross-entropy-cost. These are loss functions. The purpose of this paper is to analyze",
        "This paper provides a simple method to handle action repetitions. They make the action a tuple (a,x), where a is the action chosen, and x the number of repetition.\nIt makes sense for a game with repetition. It is a variant of the standard rule with repetition, where the initial action is a and the repetition is x, or",
        "This paper proposed a proximal (quasi-) Newton\u2019s method to learn binary DNN. The main contribution of the paper is to make our approach capable of dealing with heterogeneous datasets. Our experiments indicate that the proposed approach reduces error rates by 2.5-3.4% in comparison with the state-of-the-art method. Moreover, our method is 8-11%",
        "This paper is a parallel work to Improving Generative Adversarial Networks with Denoising Feature Matching. The main solution of both papers is introducing the idea of the Denoising Feature Matching (DFM) to Generative Adversarial Networks. The two tasks are described below:\nIn the first part of this paper, the GAN-based image denoising system"
    ]
}